{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d57980c8",
   "metadata": {},
   "source": [
    "### Data Ingestion to Vector DB pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4744fcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pom-m\\Desktop\\ai\\rag-langchain\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a2c371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 PDF files to process.\n",
      "\n",
      "Processing: ai-report.pdf\n",
      "✔️ Loaded 71 pages\n",
      "\n",
      "Processing: NIPS-2017-attention-is-all-you-need-Paper.pdf\n",
      "✔️ Loaded 11 pages\n",
      "\n",
      "Total documents loaded: 82\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 0, 'page_label': '1', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='1 \\n \\n \\nArtificial Intelligence \\nand the Future of \\nTeaching and Learning \\nInsights and Recommendations \\nMay 2023'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 1, 'page_label': '2', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Artificial Intelligence and the Future of Teaching and Learning \\nMiguel A. Cardona, Ed.D. \\nSecretary, U.S. Department of Education \\nRoberto J. Rodríguez \\nAssistant Secretary, Office of Planning, Evaluation, and Policy Development \\nKristina Ishmael \\nDeputy Director, Office of Educational Technology \\nMay 2023 \\n \\nExamples Are Not Endorsements \\nThis document contains examples and resource materials that are provided for the user’s \\nconvenience. The inclusion of any material is not intended to reflect its importance nor is it \\nintended to endorse any views expressed or products or services offered. These materials may \\ncontain the views and recommendations of various subject matter experts as well as hypertext links, \\ncontact addresses, and websites to information created and maintained by other public and private \\norganizations. The opinions expressed in any of these materials do not necessarily reflect the \\npositions or policies of the U.S. Department of Education. The U.S. Department of Education does \\nnot control or guarantee the accuracy, relevance, timeliness, or completeness of any information \\nfrom other sources that are included in these materials. Other than statutory and regulatory \\nrequirements included in the document, the contents of this guidance do not have the force and \\neffect of law and are not meant to bind the public. \\nContracts and Procurement \\nThis document is not intended to provide legal advice or approval of any potential federal \\ncontractor’s business decision or strategy in relation to any current or future federal procurement \\nand/or contract. Further, this document is not an invitation for bid, request for proposal, or other \\nsolicitation. \\nLicensing and Availability \\nThis report is in the public domain and available on the U.S. Department of Education’s \\n(Department’s) website at https://tech.ed.gov. \\nRequests for alternate format documents such as Braille or large print should be submitted to the \\nAlternate Format Center by calling 1-202-260-0852 or by contacting the 504 coordinator via email \\nat om_eeos@ed.gov. \\nNotice to Limited English Proficient Persons \\nIf you have difficulty understanding English, you may request language assistance services for \\nDepartment information that is available to the public. These language assistance services are \\navailable free of charge. If you need more information about interpretation or translation services, \\nplease call 1-800-USA-LEARN (1-800-872-5327) (TTY: 1-800-437-0833); email us at \\nEd.Language.Assistance@ed.gov; or write to U.S. Department of Education, Information Resource \\nCenter, LBJ Education Building, 400 Maryland Ave. SW, Washington, DC 20202. \\nHow to Cite \\nWhile permission to reprint this publication is not necessary, the suggested citation is as follows:  \\nU.S. Department of Education, Office of Educational Technology, Artificial Intelligence and \\nFuture of Teaching and Learning: Insights and Recommendations, Washington, DC, 2023.  \\nThis report is available at https://tech.ed.gov'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 2, 'page_label': '3', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Table of Contents \\nIntroduction ................................ ................................ ................................ ..........................  1 \\nRising Interest in AI in Education ......................................................................................................................................................... 1 \\nThree Reasons to Address AI in Education Now................................................................................................................... 2 \\nToward Policies for AI in Education .................................................................................................................................................. 3 \\nBuilding Ethical, Equitable Policies Together................................ ........................  6 \\nGuiding Questions ........................................................................................................................................................................................... 6 \\nFoundation 1: Center People (Parents, Educators, and Students) ......................................................................... 6 \\nFoundation 2: Advance Equity...............................................................................................................................................................7 \\nFoundation 3: Ensure Safety, Ethics, and Effectiveness ................................................................................................ 8 \\nFoundation 4: Promote Transparency ........................................................................................................................................... 9 \\nOverview of Document ............................................................................................................................................................................ 10 \\nWhat is AI? ................................ ................................ ................................ ..........................  11 \\nPerspective: Human-Like Reasoning ........................................................................................................................................... 12 \\nPerspective: An Algorithm that Pursues a Goal................................................................................................................... 12 \\nPerspective: Intelligence Augmentation ................................................................................................................................... 14 \\nDefinition of “Model”.................................................................................................................................................................................... 14 \\nInsight: AI Systems Enable New Forms of Interaction ................................................................................................... 15 \\nKey Recommendation: Human in the Loop AI ..................................................................................................................... 16 \\nLearning ................................ ................................ ................................ ..............................  18 \\nInsight: AI Enables Adaptivity in Learning................................................................................................................................. 18 \\nIntelligent Tutoring Systems: An Example of AI Models ............................................................................................. 19 \\nImportant Directions for Expanding AI-Based Adaptivity .......................................................................................... 20 \\nA Duality: Learning With and About AI ........................................................................................................................................ 22 \\nA Challenge: Systems Thinking About AI in Education ................................................................................................. 22 \\nOpen Questions About AI for Learning ....................................................................................................................................... 23 \\nKey Recommendation: Seek AI Models Aligned to a Vision for Learning .................................................... 24 \\nTeaching ................................ ................................ ................................ .............................  25 \\nAlways Center Educators in Instructional Loops ............................................................................................................... 25 \\nInsight: Using AI to Improve Teaching Jobs .......................................................................................................................... 26 \\nPreparing and Supporting Teachers in Planning and Reflecting ........................................................................ 29 \\nDesigning, Selecting, and Evaluating AI Tools .................................................................................................................... 30 \\nChallenge: Balancing Human and Computer Decision-Making .......................................................................... 30 \\nChallenge: Making Teaching Jobs Easier While Avoiding Surveillance ........................................................ 31 \\nChallenge: Responding to Students’ Strengths While Protecting Their Privacy .................................... 32 \\nQuestions Worth Asking About AI for Teaching .................................................................................................................34 \\nKey Recommendation: Inspectable, Explainable, Overridable AI .......................................................................34'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 3, 'page_label': '4', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Formative Assessment ................................ ................................ ................................ . 37 \\nBuilding on Best Practices ..................................................................................................................................................................... 37 \\nImplications for Teaching and Learning ................................................................................................................................... 38 \\nInsight: AI Can Enhance Feedback Loops ............................................................................................................................... 39 \\nAn Example: Automated Essay Scoring .................................................................................................................................... 40 \\nKey Opportunities for AI in Formative Assessment ......................................................................................................... 41 \\nKey Recommendation: Harness Assessment Expertise to Reduce Bias ...................................................... 42 \\nRelated Questions.........................................................................................................................................................................................43 \\nResearch and Development ................................ ................................ .......................  44 \\nInsight: Research Can Strengthen the Role of Context in AI ....................................................................................44 \\nAttention to the Long Tail of Learner Variability ................................................................................................................ 46 \\nPartnership in Design-Based Research ......................................................................................................................................47 \\nRe-thinking Teacher Professional Development .............................................................................................................. 48 \\nConnecting with Public Policy ........................................................................................................................................................... 49 \\nKey Recommendation: Focus R&D on Addressing Context.................................................................................... 50 \\nOngoing Questions for Researchers ............................................................................................................................................ 50 \\nDesired National R&D Objectives .................................................................................................................................................... 51 \\nRecommendations ................................ ................................ ................................ .........  52 \\nInsight: Aligning AI to Policy Objectives ..................................................................................................................................... 52 \\nCalling Education Leaders to Action ............................................................................................................................................ 53 \\nRecommendation #1: Emphasize Humans in the Loop ............................................................................................... 53 \\nRecommendation #2: Align AI Models to a Shared Vision for Education .....................................................54 \\nRecommendation #3: Design Using Modern Learning Principles ..................................................................... 56 \\nRecommendation #4: Prioritize Strengthening Trust .....................................................................................................57 \\nRecommendation #5: Inform and Involve Educators ....................................................................................................57 \\nRecommendation #6: Focus R&D on Addressing Context and Enhancing Trust and Safety .... 59 \\nRecommendation #7: Develop Education-Specific Guidelines and Guardrails..................................... 60 \\nNext Steps .......................................................................................................................................................................................................... 60 \\nCommon Acronyms and Abbreviations ................................ ................................ . 62 \\nAcknowledgements ................................ ................................ ................................ .......  63 \\nReferences................................ ................................ ................................ .........................  64'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 4, 'page_label': '5', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='1 \\nIntroduction \\nThe U.S. Department of Education (Department) is committed to supporting the use of \\ntechnology to improve teaching and learning and to support innovation throughout educational \\nsystems. This report addresses the clear need for sharing knowledge and developing policies for \\n“Artificial Intelligence,” a rapidly advancing class of foundational capabilities which are \\nincreasingly embedded in all types of educational technology systems and are also available to \\nthe public. We will consider “educational technology” (edtech) to include both (a) technologies \\nspecifically designed for educational use, as well as (b) general technologies that are widely used \\nin educational settings. Recommendations in this report seek to engage teachers, educational \\nleaders, policy makers, researchers, and educational technology innovators and providers as they \\nwork together on pressing policy issues that arise as Artificial Intelligence (AI) is used in \\neducation.  \\nAI can be defined as “automation based on associations.” When computers automate reasoning \\nbased on associations in data (or associations deduced from expert knowledge), two shifts \\nfundamental to AI occur and shift computing beyond conventional edtech: (1) from capturing \\ndata to detecting patterns in data and (2) from providing access to instructional resources to \\nautomating decisions about instruction and other educational processes. Detecting patterns and \\nautomating decisions are leaps in the level of responsibilities that can be delegated to a computer \\nsystem. The process of developing an AI system may lead to bias in how patterns are detected \\nand unfairness in how decisions are automated. Thus, educational systems must govern their use \\nof AI systems. This report describes opportunities for using AI to improve education, recognizes \\nchallenges that will arise, and develops recommendations to guide further policy development.  \\nRising Interest in AI in Education  \\nToday, many priorities for improvements to teaching and learning are unmet. Educators seek \\ntechnology-enhanced approaches addressing these priorities that would be safe, effective, and \\nscalable. Naturally, educators wonder if the rapid advances in technology in everyday lives could \\nhelp. Like all of us, educators use AI-powered services in their everyday lives, such as voice \\nassistants in their homes; tools that can correct grammar, complete sentences, and write essays; \\nand automated trip planning on their phones. Many educators are actively exploring AI tools as \\nthey are newly released to the public1. Educators see opportunities to use AI-powered capabilities \\nlike speech recognition to increase the support available to students with disabilities, multilingual \\nlearners, and others who could benefit from greater adaptivity and personalization in digital \\ntools for learning. They are exploring how AI can enable writing or improving lessons, as well as \\ntheir process for finding, choosing, and adapting material for use in their lessons.  \\nEducators are also aware of new risks. Useful, powerful functionality can also be accompanied \\nwith new data privacy and security risks. Educators recognize that AI can automatically produce \\noutput that is inappropriate or wrong. They are wary that the associations or automations \\ncreated by AI may amplify unwanted biases. They have noted new ways in which students may \\n \\n1 Walton Family Foundation (March 1, 2023). Teachers and students embrace ChatGPT for education. \\nhttps://www.waltonfamilyfoundation.org/learning/teachers-and-students-embrace-chatgpt-for-education'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 5, 'page_label': '6', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='2 \\nrepresent others’ work as their own. They are well-aware of “teachable moments” and \\npedagogical strategies that a human teacher can address but are undetected or misunderstood by \\nAI models. They worry whether recommendations suggested by an algorithm would be fair. \\nEducators’ concerns are manifold. Everyone in education has a responsibility to harness the \\ngood to serve educational priorities while also protecting against the dangers that may arise as a \\nresult of AI being integrated in edtech. \\nTo develop guidance for edtech, the Department works closely with educational constituents. \\nThese constituents include educational leaders—teachers, faculty, support staff, and other \\neducators—researchers; policymakers; advocates and funders; technology developers; \\ncommunity members and organizations; and, above all, learners and their families/caregivers. \\nRecently, through its activities with constituents, the Department noticed a sharp rise in interest \\nand concern about AI. For example, a 2021 field scan found that developers of all kinds of \\ntechnology systems—for student information, classroom instruction, school logistics, parent-\\nteacher communication, and more—expect to add AI capabilities to their systems. Through a \\nseries of four listening sessions conducted in June and August 2022 and attended by more than \\n700 attendees, it became clear that constituents believe that action is required now in order to get \\nahead of the expected increase of AI in education technology—and they want to roll up their \\nsleeves and start working together. In late 2022 and early 2023, the public became aware of new \\ngenerative AI chatbots and began to explore how AI could be used to write essays, create lesson \\nplans, produce images, create personalized assignments for students, and more. From public \\nexpression in social media, at conferences, and in news media, the Department learned more \\nabout risks and benefits of AI-enabled chatbots. And yet this report will not focus on a specific AI \\ntool, service, or announcement, because AI-enabled systems evolve rapidly. Finally, the \\nDepartment engaged the educational policy expertise available internally and in its relationships \\nwith AI policy experts to shape the findings and recommendations in this report.  \\nThree Reasons to Address AI in Education Now \\n“I strongly believe in the need for stakeholders to understand the cyclical \\neffects of AI and education. By understanding how different activities \\naccrue, we have the ability to support virtuous cycles. Otherwise, we will \\nlikely allow vicious cycles to perpetuate.”  \\n —Lydia Liu \\nDuring the listening sessions, constituents articulated three reasons to address AI now: \\nFirst, AI may enable achieving educational priorities in better ways, at scale, and with lower costs. \\nAddressing varied unfinished learning of students due to the pandemic is a policy priority, and \\nAI may improve the adaptivity of learning resources to students’ strengths and needs. Improving \\nteaching jobs is a priority, and via automated assistants or other tools, AI may provide teachers \\ngreater support. AI may also enable teachers to extend the support they offer to individual \\nstudents when they run out of time. Developing resources that are responsive to the knowledge \\nand experiences students bring to their learning—their community and cultural assets—is a \\npriority, and AI may enable greater customizability of curricular resources to meet local needs.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 6, 'page_label': '7', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='3 \\nAs seen in voice assistants, mapping tools, shopping recommendations, essay-writing capabilities, \\nand other familiar applications, AI may enhance educational services.  \\nSecond, urgency and importance arise through awareness of system-level risks and anxiety about \\npotential future risks. For example, students may become subject to greater surveillance. Some \\nteachers worry that they may be replaced—to the contrary, the Department firmly rejects the \\nidea that AI could replace teachers. Examples of discrimination from algorithmic bias are on the \\npublic’s mind, such as a voice recognition system that doesn’t work as well with regional dialects, \\nor an exam monitoring system that may unfairly identify some groups of students for \\ndisciplinary action. Some uses of AI may be infrastructural and invisible, which creates concerns \\nabout transparency and trust. AI often arrives in new applications with the aura of magic, but \\neducators and procurement policies require that edtech show efficacy. AI may provide \\ninformation that appears authentic, but actually is inaccurate or lacking a basis in reality. Of the \\nhighest importance, AI brings new risks in addition to the well-known data privacy and data \\nsecurity risks, such as the risk of scaling pattern detectors and automations that result in \\n“algorithmic discrimination” (e.g., systematic unfairness in the learning opportunities or \\nresources recommended to some populations of students). \\nThird, urgency arises because of the scale of possible unintended or unexpected consequences. \\nWhen AI enables instructional decisions to be automated at scale, educators may discover \\nunwanted consequences. In a simple example, if AI adapts by speeding curricular pace for some \\nstudents and by slowing the pace for other students (based on incomplete data, poor theories, or \\nbiased assumptions about learning), achievement gaps could widen. In some cases, the quality of \\navailable data may produce unexpected results. For example, an AI-enabled teacher hiring \\nsystem might be assumed to be more objective than human-based résumé scoring. Yet, if the AI \\nsystem relies on poor quality historical data, it might de-prioritize candidates who could bring \\nboth diversity and talent to a school’s teaching workforce. \\nIn summary, it is imperative to address AI in education now to realize key opportunities, prevent \\nand mitigate emergent risks, and tackle unintended consequences. \\nToward Policies for AI in Education \\nThe 2023 AI Index Report from the Stanford Institute for Human-Centered AI has documented \\nnotable acceleration of investment in AI as well as an increase of research on ethics, including \\nissues of fairness and transparency.2 Of course, research on topics like ethics is increasing \\nbecause problems are observed. Ethical problems will occur in education, too.3 The report found \\na striking interest in 25 countries in the number of legislative proposals that specifically include \\nAI. In the United States, multiple executive orders are focused on ensuring AI is trustworthy and \\nequitable, and the White House Office of Science and Technology Policy has introduced a \\n \\n2 Maslej, N., Fattorini, L., Brynjolfsson E., Etchemendy, J., Ligett, K., Lyons, T., Manyika, J., Ngo, H., Niebles, J.C., Parli, V., \\nShoham, Y., Wald, R., Clark, J. and Perrault, R., (2023). The AI index 2023 annual report. Stanford University: AI Index \\nSteering Committee, Institute for Human-Centered AI.  \\n3 Holmes, W. & Porayska-Pomsta, K. (Eds.) (2022). The ethics of artificial intelligence in education. Routledge. ISBN 978-\\n0367349721'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 7, 'page_label': '8', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='4 \\nBlueprint for an AI Bill of Rights (Blueprint)4 that provides principles and practices that help \\nachieve this goal. These initiatives, along with other AI-related policy activities occurring in both \\nthe executive and legislative branches, will guide the use of AI throughout all sectors of society. \\nIn Europe, the European Commission recently released Ethical guidelines on the use of artificial \\nintelligence (AI) and data in teaching and learning for educators.5 \\nAI is moving fast and heralding societal changes that require a national policy response. In \\naddition to broad policies for all sectors of society, education-specific policies are needed to \\naddress new opportunities and challenges within existing frameworks that take into \\nconsideration federal student privacy laws (such as the Family Educational Rights and Privacy \\nAct, or FERPA), as well as similar state related laws. AI also makes recommendations and takes \\nactions automatically in support of student learning, and thus educators will need to consider \\nhow such recommendations and actions can comply with laws such as the Individuals with \\nDisabilities Education Act (IDEA). We discuss specific policies in the concluding section. \\nFigure 1: Research about AI is growing rapidly. Other indicators, such as dollars invested and \\nnumber of people employed, show similar trends. \\n \\nAI is advancing exponentially (see Figure 1), with powerful new AI features for generating images \\nand text becoming available to the public, and leading to changes in how people create text and \\n \\n4 White House Office of Science and Technology Policy (October 2022), Blueprint for an AI bill of rights: Making automated \\nsystems work for the American people. The White House Office of Science and Technology Policy. \\nhttps://www.whitehouse.gov/ostp/ai-bill-of-rights/  \\n5 European Commission, Directorate-General for Education, Youth, Sport and Culture. (2022). Ethical guidelines on the use of \\nartificial intelligence (AI) and data in teaching and learning for educators, Publications Office of the European \\nUnion. https://data.europa.eu/doi/10.2766/153756'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 8, 'page_label': '9', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='5 \\nimages6. The advances in AI are not only happening in research labs but also are making news in \\nmainstream media and in educational-specific publications.  \\nResearchers have articulated a range of concepts and frameworks for ethical AI7, as well as for \\nrelated concepts such as equitable, responsible, and human-centered AI. Listening session \\nparticipants called for building on these concepts and frameworks but also recognized the need \\nto do more; participants noted a pressing need for guardrails and guidelines that make \\neducational use of AI advances safe, especially given this accelerating pace of incorporation of AI \\ninto mainstream technologies. As policy development takes time, policy makers and educational \\nconstituents together need to start now to specify the requirements, disclosures, regulations, and \\nother structures that can shape a positive and safe future for all constituents—especially students \\nand teachers.  \\nPolicies are urgently needed to implement the following:  \\n1. leverage automation to advance learning outcomes while protecting human decision \\nmaking and judgment;  \\n2. interrogate the underlying data quality in AI models to ensure fair and unbiased pattern \\nrecognition and decision making in educational applications, based on accurate \\ninformation appropriate to the pedagogical situation;  \\n3. enable examination of how particular AI technologies, as part of larger edtech or \\neducational systems, may increase or undermine equity for students; and \\n4. take steps to safeguard and advance equity, including providing for human checks and \\nbalances and limiting any AI systems and tools that undermine equity. \\n  \\n \\n6 Sharples, M. & Pérez y Pérez, R. (2022). Story machines: How computers have become creative writers. Routledge. ISBN \\n9780367751951 \\n7 Akgun, S., Greenhow, C. (2022). Artificial intelligence in education: Addressing ethical challenges in K-12 settings. AI \\nEthics, 2, 431–440. https://doi.org/10.1007/s43681-021-00096-7'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 9, 'page_label': '10', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='6 \\n \\nBuilding Ethical, Equitable \\nPolicies Together \\nIn this report, we aim to build on the listening sessions the Department hosted to engage and \\ninform all constituents involved in making educational decisions so they can prepare for and \\nmake better decisions about the role of AI in teaching and learning. AI is a complex and broad \\ntopic, and we are not able to cover everything nor resolve issues that still require more \\nconstituent engagement. This report is intended to be a starting point. \\nThe opportunities and issues of AI in education are equally important in K-12, higher education, \\nand workforce learning. Due to scope limitations, the examples in this report will focus on K-12 \\neducation. The implications are similar at all levels of education, and the Department intends \\nfurther activities in 2023 to engage constituents beyond K-12 schools. \\nGuiding Questions \\nUnderstanding that AI increases automation and allows machines to do some tasks that only \\npeople did in the past leads us to a pair of bold, overarching questions:  \\n1. What is our collective vision of a desirable and achievable educational system that \\nleverages automation to advance learning while protecting and centering human agency? \\n2. How and on what timeline will we be ready with necessary guidelines and guardrails, as \\nwell as convincing evidence of positive impacts, so that constituents can ethically and \\nequitably implement this vision widely? \\nIn the Learning, Teaching, and Assessment sections of this report, we elaborate on elements of \\nan educational vision grounded in what today’s learners, teachers, and educational systems need, \\nand we describe key insights and next steps required. Below, we articulate four key foundations \\nfor framing these themes. These foundations arise from what we know about the effective use of \\neducational technology to improve opportunity, equity, and outcomes for students and also \\nrelate to the new Blueprint. \\nFoundation 1: Center People (Parents, Educators, and Students) \\nEducation-focused AI policies at the federal, state, and district levels will be needed to guide and \\nempower local and individual decisions about which technologies to adopt and use in schools \\nand classrooms. Consider what is happening in everyday lives. Many of us use AI-enabled \\nproducts because they are often better and more convenient. For example, few people want to \\nuse paper maps anymore; people find that technology helps us plan the best route to a \\ndestination more efficiently and conveniently. And yet, people often do not realize how much \\nprivacy they are giving up when they accept AI-enabled systems into their lives. AI will bring \\nprivacy and other risks that are hard to address only via individual decision making; additional \\nprotections will be needed.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 10, 'page_label': '11', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='7 \\nThere should be clear limits on the ability to collect, use, transfer, and \\nmaintain our personal data, including limits on targeted advertising. \\nThese limits should put the burden on platforms to minimize how much \\ninformation they collect, rather than burdening Americans with reading \\nfine print.8 \\nAs protections are developed, we recommend that policies center people, not machines. To this \\nend, a first recommendation in this document (in the next section) is an emphasis on AI with \\nhumans in the loop. Teachers, learners, and others need to retain their agency to decide what \\npatterns mean and to choose courses of action. The idea of humans in the loop builds on the \\nconcept of “Human Alternatives, Consideration, and Fallback” in the Blueprint and ethical \\nconcepts used more broadly in evaluating AI, such as preserving human dignity. A top policy \\npriority must be establishing human in the loop as a requirement in educational applications, \\ndespite contrary pressures to use AI as an alternative to human decision making. Policies should \\nnot hinder innovation and improvement, nor should they be burdensome to implement. Society \\nneeds an education-focused AI policy that protects civil rights and promotes democratic values \\nin the building, deployment, and governance of automated systems to be used across the many \\ndecentralized levels of the American educational system. \\nFoundation 2: Advance Equity \\n“AI brings educational technology to an inflection point. We can either \\nincrease disparities or shrink them, depending on what we do now.”  \\n—Dr. Russell Shilling \\nA recent Executive Order9 issued by President Biden sought to strengthen the connection among \\nracial equity, education and AI, stating that “members of underserved communities—many of \\nwhom have endured generations of discrimination and disinvestment—still confront significant \\nbarriers to realizing the full promise of our great Nation, and the Federal Government has a \\nresponsibility to remove these barriers” and that the Federal Government shall both “pursue \\neducational equity so that our Nation’s schools put every student on a path to success” and also \\n“root out bias in the design and use of new technologies, such as artificial intelligence.” A specific \\nvision of equity, such as described in the Department’s recent report, Advancing Digital Equity for \\nAll10 is essential to policy discussion about AI in education. This report defines digital equity as \\n \\n8 The White House (September 8, 2022). Readout of White House listening session on tech platform accountability. \\nhttps://www.whitehouse.gov/briefing-room/statements-releases/2022/09/08/readout-of-white-house-listening-session-\\non-tech-platform-accountability/ \\n9 The White House (February 17, 2023). Executive order on further advancing racial equity and support for underserved \\ncommunities through the federal government. https://www.whitehouse.gov/briefing-room/presidential-\\nactions/2023/02/16/executive-order-on-further-advancing-racial-equity  \\n10 U.S. Department of Education, Office of Educational Technology (2022). Advancing digital equity for all: Community-\\nbased recommendations for developing effective digital equity plans to close the digital divide and enable technology-\\nempowered learning. US Department of Education.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 11, 'page_label': '12', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='8 \\n“the condition in which individuals and communities have the information technology capacity \\nthat is needed for full participation in the society and economy of the United States.” \\nIssues related to racial equity and unfair bias were at the heart of every listening session we held. \\nIn particular, we heard a conversation that was increasingly attuned to issues of data quality and \\nthe consequences of using poor or inappropriate data in AI systems for education. Datasets are \\nused to develop AI, and when they are non-representative or contain undesired associations or \\npatterns, resulting AI models may act unfairly in how they detect patterns or automate decisions. \\nSystematic, unwanted unfairness in how a computer detects patterns or automates decisions is \\ncalled “algorithmic bias.” Algorithmic bias could diminish equity at scale with unintended \\ndiscrimination. As this document discussed in the Formative Assessment section, this is not a new \\nconversation. For decades, constituents have rightly probed whether assessments are unbiased \\nand fair. Just as with assessments, whether an AI model exhibits algorithmic bias or is judged to \\nbe fair and trustworthy is critical as local school leaders make adoption decisions about using AI \\nto achieve their equity goals.  \\nWe highlight the concept of “algorithmic discrimination” in the Blueprint. Bias is intrinsic to \\nhow AI algorithms are developed using historical data, and it can be difficult to anticipate all \\nimpacts of biased data and algorithms during system design. The Department holds that biases \\nin AI algorithms must be addressed when they introduce or sustain unjust discriminatory \\npractices in education. For example, in postsecondary education, algorithms that make \\nenrollment decisions, identify students for early intervention, or flag possible student cheating \\non exams must be interrogated for evidence of unfair discriminatory bias—and not only when \\nsystems are designed, but also later, as systems become widely used. \\nFoundation 3: Ensure Safety, Ethics, and Effectiveness \\nA central safety argument in the Department’s policies is the need for data privacy and security \\nin the systems used by teachers, students, and others in educational institutions. The \\ndevelopment and deployment of AI requires access to detailed data. This data goes beyond \\nconventional student records (roster and gradebook information) to detailed information about \\nwhat students do as they learn with technology and what teachers do as they use technology to \\nteach. AI’s dependence on data requires renewed and strengthened attention to data privacy, \\nsecurity, and governance (as also indicated in the Blueprint). As AI models are not generally \\ndeveloped in consideration of educational usage or student privacy, the educational application \\nof these models may not be aligned with the educational institution’s efforts to comply with \\nfederal student privacy laws, such as FERPA, or state privacy laws.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 12, 'page_label': '13', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='9 \\nFigure 2: The Elementary and Secondary Education Act defines four levels of evidence.\\n \\nFurther, educational leaders are committed to basing their decisions about the adoption of \\neducational technology on evidence of effectiveness—a central foundation of the Department’s \\npolicy. For example, the requirement to base decisions on evidence also arises in the Elementary \\nand Secondary Education Act (ESEA), as amended, which introduced four tiers of evidence (see \\nFigure 2). Our nation’s research agencies, including the Institute of Education Sciences, are \\nessential to producing the needed evidence. The Blueprint calls for evidence of effectiveness, but \\nthe education sector is ahead of that game: we need to insist that AI-enhanced edtech rises to \\nmeet ESEA standards as well. \\nFoundation 4: Promote Transparency  \\nThe central role of complex AI models in a technology’s detection of patterns and \\nimplementation of automation is an important way in which AI-enabled applications, products, \\nand services will be different from conventional edtech. The Blueprint introduces the need for \\ntransparency about AI models in terms of disclosure (“notice”) and explanation. In education, \\ndecision makers will need more than notice—they will need to understand how AI models work \\nin a range of general educational use cases, so they can better anticipate limitations, problems, \\nand risks.  \\nAI models in edtech will be approximations of reality and, thus, constituents can always ask these \\nquestions: How precise are the AI models? Do they accurately capture what is most important? \\nHow well do the recommendations made by an AI model fit educational goals? What are the \\nbroader implications of using AI models at scale in educational processes?  \\nBuilding on what was heard from constituents, the sections of this report develop the theme of \\nevaluating the quality of AI systems and tools using multiple dimensions as follows: \\n● About AI: AI systems and tools must respect data privacy and security. Humans must be \\nin the loop. \\n● Learning: AI systems and tools must align to our collective vision for high-quality \\nlearning, including equity. \\n● Teaching: AI systems and tools must be inspectable, explainable, and provide human \\nalternatives to AI-based suggestions; educators will need support to exercise professional \\njudgment and override AI models, when necessary.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 13, 'page_label': '14', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='10 \\n● Formative Assessment: AI systems and tools must minimize bias, promote fairness, and \\navoid additional testing time and burden for students and teachers. \\n● Research and Development: AI systems and tools must account for the context of \\nteaching and learning and must work well in educational practice, given variability in \\nstudents, teachers, and settings. \\n● Recommendations: Use of AI systems and tools must be safe and effective for students. \\nThey must include algorithmic discrimination protections, protect data privacy, provide \\nnotice and explanation, and provide a recourse to humans when problems arise. The \\npeople most affected by the use of AI in education must be part of the development of \\nthe AI model, system, or tool, even if this slows the pace of adoption. \\n \\nWe return to the idea that these considerations fit together in a comprehensive perspective on \\nthe quality of AI models in the Recommendations section. \\nOverview of Document \\nWe begin in the next section by elaborating a definition of AI, followed by addressing learning, \\nteaching, assessment, and research and development. Organizing key insights by these topics \\nkeeps us focused on exploring implications for improving educational opportunity and \\noutcomes for students throughout the report. \\nWithin these topics, three important themes are explored: \\n1. Opportunities and Risks. Policies should focus on the most valuable educational \\nadvances while mitigating risks. \\n2. Trust and Trustworthiness. Trust and safeguarding are particularly important in \\neducation because we have an obligation to keep students out of harm’s way and \\nsafeguard their learning experiences.  \\n3. Quality of AI Models. The process of developing and then applying a model is at the \\nheart of any AI system. Policies need to support evaluation of the qualities of AI models \\nand their alignment to goals for teaching and learning during the processes of \\neducational adoption and use. \\n“AI in education can only grow at the speed of trust.” \\n—Dr. Dale Allen'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 14, 'page_label': '15', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='11 \\nWhat is AI? \\nOur preliminary definition of AI as automation based on associations requires elaboration. \\nBelow we address three additional perspectives on what constitutes AI. Educators will find these \\ndifferent perspectives arise in the marketing of AI functionality and are important to understand \\nwhen evaluating edtech systems that incorporate AI. One useful glossary of AI for Education \\nterms is the CIRCLS Glossary of Artificial Intelligence Terms for Educators.11  \\nAI is not one thing but an umbrella term for a growing set of modeling capabilities, as visualized \\nin Figure 3. \\nFigure 3: Components, types, and subfields of AI based on Regona et al (2022).12  \\n \\n \\n11 Search for “AI Glossary Educators” to find other useful definitions. \\n12 Regona, Massimo & Yigitcanlar, Tan & Xia, Bo & Li, R.Y.M. (2022). Opportunities and adoption challenges of AI in the \\nconstruction industry: A PRISMA review. Journal of Open Innovation Technology Market and Complexity, 8(45). \\nhttps://doi.org/10.3390/joitmc8010045'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 15, 'page_label': '16', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='12 \\nPerspective: Human-Like Reasoning \\n“The theory and development of computer systems able to perform tasks \\nnormally requiring human intelligence such as, visual perception, speech \\nrecognition, learning, decision-making, and natural language  \\nprocessing.” 13 \\nBroad cultural awareness of AI may be traced to the landmark 1968 film “2001: A Space \\nOdyssey”—in which the “Heuristically-programmed ALgorithmic” computer, or “HAL,” \\nconverses with astronaut Frank. HAL helps Frank pilot the journey through space, a job that \\nFrank could not do on his own. However, Frank eventually goes outside the spacecraft, HAL \\ntakes over control, and this does not end well for Frank. HAL exhibits human-like behaviors, \\nsuch as reasoning, talking, and acting. Like all applications of AI, HAL can help humans but also \\nintroduces unanticipated risks—especially since AI reasons in different ways and with different \\nlimitations than people do. \\nThe idea of “human-like” is helpful because it can be a shorthand for the idea that computers \\nnow have capabilities that are very different from the capabilities of early edtech applications. \\nEducational applications will be able to converse with students and teachers, co-pilot how \\nactivities unfold in classrooms, and take actions that impact students and teachers more broadly. \\nThere will be both opportunities to do things much better than we do today and risks that must \\nbe anticipated and addressed. \\nThe “human-like” shorthand is not always useful, however, because AI processes information \\ndifferently from how people process information. When we gloss over the differences between \\npeople and computers, we may frame policies for AI in education that miss the mark. \\nPerspective: An Algorithm that Pursues a Goal \\n“Any computational method that is made to act independently towards a \\ngoal based on inferences from theory or patterns in data.” 14 \\nThis second definition emphasizes that AI systems and tools identify patterns and choose actions \\nto achieve a given goal. These pattern recognition capabilities and automated recommendations \\nwill be used in ways that impact the educational process, including student learning and teacher \\ninstructional decision making. For example, today’s personalized learning systems may \\nrecognize signs that a student is struggling and may recommend an alternative instructional \\nsequence. The scope of pattern recognition and automated recommendations will expand. \\n \\n13 IEEE-USA Board of Directors. (February 10, 2017). Artificial intelligence research, development and regulation. IEEE \\nhttp://globalpolicy.ieee.org/wp-content/uploads/2017/10/IEEE17003.pdf \\n14 Friedman, L., Blair Black, N., Walker, E., & Roschelle, J. (November 8, 2021) Safe AI in education needs you. Association of \\nComputing Machinery blog, https://cacm.acm.org/blogs/blog-cacm/256657-safe-ai-in-education-needs-you/fulltext'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 16, 'page_label': '17', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='13 \\nCorrespondingly, humans must determine the types and degree of responsibility we will grant to \\ntechnology within educational processes, which is not a new dilemma.  \\nFor decades, the lines between the role of teachers and computers have been discussed in \\neducation, for example, in debates using terms such as “’computer-aided instruction,” “blended \\ninstruction,” and “personalized learning.” Yet, how are instructional choices made in systems that \\ninclude both humans and algorithms? Today, AI systems and tools are already enabling the \\nadaptation of instructional sequences to student needs to give students feedback and hints, for \\nexample, during mathematics problem solving or foreign language learning. This discussion \\nabout the use of AI in classroom pedagogy and student learning will be renewed and intensify as \\nAI-enabled systems and tools advance in capability and become more ubiquitous. \\nLet’s start with another simple example. When a teacher says, “Display a map of ancient Greece \\non the classroom screen,” an AI system may choose among hundreds of maps by noting the \\nlesson objectives, what has worked well in similar classrooms, or which maps have desirable \\nfeatures for student learning. In this case, when an AI system suggests an instructional resource \\nor provides a choice among a few options, the instructor may save time and may focus on more \\nimportant goals. However, there are also forms of AI-enabled automation that the classroom \\ninstructor may reject, for example, enabling an AI system or tool to select the most appropriate \\nand relevant readings for students associated with a historical event. In this case, an educator \\nmay choose not to utilize AI-enabled systems or tools given the risk of AI creating false facts \\n(“hallucinating”) or steering students toward inaccurate depictions of historical events found on \\nthe internet. Educators will be weighing benefits and risks like these daily. \\nComputers process theory and data differently than humans. AI’s success depends on \\nassociations or relationships found in the data provided to an algorithm during the AI model \\ndevelopment process. Although some associations may be useful, others may be biased or \\ninappropriate. Finding bad associations in data is a major risk, possibly leading to algorithmic \\ndiscrimination. Every guardian is familiar with the problem: A person or computer may say, \\n“Our data suggests your student should be placed in this class,” and the guardian may well argue, \\n“No, you are using the wrong data. I know my child better, and they should instead be placed in \\nanother class.” This problem is not limited exclusively to AI systems and tools, but the use of AI \\nmodels can amplify the problem when a computer uses data to make a recommendation because \\nit may appear to be more objective and authoritative, even if it is not. \\nAlthough this perspective can be useful, it can be misleading. A human view of agency, pursuing \\ngoals, and reasoning includes our human abilities to make sense of multiple contexts. For \\nexample, a teacher may see three students each make the same mathematical error but recognize \\nthat one student has an Individualized Education Program to address vision issues, another \\nmisunderstands a mathematical concept, and a third just experienced a frustrating interaction on \\nthe playground; the same instructional decision is therefore not appropriate. However, AI \\nsystems often lack data and judgement to appropriately include context as they detect patterns \\nand automate decisions. Further, case studies show that technology has the potential to quickly \\nderail from safe to unsafe or from effective to ineffective when the context shifts even slightly. \\nFor this and other reasons, people must be involved in goal setting, pattern analysis, and \\ndecision-making.15 \\n \\n15 Russell, S. (2019). Human compatible: Artificial intelligence and the problem of control. Viking. ISBN 978-0-525-55861-3.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 17, 'page_label': '18', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='14 \\nPerspective: Intelligence Augmentation \\n“Augmented intelligence is a design pattern for a human-centered \\npartnership model of people and artificial intelligence (AI) working \\ntogether to enhance cognitive performance, including learning, decision \\nmaking, and new experiences.” 16 \\nFoundation #1 (above) keeps humans in the loop and positions AI systems and tools to support \\nhuman reasoning. “Intelligence Augmentation” (IA)17 centers “intelligence” and “decision \\nmaking” in humans but recognizes that people sometimes are overburdened and benefit from \\nassistive tools. AI may help teachers make better decisions because computers notice patterns \\nthat teachers can miss. For example, when a teacher and student agree that the student needs \\nreminders, an AI system may provide reminders in whatever form a student likes without \\nadding to the teacher’s workload. Intelligence Automation (IA) uses the same basic capabilities of \\nAI, employing associations in data to notice patterns, and, through automation, takes actions \\nbased on those patterns. However, IA squarely focuses on helping people in human activities of \\nteaching and learning, whereas AI tends to focus attention on what computers can do. \\nDefinition of “Model” \\nThe above perspectives open a door to making sense of AI. Yet, to assess AI meaningfully, \\nconstituents must consider specific models and how they are developed. In everyday usage, the \\nterm “model” has multiple definitions. We clarify our intended meaning, which is a meaning \\nsimilar to “mathematical model,” below. (Conversely, note that “model” as used in “AI model” is \\nunlike the usage in “model school” or “instructional model” as AI model is not a singular case \\ncreated by experts to serve as an exemplar.) \\nAI models are like financial models: an approximation of reality that is useful for identifying \\npatterns, making predictions, or analyzing alternative decisions. In a typical middle school math \\ncurriculum, students use a mathematical model to analyze which of two cell phone plans is \\nbetter. Financial planners use this type of model to provide guidance on a retirement portfolio. \\nAt its heart, AI is a highly advanced mathematical toolkit for building and using models. Indeed, \\nin well-known chatbots, complex essays are written one word at a time. The underlying AI model \\npredicts which next words would likely follow the text written so far; AI chatbots use a very large \\nstatistical model to add one likely word at a time, thereby writing surprisingly coherent essays. \\nWhen we ask about the model at the heart of AI, we begin to get answers about “what aspects of \\nreality does the model approximate well?” and “how appropriate is it to the decision to be made?” \\nOne could similarly ask about algorithms—the specific decision-making processes that an AI \\nmodel uses to go from inputs to outputs. One could also ask about the quality of the data used to \\nbuild the model—for example, how representative is that data? Switching among three terms—\\n \\n16 Gartner (n.d.) Gartner glossary: Augmented intelligence. Gartner. https://www.gartner.com/en/information-\\ntechnology/glossary/augmented-intelligence \\n17 Englebart, D.C. (October 1962). Augmenting human intellect: A conceptual framework. SRI Summary Report AFOSR-\\n3223. https://www.dougengelbart.org/pubs/augment-3906.html'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 18, 'page_label': '19', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"15 \\nmodels, algorithms, and data—will become confusing. Because the terms are closely related, \\nwe’ve chosen to focus on the concept of AI models. We want to bring to the fore the idea that \\nevery AI model is incomplete, and it's important to know how well the AI model fits the reality \\nwe care about, where the model will break down, and how. \\nSometimes people avoid talking about the specifics of models to create a mystique. Talking as \\nthough AI is unbounded in its potential capabilities and a nearly perfect approximation to reality \\ncan convey an excitement about the possibilities of the future. The future, however, can be \\noversold. Similarly, sometimes people stop calling a model AI when its use becomes \\ncommonplace, yet such systems are still AI models with all of the risks discussed here. We need \\nto know exactly when and where AI models fail to align to visions for teaching and learning. \\nInsight: AI Systems Enable New Forms of Interaction \\nAI models allow computational processes to make recommendations or plans and also enable \\nthem to support forms of interaction that are more natural, such as speaking to an assistant. AI-\\nenabled educational systems will be desirable in part due to their ability to support more natural \\ninteractions during teaching and learning. In classic edtech platforms, the ways in which teachers \\nand students interact with edtech are limited. Teachers and students may choose items from a \\nmenu or in a multiple-choice question. They may type short answers. They may drag objects on \\nthe screen or use touch gestures. The computer provides outputs to students and teachers \\nthrough text, graphics, and multimedia. Although these forms of inputs and outputs are versatile, \\nno one would mistake this style of interaction with the way two people interact with one another; \\nit is specific to human-computer interaction. With AI, interactions with computers are likely to \\nbecome more like human-to-human interactions (see Figure 4). A teacher may speak to an AI \\nassistant, and it may speak back. A student may make a drawing, and the computer may highlight \\na portion of the drawing. A teacher or student may start to write something, and the computer \\nmay finish their sentence—as when today’s email programs can complete thoughts faster than \\nwe can type them. \\nAdditionally, the possibilities for automated actions that can be executed by AI tools are \\nexpanding. Current personalization tools may automatically adjust the sequence, pace, hints, or \\ntrajectory through learning experiences.18 Actions in the future might look like an AI system or \\ntool that helps a student with homework19 or a teaching assistant that reduces a teacher’s \\nworkload by recommending lesson plans that fit a teacher’s needs and are similar to lesson plans \\na teacher previously liked.20 Further, an AI-enabled assistant may appear as an additional \\n“partner” in a small group of students who are working together on a collaborative assignment.21 \\nAn AI-enabled tool may also help teachers with complex classroom routines.22 For example, a \\n \\n18 Shemshack, A., Spector, J.M. (2020) A systematic literature review of personalized learning terms. Smart Learning \\nEnvironments, 7(33). https://doi.org/10.1186/s40561-020-00140-9 \\n19 Roschelle, J., Feng, M., Murphy, R. & Mason, C.A. (2016). Online mathematics homework increases student achievement. \\nAERA Open, 2(4), 1-12. DOI: 10.1177/2332858416673968 \\n20 Celik, I., Dindar, M., Muukkonen, H. & Järvelä, S. (2022). The promises and challenges of artificial intelligence for \\nteachers: A systematic review of research. TechTrends, 66, 616–630. https://doi.org/10.1007/s11528-022-00715-y \\n21 Chen, C., Park, H.W. & Breazeal, C. (2020). Teaching and learning with children: Impact of reciprocal peer learning with \\na social robot on children’s learning and emotive engagement. Computers & Education, 150, \\nhttps://doi.org/10.1016/j.compedu.2020.103836 \\n22 Holstein, K., McLaren, B.M., & Aleven, V. (2019). Co-designing a real-time classroom orchestration tool to support \\nteacher–AI complementarity. Journal of Learning Analytics, 6(2). https://doi.org/10.18608/jla.2019.62.3\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 19, 'page_label': '20', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='16 \\ntool may help teachers with orchestrating23 the movement of students from a full class discussion \\ninto small groups and making sure each group has the materials needed to start their work. \\nFigure 4. Differences that teachers and students may experience in future technologies. \\n \\nKey Recommendation: Human in the Loop AI \\nMany have experienced a moment where technology surprised them with an uncanny ability to \\nrecommend what feels like a precisely personalized product, song, or even phrase to complete a \\nsentence in a word processor such as the one being used to draft this document. Throughout this \\nsupplement, we talk about specific, focused applications where AI systems may bring value (or \\nrisks) into education. At no point do we intend to imply that AI can replace a teacher, a guardian, \\nor an educational leader as the custodian of their students’ learning. We talk about the limitations \\nof models in AI and the conversations that educational constituents need to have about what \\nqualities they want AI models to have and how they should be used. \\n“We can use AI to study the diversity, the multiplicity of effective learning \\napproaches and think about the various models to help us get a broader \\nunderstanding of what effective, meaningful engagement might look like \\nacross a variety of different contexts.” \\n—Dr. Marcelo Aaron Bonilla Worsley \\n \\n \\n23 Roschelle, J., Dimitriadis, Y. & Hoppe, U. (2013). Classroom orchestration: Synthesis. Computers & Education, 69, 512-526. \\nhttps://doi.org/10.1016/j.compedu.2013.04.010'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 20, 'page_label': '21', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='17 \\nThese limitations lead to our first recommendation: that we pursue a vision of AI where humans \\nare in the loop. That means that people are part of the process of noticing patterns in an \\neducational system and assigning meaning to those patterns. It also means that teachers remain \\nat the helm of major instructional decisions. It means that formative assessments involve teacher \\ninput and decision making, too. One loop is the cycle of recognizing patterns in what students do \\nand selecting next steps or resources that could support their learning. Other loops involve \\nteachers planning and reflecting on lessons. Response to Intervention is another well-known \\ntype of loop.  \\nThe idea of humans in the loop is part of our broader discussions happening about AI and \\nsociety, not just AI in education. Interested readers could look for more on human-centered AI, \\nresponsible AI, value-sensitive AI, AI for social good, and other similar terms that ally with \\nhumans in the loop, such as “human-centered AI.” \\nExercising judgement and control in the use of AI systems and tools is an essential part of \\nproviding the best opportunity to learn for all students—especially when educational decisions \\ncarry consequence. AI does not have the broad qualities of contextual judgment that people do. \\nTherefore, people must remain responsible for the health and safety of our children, for all \\nstudents’ educational success and preparation for their futures, and for creating a more equitable \\nand just society.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 21, 'page_label': '22', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='18 \\nLearning \\nThe Department’s long-standing edtech vision sees students as active learners; students \\nparticipate in discussions that advance their understanding, use visualizations and simulations to \\nexplain concepts as they relate to the real world, and leverage helpful scaffolding and timely \\nfeedback as they learn. Constituents want technology to align to and build on these and other \\nresearch-based understandings of how people learn. Educators can draw upon two books titled \\nHow People Learn and How People Learn II by the National Academies of Sciences, Engineering, \\nand Medicine for a broad synthesis of what we know about learning.24 As we shape AI-enhanced \\nedtech around research-based principles, a key goal must be to strengthen and support learning \\nfor those who have experienced unfavorable circumstances for learning, such as caused by the \\nCOVID-19 pandemic or by broader inequities. And we must keep a firm eye toward the forms of \\nlearning that will most benefit learners in their future lives in communities and workplaces. \\nExamples of AI supporting learning principles in this section include the following: AI-based \\ntutoring for students as they solve math problems (based on cognitive learning theories), \\nadapting to learners with special needs (based on the Universal Design for Learning framework \\nand related theories), and AI support for effective student teamwork (based on theories in the \\nfield called “Computer Supported Collaborative Learning”). \\nInsight: AI Enables Adaptivity in Learning \\nAdaptivity has been recognized as a key way in which technology can improve learning.25 AI can \\nbe a toolset for improving the adaptivity of edtech. AI may improve a technology’s ability to \\nmeet students where they are, build on their strengths, and grow their knowledge and skills. \\nBecause of AI’s powers of work with natural forms of input and the foundational strengths of AI \\nmodels (as discussed in the What is AI? section), AI can be an especially strong toolkit for \\nexpanding the adaptivity provided to students. \\nAnd yet, especially with AI, adaptivity is always more specific and limited than what a broad \\nphrase like “meet students where they are” might suggest. Core limits arise from the nature of \\nthe model at the heart of any specific AI-enabled system. Models are approximations of reality. \\nWhen important parts of human learning are left out of the model or less fully developed, the \\nresulting adaptivity will also be limited, and the resulting supports for learning may be brittle or \\nnarrow. Consequently, this section on Learning focuses on one key concept: Work toward AI \\nmodels that fit the fullness of visions for learning—and avoid limiting learning to what AI can \\ncurrently model well. \\nAI models are demonstrating greater skills because of advances in what are called “large language \\nmodels” or sometimes “foundational models.” These very general models still have limits. For \\nexample, generative AI models discussed in the mainstream news can quickly generate \\nconvincing essays about a wide variety of topics while other models can draw credible images \\nbased on just a few prompts. Despite the excitement about foundational models, experts in our \\n \\n24 National Research Council. 2000. How people learn: Brain, mind, experience, and school. The National Academies Press. \\nhttps://doi.org/10.17226/9853; National Academies of Sciences, Engineering, and Medicine. 2018. How people learn II: \\nLearners, contexts, and cultures. The National Academies Press. https://doi.org/10.17226/24783 \\n25 Aleven, V., McLaughlin, E. A., Glenn, R. A., & Koedinger, K. R. (2016). Instruction based on adaptive learning \\ntechnologies. In Mayer, R.E. & Alexander, P.A., Handbook of research on learning and instruction, 522-560. ISBN: 113883176X'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 22, 'page_label': '23', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='19 \\nlistening sessions warned that AI models are narrower than visions for human learning and that \\ndesigning learning environments with these limits in mind remains very important. The models \\nare also brittle and can’t perform well when contexts change. In addition, they don’t have the \\nsame “common sense” judgment that people have, often responding in ways that are unnatural \\nor incorrect.26 Given the unexpected ways in which foundational models miss the mark, keeping \\nhumans in the loop remains highly important. \\nIntelligent Tutoring Systems: An Example of AI Models \\nOne long-standing type of AI-enabled technology is an Intelligent Tutoring System (ITS).27 In an \\nearly success, scientists were able to build accurate models of how human experts solve \\nmathematical problems. The resulting model was incorporated into a system that would observe \\nstudent problem solving as they worked on mathematical problems on a computer. Researchers \\nwho studied human tutors found that feedback on specific steps (and not just right or wrong \\nsolutions) is a likely key to why tutoring is so effective.28 For example, when a student diverged \\nfrom the expert model, the system gave feedback to help the student get back on track.29 \\nImportantly, this feedback went beyond right or wrong, and instead, the model was able to \\nprovide feedback on specific steps of a solution process. A significant advancement of AI, \\ntherefore, can be its ability to provide adaptivity at the step-by-step level and its ability to do so \\nat scale with modest cost. \\nAs a research and development (R&D) field emerged to advance ITS, the work has gone beyond \\nmathematics problems to additional important issues beyond step-by-step problem solving. In \\nthe early work, some limitations can be observed. The kinds of problems that an ITS could \\nsupport were logical or mathematical, and they were closed tasks, with clear expectations for \\nwhat a solution and solution process should look like. Also, the “approximation of reality” in \\nearly AI models related to cognition and not to other elements of human learning, for example, \\nsocial or motivational aspects. Over time, these early limitations have been addressed in two \\nways: by expanding the AI models and by involving humans in the loop, a perspective that is also \\nimportant now. Today, for example, if an ITS specializes in feedback as a student practices, a \\nhuman teacher could still be responsible for motivating student engagement and self-regulation \\nalong with other aspects of instruction. In other contemporary examples, the computer ITS \\nmight focus on problem solving practice, while teachers work with students in small groups. \\nFurther, students can be in the loop with AI, as is the case with “open learner models”—a type of \\nAI-enabled system that provides information to support student self-monitoring and \\nreflection.30 \\n \\n26 Dieterle, E., Dede, C. & Walker, M. (2022). The cyclical ethical effects of using artificial intelligence in education. AI & \\nSociety. https://link.springer.com/article/10.1007/s00146-022-01497-w \\n27 Mousavinasab, E., Zarifsanaiey, N., R. Niakan Kalhori, S., Rakhshan, M., Keikha, L., & Ghazi Saeedi, M. (2021). Intelligent \\ntutoring systems: A systematic review of characteristics, applications, and evaluation methods. Interactive Learning \\nEnvironments, 29(1), 142–163. https://psycnet.apa.org/doi/10.1080/10494820.2018.1558257 \\n28 Van Lehn, K. (2011) The relative effectiveness of human tutoring, intelligent tutoring systems, and other tutoring \\nsystems. Educational Psychologist, 46(4), 197-221. https://doi.org/10.1080/00461520.2011.611369 \\n29 Ritter, S., Anderson, J.R., Koedinger, K.R. & Corbett, A. (2007). Cognitive Tutor: Applied research in mathematics \\neducation. Psychonomic Bulletin & Review, 14, 249–255/ https://doi.org/10.3758/BF03194060 \\n30 Winne, P.H. (2021). Open learner models working in symbiosis with self-regulating learners: A research agenda. \\nInternational Journal of Artificial Intelligence in Education, 31(3), 446-459. https://doi.org/10.1007/s40593-020-00212-4'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 23, 'page_label': '24', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"20 \\nAlthough R&D along the lines of an ITS should not limit the view of what’s possible, such an \\nexample is useful because so much research and evaluation has been done on the ITS approach. \\nResearchers have looked across all the available high-quality studies in a meta-analysis and \\nconcluded that ITS approaches are effective.31 Right now, many school systems are looking at \\nhigh-intensity human tutoring to help students with unfinished learning. Human tutoring is very \\nexpensive, and it is hard to find enough high-quality human tutors. With regard to large-scale \\nneeds, if it is possible for an ITS to supplement what human tutors do, it might be possible to \\nextend beyond the amount of tutoring that people can provide to students.  \\nImportant Directions for Expanding AI-Based Adaptivity \\nAdaptivity is sometimes referred to as “personalization.” Although this is a convenient term, \\nmany observers have noted how imprecise it is.32 For some educators, personalization means \\ngiving learners “voice and choice,” and for others it means that a learning management system \\nrecommends an individual “playlist” of activities to each student. Hidden in that imprecision is \\nthe reality that many edtech products that personalize do so in limited ways. Adjusting the \\ndifficulty and the order of lesson materials are among the two most common ways that edtech \\nproducts adapt. And yet, any teacher knows there is more to supporting learning than adjusting \\nthe difficulty and sequence of materials. For example, a good teacher can find ways to engage a \\nstudent by connecting to their own past experiences and can shape explanations until they really \\nconnect in an “aha!” moment for that student. When we say, “meet the learner where they are,” \\nhuman teachers bring a much more complete picture of each learner than most available edtech. \\nThe teacher is also not likely to “over personalize” (by performing like an algorithm that only \\npresents material for which the learner has expressed interest), thereby limiting the student’s \\nexposure to new topics. The nature of “teachable moments” that a human teacher can grasp is \\nbroader than the teachable moments today’s AI models grasp. \\nIn our listening sessions, we heard many ways in which the core models in an AI system must be \\nexpanded. We discuss these below. \\n1. From deficit-based to asset-oriented. Listening session attendees noted that the rhetoric \\naround adaptivity has often been deficit-based; technology tries to pinpoint what a \\nstudent is lacking and then provides instruction to fill that specific gap. Teachers also \\norient to students' strengths; they find competencies or “assets” a student has and use \\nthose to build up the students’ knowledge. AI models cannot be fully equitable while \\nfailing to recognize or build upon each student’s sources of competency. AI models that \\nare more asset-oriented would be an advance.  \\n2. From individual cognition to including social and other aspects of learning. The \\nexisting adaptivity rhetoric has also tended to focus on individualized learning and \\nmostly on cognitive elements of learning, with motivational and other elements only \\nbrought in to support the cognitive learning goals. Attendees observe that their vision for \\nlearning is broader than cognition. Social learning is important, for example, especially \\n \\n31 Kulik, J.A., & Fletcher, J.D. (2016). Effectiveness of intelligent tutoring systems: A meta-analytic review. Review of \\nEducational Research, 86(1), 42–78; Ma, W., Adescope, O.O, Nesbit, J.C. & Liu, Q. (2014). Intelligent tutoring systems and \\nlearning outcomes: A meta-analysis. Journal of Educational Psychology, 106(4), 901–918. http://dx.doi.org/10.1037/a0037123 \\n32 Plass, J.L., & Pawar, S. (2020). Toward a taxonomy of adaptivity for learning. Journal of Research on Technology in \\nEducation, 52(3), 275–300. https://doi.org/10.1080/15391523.2020.1719943;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 24, 'page_label': '25', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"21 \\nfor students to learn to reason, explain, and justify. For students who are learning English, \\ncustomized and adaptive support for improving language skills while learning curricular \\ncontent is clearly important. Developing self-regulation skills is also important. A modern \\nvision of learning is not individualistic; it recognizes that students learn in groups and \\ncommunities too.  \\n3. From neurotypical to neurodiverse learners. AI models could help in including \\nneurodiverse learners (students who access, process, and interact with the world in less \\ncommon ways than “neurotypical” students) who could benefit from different learning \\npaths and from forms of display and input that fit their strengths. Constituents want AI \\nmodels that can support learning for neurodiverse learners and learners with disabilities. \\nThus, they want AI models that can work with multiple paths to learning and multiple \\nmodalities of interaction. Such models should be tested for efficacy, to guard against the \\npossibility that some students could be assigned a “personalized” but inadequate learning \\nresource. In addition, some systems for neurodiverse students are presently \\nunderutilized, so designs that support intended use will also be important. \\n4. From fixed tasks to active, open, and creative tasks. As mentioned above, AI models are \\nhistorically better at closed tasks like solving a math problem or logical tasks like playing \\na game. In terms of life-wide and lifelong opportunities, we value learning how to \\nsucceed at open-ended and creative tasks that require extended engagement from the \\nlearner, and these are often not purely mathematical or logical. We want students to learn \\nto invent and create innovative approaches. We want AI models that enable progress on \\nopen, creative tasks. \\n5. From correct answers to additional goals. At the heart of many adaptivity approaches \\nnow on the market, the model inside the technology counts students' wrong answers and \\ndecides whether to speed up, slow down, or offer a different type of learning support. Yet, \\nright and wrong answers are not the only learning goals. We want students to learn how \\nto self-regulate when they experience difficulties in learning, for example, such as being \\nable to persist in working on a difficult problem or knowing how and when to ask for \\nhelp. We want learners to become skilled in teamwork and in leading teams. As students \\ngrow, we want them to develop more agency and to be able to act on their own to \\nadvance toward their own learning goals.  \\nListing every dimension of expansion that we heard in our listening sessions is beyond the scope \\nof this report. Some additional dimensions are presented in the following sections on Teaching, \\nAssessment, and Research. For example, in Research, we discuss all the ways in which AI systems \\nhave trouble with context—context that humans readily grasp and consider.  \\nOverall, constituents in the listening sessions realized we need an ambitious outlook on learning \\nto respond to the future today’s learners face. Constituents were concerned about ways in which \\nAI might narrow learning. For example, if the incorporation of AI into education slowed \\nattention to students’ skills on creative, open-ended tasks and their ability to lead and collaborate \\nin teams, then school districts may be less able to realize their students’ progress in relation to a \\nPortrait of a Graduate who excels in communication and other skills valued in communities and \\ncareers.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 25, 'page_label': '26', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"22 \\nConstituents reminded us that as we conceptualize what we want AI in edtech to accomplish, we \\nmust start and constantly revisit a human-centered vision of learning. \\nA Duality: Learning With and About AI \\nAs AI is brought into schools, two broad perspectives about AI in education arise: (1) AI in support \\nof student learning; and (2) support for learning about AI and related technologies. So far, we’ve \\ndiscussed AI systems and tools to support student learning and mastery of subjects like \\nmathematics and writing. Yet, it is also important that students learn about AI, critically examine \\nits presence in education and society, and determine its role and value in their own lives and \\ncareers. We discuss risks across each section in this report. Here, it is important for students to \\nbecome more aware of and savvy to the risks of AI—including risks of bias and surveillance—as \\nthey appear in all elements of their lives. In the recent past, schools have supported students’ \\nunderstanding of cybersecurity, for example. AI will bring new risks, and students need to learn \\nabout them. \\nWe are encouraged by efforts we’ve seen underway that would give students opportunities to \\nlearn about how AI works while also giving them opportunities to discuss relevant topics like \\nprivacy and security.33 Other learning goals are noted in the K-12 Computer Science Framework. \\nWe’ve seen that students can begin learning about AI in elementary, middle, and high school. \\nThey can use AI to design simulations and products that they find exciting. And we’ve seen that \\nstudents want to talk about the ethics of products they experience in their everyday lives and \\nhave much to say about the kinds of products they’d like to see or not see in school. (And later, in \\nthe Research section, we note the desire for co-design processes that involve students in creating \\nthe next generation of AI-enabled edtech). Overall, it’s important to balance attention to using AI \\nto support learning and giving students opportunities to learn about AI. \\nA Challenge: Systems Thinking About AI in Education \\nAs AI expands into the educational system, our listening session attendees reminded us that it \\nwill be entering parts or locations of the system that are presently dysfunctional. AI is certainly \\nnot a fix for broken systems, and instead, must be used with even more care when the systems’ \\ncontext is unstable or uncertain.  \\n \\n33 Forsyth, S., Dalton, B., Foster, E.H., Walsh, B., Smilack, J., & Yeh, T. (2021, May). Imagine a more ethical AI: Using stories \\nto develop teens' awareness and understanding of artificial intelligence and its societal impacts. In 2021 Conference on \\nResearch in Equitable and Sustained Participation in Engineering, Computing, and Technology (RESPECT). IEEE. \\nhttps://doi.org/10.1109/RESPECT51740.2021.9620549; Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., & Breazeal, C. \\n(2022). Integrating ethics and career futures with technical learning to promote AI literacy for middle school students: An \\nexploratory study. International Journal of Artificial Intelligence in Education, 1–35. https://doi.org/10.1007/s40593-022-\\n00293-3\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 26, 'page_label': '27', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"23 \\n“First and foremost, they are getting deployed in educational contexts \\nthat are already fragmented and broken and unequal. Technology \\ndoesn't discriminate—we do. So, as we think about the application of \\nthese new systems, we have to really think about the contextual \\napplication of AI.”  \\n—Dr. Nicole Turner \\nAs discussed previously, because AI systems and tools do not fully align with goals for learning, \\nwe have to design educational settings to situate AI in the right place, where educators and other \\nadults can make effective use of these tools for teaching and learning. Within the ITS example, \\nwe saw that AI could make learning by practicing math problems more effective, and a whole \\ncurricular approach might include roles for teachers that emphasize mathematical practices like \\nargumentation and modeling. Further, small-group work is likely to remain important: Students \\nmight work in small groups to use mathematics to predict or justify as they work on responding \\nto a realistic challenge. At the present, one “right place” for people, and not AI, is understanding \\nhow learning can be culturally responsive and culturally sustaining, as AI is not even close to \\nbeing ready to connect learning to the unique strengths in a student’s community and family. \\nOpen Questions About AI for Learning \\nWith advances occurring in the foundations for AI, opportunities to use AI in support of learning \\nare rapidly expanding. As we explore these opportunities, the open questions below deserve \\nongoing attention: \\n● To what extent is AI enabling adaptation to students’ strengths and not just deficits? Is AI \\nenabling improved support for learners with disabilities and English language learners? \\n● How are youth voices involved in choosing and using AI for learning? \\n● Is AI leading to narrower student activities (e.g., procedural math problems), or the fuller \\nrange of activities highlighted in the National Educational Technology Plan (NETP), \\nwhich emphasizes features such as personalized learning, project-based learning, learning \\nfrom visualizations, simulations, and virtual reality, as well as learning across school, \\ncommunity, and familial settings? \\n● Is AI supporting the whole learner, including social dimensions of learning such as \\nenabling students to be active participants in small group and collaborative learning? For \\nexample, does AI contribute to aspects of student collaboration we value like shared \\nattention, mutual engagement, peer help, self-regulation, and building on each other’s \\ncontributions? \\n● When AI is used, are students’ privacy and data protected? Are students and their \\nguardians informed about what happens with their data? \\n● How strong are the processes or systems for monitoring student use of AI for barriers, \\nbias, or other undesirable consequences of AI use by learners? How are emergent issues \\naddressed? \\n● Is high-quality research or evaluations about the impacts of using the AI system for \\nstudent learning available? Do we know not only whether the system works but for whom \\nand under what conditions?\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 27, 'page_label': '28', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='24 \\nKey Recommendation: Seek AI Models Aligned to a Vision for Learning \\nWe’ve called attention to how advances in AI are important to adaptivity but also to ways in \\nwhich adaptivity is limited by the model’s inherent quality. We noted that a prior wave of edtech \\nused the term “personalized” in differing ways, and it was often important to clarify what \\npersonalization meant for a particular product or service. Thus, our key recommendation is to \\ntease out the strengths and limitations of AI models inside forthcoming edtech products and to \\nfocus on AI models that align closely to desired visions of learning. AI is now advancing rapidly, \\nand we should differentiate between products that have simple AI-like features inside and \\nproducts that have more sophisticated AI models.  \\nLooking at what’s happening in research and development, we can see significant effort and push \\ntoward overcoming these limitations. We noted that decision makers need to be careful about \\nselecting AI models that might narrow their vision for learning, as general artificial intelligence \\ndoes not exist. And because AI models will always be narrower than real world experience, we \\nneed to proceed with systems thinking in which humans are in the loop, with the strengths and \\nweaknesses of the specific educational system considered. We hold that the full system for \\nlearning is broader than its AI component.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 28, 'page_label': '29', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='25 \\nTeaching \\nTeachers have long envisioned many things that technology could make possible for teachers, \\ntheir classrooms, and their students but not the changes wrought by the recent pandemic. Today, \\nnearly all teachers have experienced uses of technologies for instruction that no one anticipated. \\nSome of those experiences were positive, and others were not. All of the experiences provide an \\nimportant context as we think further about teaching and technology. \\nThere is a critical need to focus on addressing the challenges teachers experience. It must \\nbecome easier for teachers to do the amazing work they always do. We must also remember why \\npeople choose the teaching profession and ensure they can do the work that matters. This \\nsection discusses examples of AI supporting teachers and teaching including these concepts: AI \\nassistants to reduce routine teaching burdens; AI that provides teachers with recommendations \\nfor their students’ needs and extends their work with students; and AI that helps teachers to \\nreflect, plan, and improve their practice. \\n“One opportunity I see with AI is being able to reduce the amount of \\nattention I have to give to administrative things and increase the amount \\nof attention I can give to my students with their learning needs in the \\nclassroom. So that\\'s the first one that I\\'d say that I\\'m super excited about \\nthe possibility of AI to support me as a teacher.\"  \\n—Vidula Plante \\nAlways Center Educators in Instructional Loops \\nTo succeed with AI as an enhancement to learning and teaching, we need to always center \\neducators (ACE). Practically speaking, practicing “ACE in AI” means keeping a humanistic view of \\nteaching front and center. ACE leads the Department to confidently respond “no” when asked \\n“will AI replace teachers?” ACE is not just about making teachers’ jobs easier but also making it \\npossible to do what most teachers want to do. That includes, for example, understanding their \\nstudents more deeply and having more time to respond in creative ways to teachable moments. \\nTo bring more precision to how and where we should center educators, we return to our \\nadvocacy for human in the loop AI and ask, what are the loops in which teachers should be \\ncentered? Figure 5 suggests three key loops (inspired by research on adaptivity loops34): \\n  \\n \\n34 Aleven, V., McLaughlin, E.A., Glenn, R.A., & Koedinger, K.R. (2016). Instruction based on adaptive learning technologies. \\nIn Mayer, R.E. & Alexander, P.A., Handbook of research on learning and instruction, 522-560. ISBN: 113883176X'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 29, 'page_label': '30', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='26 \\n \\n1. The loop in which teachers make moment-to-moment decisions as they do the \\nimmediate work of teaching.  \\n2. The loop in which teachers prepare for, plan, and reflect on teaching, which includes \\nprofessional development. \\n3. The loop in which teachers participate in decisions about the design of AI-enabled \\ntechnologies, participate in selecting the technologies, and shape the evaluation of \\ntechnologies—thus setting a context for not only their own classroom but those of fellow \\nteachers as well.  \\nFigure 5: Three ways to center educators as we conceptualize human in the loop AI  \\n \\n \\nPlease note that in the next section, on Formative Assessment, we also discuss teachers’ important \\nrole in feedback loops that support students and enable school improvement. That section also \\nincludes a discussion of the concepts of “bias” and “fairness,” which are important to teachers. \\nInsight: Using AI to Improve Teaching Jobs \\nThe job of teaching is notoriously complex, with teachers making thousands of decisions each \\nday. Teachers participate in classroom processes, in interactions with students beyond \\nclassrooms, in work with fellow teachers, and in administrative functions. They also are part of \\ntheir communities and thus are expected to interact with families and caregivers.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 30, 'page_label': '31', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='27 \\nIf the teacher is able to efficiently predict and understand the range of \\nother answers given by students in the class, it becomes possible to think \\ncreatively about the novel answer and figure how and why the student \\nmight have generated it.35 \\nWe think about how much easier some everyday tasks have become. We can request and receive \\nalerts and notifications about events. Selecting music that we want to hear used to be a multistep \\nprocess (even with digital music), and now we can speak the name of a song we want to hear, and \\nit plays. Likewise, mapping a journey used to require a cumbersome study of maps, but now cell \\nphones let us choose among several transportation options to reach a destination. Why can’t \\nteachers be supported to notice changing student needs and provided with supports to enact a \\ntechnology-rich lesson plan? Why can’t they more easily plan their students’ learning journeys? \\nWhen things change in a classroom, as they always do, why don’t the tools of the classroom make \\nit easier for teachers to adapt to student strengths and needs on the fly? \\nFigure 6: Teachers work about 50 hours a week, spending less than half the time in direct \\ninteraction with students. \\n \\n \\nA report by McKinsey36 first suggested that AI’s initial benefit could be to improve teaching jobs \\nby reducing low-level burdens in administrative or clerical work (Figure 6). The report also \\nsuggests that recovered time from AI-enabled technology should be rededicated toward more \\n \\n35 Hammerness, K., Darling-Hammond, L., & Bransford, J. (2005). Preparing teachers for a changing world: What teachers should \\nlearn and be able to do. Jossey-Bass. ISBN: 0787996343 \\n36 Bryant, J., Heitz,C., Sanghvi, S., & Wagle, D. (2020, January 14). How artificial intelligence will impact K-12 teachers. \\nMcKinsey. https://www.mckinsey.com/industries/education/our-insights/how-artificial-intelligence-will-impact-k-12-\\nteachers'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 31, 'page_label': '32', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"28 \\neffective instruction—particularly, outcomes such as reducing the average 11 hours of weekly \\npreparation down to only six. We highlight these opportunities and two others below. \\n1. Handling low-level details to ease teaching burdens and increase focus on students. A \\ngood teacher must master all levels of details, big and small. When working with a \\nparticular student, the teacher may wish to later send that student a helpful learning \\nresource. How will they remember to send it? A voice assistant or other forms of an AI \\nassistant could make it easier to stay organized by categorizing simple voice notes for \\nteachers to follow up on after a classroom session ends. We are beginning to see AI-\\nenabled voice assistants in the market, and they could do many simple tasks so that the \\nteachers can stay focused on students. These tasks can include record-keeping, starting \\nand stopping activities, controlling displays, speakers, and other technologies in the \\nclassroom, and providing reminders. Many workers may eventually use assistants to \\nmake their jobs easier, and teachers are the most deserving of efforts to ease their jobs \\nnow.  \\n2. Extending beyond the teacher's availability with their students but continuing to \\ndeliver on the teacher’s intent. Teachers almost always want to do more with each \\nstudent than they can, given the limited number of hours before the next school day. A \\nteacher may wish to sit with the student as they practice 10 more math problems, giving \\nthem ongoing support and feedback. If the teacher can sit with the student for only three \\nproblems, perhaps they could delegate to an AI-enabled learning system to help with the \\nrest. Teachers cannot be at their best if on call at all hours to help with homework, but \\nperhaps they can indicate what types of supports, hints, and feedback they want students \\nto receive while studying after school hours. An AI assistant can ensure that students have \\nthat support wherever and whenever they do homework or practice skills on their own. \\nTeachers may wish to provide more extensive personal notes to families/caregivers, and \\nperhaps an AI assistant could help with drafts based on students’ recent classroom work. \\nThen, the teacher could review the AI-generated comments and quickly edit where \\nneeded before returning it to the student for another draft. AI tools might also help \\nteachers with language translation so they can work with all parents and caregivers of \\ntheir students. AI tools might also help teachers with awareness. For example, in the next \\nsection, Formative Assessment, we note that teachers can’t always know what’s going on for \\neach student and in each small group of students; emerging products might signal to the \\nteacher when a student or teacher may need some more personal attention. \\n3. Making teacher professional development more productive and fruitful. Emerging \\nproducts already enable a teacher to record her classroom and allow an AI algorithm to \\nsuggest highlights of the classroom discussion worth reviewing with a professional \\ndevelopment coach.37 AI can compute metrics, such as whether students have been \\ntalking more or less, which are difficult for a teacher to calculate during a lesson.38 For \\n \\n37 Chen, G., Clarke, S., & Resnick, L.B. (2015). Classroom Discourse Analyzer (CDA): A discourse analytic tool for teachers. \\nTechnology, Instruction, Cognition and Learning, 10(2), 85-105 \\n38 Jensen, E., Dale, M., Donnelly, P.J., Stone, C., Kelly, S., Godley, A. & D'Mello, S.K. (2020). Toward automated feedback on \\nteacher discourse to enhance teacher learning. In Proceedings of the 2020 CHI Conference on Human Factors in \\nComputing Systems (CHI '20). https://doi.org/10.1145/3313831.3376418\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 32, 'page_label': '33', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='29 \\nteachers who want to increase student engagement, these metrics can be a valuable tool. \\nClassroom simulation tools are also emerging and can enable teachers to practice their \\nskills in realistic situations.39 Simulators can include examples of teaching from a real \\nclassroom while changing the faces and voices of the participants so that teaching \\nsituations can be shared and discussed among teachers without revealing identities.  \\nNote the emphasis above on what listening-session panelist Sarah Hampton said about the \\nhuman touch. Teachers will feel that AI is helping them teach with a focus on their human \\nconnection to their students when the necessary (but less meaningful) burdens of teaching are \\nlessened. In Figure 7, below, see concerns that teachers raised about AI during listening sessions. \\nFigure 7: Concerns raised during the listening session about teaching with AI \\n \\nPreparing and Supporting Teachers in Planning and Reflecting \\nACE also means preparing teachers to take advantage of possibilities like those listed above and \\nmore. In the Research section, we highlight how pre-service education still tends to \\ncompartmentalize and inadequately address the topic of technology. That section suggests a \\nneed to invest in research about how to deeply integrate technology in pre-service teacher \\ntraining programs. In-service teachers, too, will need professional development to take \\nadvantage of opportunities that AI can provide, like those presented in the Teaching section. \\nProfessional development will need to be balanced not only to discuss opportunities but also to \\ninform teachers of new risks, while providing them with tools to avoid the pitfalls of AI.  \\n \\n39 Ersozlu, Z., Ledger, S., Ersozlu, A., Mayne, F., & Wildy, H. (2021). Mixed-reality learning environments in teacher \\neducation: An analysis of TeachLivETM Research. SAGE Open, 11(3). https://doi.org/10.1177/21582440211032155.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 33, 'page_label': '34', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='30 \\n“Humans are well suited to discern the outcomes…because we are the \\nones that have the capacity for moral reflection and empathy. So, in other \\nwords, I want the AI to help me really quickly and easily see what my \\nstudent needs in their learning journey.”  \\n—Sarah Hampton \\nBy nature, teaching requires significant time in planning as well to account for the breadth of \\nneeds across their rosters—especially for inclusive learning environments and students with IEPs \\nand 504 plans. AI could help teachers with recommendations that are tuned to their situation and \\ntheir ways of practicing teaching and support with adapting found materials to fit their exact \\nclassroom needs. For students with an IEP, AI could help with finding components to add to \\nlesson plans to fully address standards and expectations and to meet each student’s unique \\nrequirements. Even beyond finding components, AI might help adapt standardized resources to \\nbetter fit specific needs—for example, providing a voice assistant that allows a student with a \\nvisual difficulty to hear material and respond to it or permitting a group of students to present \\ntheir project using American Sign Language (ASL) which could be audibly voiced for other \\nstudents using an AI ASL-to-Spoken-English translation capability. Indeed, coordinating IEPs is \\ntime-consuming work that might benefit from supportive automation and customized \\ninteractivity that can be provided by AI. \\nReflection is important too. In the bustle of a classroom, it is sometimes difficult to fully \\nunderstand what a student is expressing or what situations lead to certain positive or negative \\nbehaviors. Again, context is paramount. In the moment, teachers may not be aware of external \\nevents that could shape their understanding of how students are showing up in their classrooms. \\nTools that notice patterns and suggest ways to share information might help students and \\nteachers communicate more fully about strengths and needs. \\nDesigning, Selecting, and Evaluating AI Tools \\nThe broadest loop teachers should be part of is the loop that determines what classroom tools do \\nand which tools are available. Today, teachers already play a role in designing and selecting \\ntechnologies. Teachers can weigh in on usability and feasibility. Teachers examine evidence of \\nefficacy and share their findings with other school leaders. Teachers already share insights on \\nwhat is needed to implement technology well.  \\nWhile these concerns will continue, AI will raise new concerns too. For example, the following \\nFormative Assessment section raises concerns about bias and fairness that can lead to algorithmic \\ndiscrimination. Those concerns go beyond data privacy and security; they raise attention to how \\ntechnologies may unfairly direct or limit some students’ opportunities to learn. A key takeaway \\nhere is that teachers will need time and support so they can stay abreast of both the well-known \\nand the newer issues that are arising and so they can fully participate in design, selection, and \\nevaluation processes that mitigate risks. \\nChallenge: Balancing Human and Computer Decision-Making \\nOne major new challenge with AI-enabled tools for teachers is that AI can enable autonomous \\nactivity by a computer, and thus when a teacher delegates work to an AI-enabled tool, it may'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 34, 'page_label': '35', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='31 \\ncarry on with that work somewhat independently. Professor Inge Molenaar40 has wondered \\nabout the challenges of control in a hybrid teaching scenario: When should a teacher be in \\ncontrol? What can be delegated to a computational system? How can a teacher monitor the AI \\nsystem and override its decisions or take back control as necessary? \\nFigure 8: The tension between human and AI decision making: Who is in control? \\n \\nFigure 8 expresses the tension around control. To the left, the teacher is fully in control, and \\nthere is no use of AI in the classroom. To the right, the technology is fully in control with no \\nteacher involved—a scenario which is rarely desirable. The middle ground is not one \\ndimensional and involves many choices. Molenaar analyzed products and suggests some \\npossibilities: \\n● The technology only offers information and recommendations to the teacher. \\n● The teacher delegates specific types of tasks to the technology, for example, giving \\nfeedback on a particular math assignment or sending out reminders to students before an \\nassignment is due. \\n● The teacher delegates more broadly to the technology, with clear protocols for alerts, for \\nmonitoring, and for when the teacher takes back control. \\nThese and other choices need to be debated openly. For example, we may want to define \\ninstructional decisions that have different kinds of consequences for a student and be very \\ncareful about delegating control over highly consequential decisions (for example, placement in \\na next course of study or disciplinary referrals). For human in the loop to become more fully \\nrealized, AI technologies must allow teacher monitoring, have protocols to signal a teacher when \\ntheir judgment is needed, and allow for classroom, school, or district overrides when they \\ndisagree with an instructional choice for their students. We cannot forget that if a technology \\nallows a teacher choice—which it should—it will take significant time for a teacher to think \\nthrough and set up all the options, requiring greater time initially.  \\nChallenge: Making Teaching Jobs Easier While Avoiding Surveillance \\nWe also recognize that the very technologies that make jobs easier might also introduce new \\npossibilities for surveillance (Figure 9). In a familiar example, when we enable a voice assistant in \\nthe kitchen, it might help us with simple household tasks like setting a cooking timer. And yet the \\nsame voice assistant might hear things that we intended to be private. This kind of dilemma will \\n \\n40 Molenaar, I. (2022). Towards hybrid human-AI learning technologies. European Journal of Education, 00, 1–14. \\nhttps://doi.org/10.1111/ejed.12527'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 35, 'page_label': '36', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='32 \\noccur in classrooms and for teachers. When they enable an AI-assistant to capture data about \\nwhat they say, what teaching resources they search for, or other behaviors, the data could be \\nused to personalize resources and recommendations for the teacher. Yet the same data might \\nalso be used to monitor the teacher, and that monitoring might have consequences for the \\nteacher. Achieving trustworthy AI that makes teachers’ jobs better will be nearly impossible if \\nteachers experience increased surveillance. \\nA related tension is that asking teachers to be “in the loop” could create more work for teachers if \\nnot done well, and thus, being in the loop might be in tension with making teaching jobs easier. \\nAlso related is the tension between not trusting AI enough (to obtain assistance) or trusting it too \\nmuch (and incurring surveillance or loss of privacy). For example, researchers have documented \\nthat people will follow instructions from a robot during a simulated fire emergency even when \\n(a) they are told the robot is broken and (b) the advice is obviously wrong.41 We anticipate \\nteachers will need training and support to understand how and when they will need to exercise \\nhuman judgement. \\nFigure 9: Highly customized assistance vs. increased teacher surveillance \\n \\nChallenge: Responding to Students’ Strengths While Protecting Their \\nPrivacy \\nEducators seek to tackle inequities in learning, no matter how they manifest locally (e.g. in access \\nto educational opportunities, resources, or supports). In culturally responsive42 and culturally \\nsustaining43 approaches, educators design materials to build on the “assets”—individual, \\ncommunity, and cultural strengths that students bring to learning. Along with considering assets, \\nof course, educators must meet students where they are, including both strengths and needs. AI \\ncould assist in this process by helping teachers with customizing curricular resources, for \\nexample. But to do so, the data inputted in an AI-enabled system would have to provide more \\ninformation about the students. This information could be, but need not be, demographic \\ndetails. It could also be information about students’ preferences, outside interests, relationships, \\n \\n41 Wagner, A.R., Borenstein, J. & Howard, A. (September 2018). Overtrust in the robotics age. Communications of the ACM, \\n61(9),22-24. https://doi.org/10.1145/3241365 \\n42 Gay, G. (2018). Culturally responsive teaching: Theory, research, and practice. Teachers College Press. ISBN: 978-0807758762 \\n43 Paris, D., & Alim, H.S. (Eds.). (2017). Culturally sustaining pedagogies: Teaching and learning for justice in a changing \\nworld. Teachers College Press. ISBN: 978-0807758342'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 36, 'page_label': '37', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='33 \\nor experiences.44 What happens to this data, how it is deleted, and who sees it is of huge concern \\nto educators. As educators contemplate using AI-enabled technologies to assist in tackling \\neducational inequities, they must consider whether the information about students shared with \\nor stored in an AI-enabled system is subject to federal or state privacy laws, such as FERPA. \\nFurther, educators must consider whether interactions between students and AI systems create \\nrecords that must be protected by law, such as when a chatbot or automated tutor generates \\nconversational or written guidance to a student. Decisions made by AI technologies, along with \\nexplanations of those decisions that are generated by algorithms may also be records that must \\nbe protected by law. Therein, a third tension emerges, between more fully representing students \\nand protecting their privacy (Figure 10). \\nFigure 10: Responding to students’ strengths while fully protecting student privacy \\nFurther, representation would be just a start toward a solution. As discussed earlier in this report, \\nAI can introduce algorithmic discrimination through bias in the data, code, or models within AI-\\nenhanced edtech. Engineers develop the pattern detection in AI models using existing data, and \\nthe data they use may not be representative or may contain associations that run counter to \\npolicy goals. Further, engineers shape the automations that AI implements when it recognizes \\npatterns, and the automations may not meet the needs of each student group with a diverse \\npopulation. The developers of AI are typically less diverse than the populations they serve, and \\nas a consequence, they may not anticipate the ways in which pattern detection and automation \\nmay harm a community, group, or individual. \\nAI could help teachers to customize and personalize materials for their students, leveraging the \\nteacher’s understanding of student needs and strengths. It is time consuming to customize \\ncurricular resources, and teachers are already exploring how AI chatbots can help them design \\nadditional resources for their students. An elementary school teacher could gain powerful \\nsupports for changing the visuals in a storybook to engage their students or for adapting \\nlanguage that poorly fits local manners of speaking or even for modifying plots to incorporate \\nother dimensions of a teacher’s lesson. In the Learning section, we noted that AI could help \\nidentify learner strengths. For example, a mathematics teacher may not be aware of ways in \\nwhich a student is making great sense of graphs and tables about motions when they are in \\nanother teacher’s physics classroom and might not realize that using similar graphs about \\n \\n44 Zacamy, J. & Roschelle, J. (2022). Navigating the tensions: How could equity-relevant research also be agile, open, and \\nscalable? Digital Promise. http://hdl.handle.net/20.500.12265/159; Baker, R.S., Esbenshade, L., Vitale, J., & Karumbaiah, S. \\n(2022). Using demographic data as predictor variables: A questionable choice. https://doi.org/10.35542/osf.io/y4wvj'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 37, 'page_label': '38', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='34 \\nmotion could help with their linear function lesson. AI might help teachers when they seek to \\nreflect student strengths by creating or adapting instructional resources. \\nYet, the broad equity challenges of avoiding algorithmic discrimination while increasing \\ncommunity and cultural responsiveness must be approached within the four foundations we \\nearlier outlined: human in the loop, equity, safety and effectiveness, and evaluation of AI models. \\nWe cannot expect AI models to respect cultural responsiveness. The Department is particularly \\nconcerned that equity is something that engaged educators and other responsive adults are in the \\nbest position to address and something that is never solely addressable as a computational \\nproblem. \\nQuestions Worth Asking About AI for Teaching \\nAs leaders in both pre-service and post-service teacher education contemplate how AI can \\nimprove teaching (along with policymakers, developers, and researchers), we urge all in the \\necosystem to spend more time asking these questions: \\n• Is AI improving the quality of an educator’s day-to-day work? Are teachers experiencing \\nless burden and more ability to focus and effectively teach their students? \\n• As AI reduces one type of teaching burden, are we preventing new responsibilities or \\nadditional workloads being shifted and assigned to teachers in a manner that negates the \\npotential benefits of AI? \\n• Is classroom AI use providing teachers with more detailed insights into their students and \\ntheir strengths while protecting their privacy?  \\n• Do teachers have oversight of AI systems used with their learners? Are they exercising \\ncontrol in the use of AI-enabled tools and systems appropriately or inappropriately \\nyielding decision-making to these systems and tools? \\n• When AI systems are being used to support teachers or to enhance instruction, are the \\nprotections against surveillance adequate? \\n• To what extent are teachers able to exercise voice and decision-making to improve \\nequity, reduce bias, and increase cultural responsiveness in the use of AI-enabled tools \\nand systems? \\nKey Recommendation: Inspectable, Explainable, Overridable AI \\nIn the Introduction, we discuss the notion that when AI is incorporated into a system, the core of \\nthe AI is a model. In the Learning section, we discuss that we need to be careful that models align \\nto the learning we envision (e.g., that they aren’t too narrow). Now, based on the needs of \\nteachers (as well as students and their families/caregivers), we add another layer to our criteria \\nfor good AI models: the need for explainability.45 Some AI models can recognize patterns in the \\nworld and do the right action, but they cannot explain why (e.g., how they arrived at the \\n \\n45 Khosravi, H., Shum, S.B., Chen, G, Conati, C., Tsai,Y-S., Kay, J., Knight, S., Martinez-Maldonado, R., Sadiq, S., Gašević, D. \\n(2022). Explainable artificial intelligence in education. Computers and Education: Artificial Intelligence, 3. \\nhttps://doi.org/10.1016/j.caeai.2022.100074'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 38, 'page_label': '39', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='35 \\nconnection between the pattern and the action). This lack of explainability will not suffice for \\nteaching; teachers will need to know how an AI model analyzed the work of one of their students \\nand why the AI model recommended a particular tutorial, resource, or next step to the student.  \\nThus, explainability of an AI system’s decision is key to a teacher’s ability to judge that \\nautomated decision. Such explainability helps teachers to develop appropriate levels of trust and \\ndistrust in AI, particularly to know where the AI model tends to make poor decisions. \\nExplainability is also key to a teacher’s ability to monitor when an AI system may be unfairly \\nacting on the wrong information (and thus may be biased. We discuss bias and fairness more in \\nthe Assessment section next). \\nSurrounding the idea of explainability is the need for teachers to be able to inspect what an AI \\nmodel is doing. For example, what kinds of instructional recommendations are being made and \\nto which students? Which students are being assigned remedial work in a never ended loop? \\nWhich are making progress? Dashboards in current products present some of this information, \\nbut with AI, teachers may want to further explore which decisions are being made and for whom \\nand know of the student-specific factors that an AI model had available (and possibly which \\nfactors were influential) when reaching a particular decision. For example, some of today’s \\nadaptive classroom products use limited recommendation models that only consider student \\nsuccess on the last three mathematics problems and do not consider other variables that a \\nteacher would know to consider, such as whether a student has an IEP Plan or other needs. \\nOur call for attending to equity considerations as we evaluate AI models requires information \\nabout how discriminatory bias may arise in particular AI systems and what developers have done \\nto address it. This can only be achieved with transparency for how the tools use datasets to \\nachieve outcomes and what data they have available or that a teacher could include in her \\njudgement but are not available to the system (IEP status is offered as an example above).  \\nTeachers will also need the ability to view and make their own judgement about automated \\ndecisions, such as decisions about which set of mathematics problems a student should work on \\nnext. They need to be able to intervene and override decisions when they disagree with the logic \\nbehind an instructional recommendation.46 Teachers need protection against adverse \\nramifications when they assert human judgement over an AI system’s decision. \\n \\n46 Ruiz, P. & Fusco, J. (2022). Teachers partnering with artificial intelligence: Augmentation and automation. Digital Promise. \\nhttps://digitalpromise.org/2022/07/06/teachers-partnering-with-artificial-intelligence-augmentation-and-automation/'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 39, 'page_label': '40', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='36 \\n“These systems sometimes are seen as a black box kind of a situation \\nwhere predictions are made based on lots of data. But what we need is to \\nhave a clear view—to clearly show how those recommendations or those \\ninteractions are made and what evidence is used or what data is used to \\nbe able to make those recommendations so teachers and everyone \\ninvolved know about why that kind of system is providing that type of \\ninformation. So, having open learning environments or inspectable \\nlearner models or applications where the stakeholders can understand \\nhow these systems make decisions or recommendations is going to be an \\nimportant aspect in the future of teaching and learning.”  \\n—Diego Zapata-Rivera'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 40, 'page_label': '41', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='37 \\nFormative Assessment \\nFormative assessment is traditionally a key use of edtech because feedback loops are vital to \\nimproving teaching and learning.47 As we have emphasized throughout this report, a top priority \\nwith AI is to keep humans in the loop and in control, which includes focusing on the people \\nengaged with formative assessments: students, teachers, school leaders, families/caregivers, and \\nothers who support learners. In the definition below, please note the overlap between definitions \\nof AI and formative assessment; both have to do with detecting patterns and choosing a future \\ncourse of action (that adapts to learner strengths and needs). \\nAssessment refers to all those activities undertaken by teachers, and by \\nthe students in assessing themselves, which provide information to be \\nused as feedback to modify the teaching and learning activities in which \\nthey are engaged. Such assessment becomes “formative assessment” \\nwhen the evidence is actually used to adapt the teaching to meet the \\nneeds.48 \\nBuilding on Best Practices \\nA number of dimensions hold potential for shaping the future of formative assessments, and \\nmany have ready extensions to the field of AI-enabled systems and tools. For example, the 2017 \\nNETP discussed how technology can lead to improved formative assessments along seven \\ndimensions, listed below: \\n1. Enabling Enhanced Question Types: \\nto give students more ways to show what they know and can do. \\n2. Measurement of Complex Competencies:  \\nto better elicit growth in important skills that go beyond typical subject matter standards, \\nfor example, in measuring practices, social skills like teamwork, self-regulation, and \\nwork-relevant skills (e.g., making presentations or leading teams). \\n3. Providing Real-Time Feedback:  \\nto maintain and increase student engagement and to support effective learning, \\nproviding timely and helpful responses and suggestions to each learner. \\n4. Increasing Accessibility:  \\nto include neurodiverse learners and to engage learners’ best communication capabilities \\nas they share what they know and can do. \\n \\n47 Shute, V.J. (2008). Focus on formative feedback. Review of Educational Research, 78(1), 153–189. \\nhttps://doi.org/10.3102/0034654307313795 \\n48 Black, P. & Wiliam, D. (1998). Inside the black box: Raising standards through classroom assessment. Phi Delta Kappan, \\n92(1), 81-90. https://kappanonline.org/inside-the-black-box-raising-standards-through-classroom-assessment/'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 41, 'page_label': '42', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='38 \\n5. Adapting to Learner Ability and Knowledge:  \\nto make assessments more precise and efficient. \\n6. Embedded Assessment in the Learning Process:  \\nto emphasize an assessment’s role in improving teaching and learning (this report does \\nnot focus on assessment for accountability purposes). \\n7. Assess for Ongoing Learning: \\nto reveal progress over time and not just predetermined milestones. \\nAI models and AI-enabled systems may have potential to strengthen formative assessments. In \\none example, a question type that invites students to draw a graph or create a model can be \\nanalyzed with AI algorithms,49 and similar student models might be grouped for the teacher to \\ninterpret. Enhanced formative assessment may enable teachers to better respond to students’ \\nunderstanding of a concept like “rate of change” in a complex, real-world situation. AI can also \\ngive learners feedback on complex skills, such as learning American Sign Language50 or speaking \\na foreign language51 and in other practice situations where no person is available to provide \\nimmediate feedback. \\nGenerally, an AI assistant may be able to reduce the load for teachers related to grading simpler \\naspects of student responses, allowing the teacher to focus their specialized judgment on \\nimportant qualities of a whole essay or a complex project. We also may be able to better provide \\nfeedback with accessibility. For example, an AI-enabled learning technology may be able to \\ninteract verbally with a student about their response to an essay prompt, asking questions that \\nguide the student to clarify their argument without requiring the student to read a screen or type \\nat a keyboard. In the examples shared earlier in the Learning section, we also see that AI can be \\nembedded in the learning process, providing feedback to students as they work to solve a \\nproblem, rather than only later after the student has reached a wrong answer. When formative \\nassessment is more embedded, it can better support learning, and timely feedback is critical.52  \\nAlthough there are many points of connection like these between AI and formative assessments, \\nour listening sessions also revealed attendees’ desire to tackle some existing shortcomings in the \\nfield of formative assessment; namely, the time-consuming and sometime onerous nature of \\ntaking tests, quizzes, or other assessments and the lack of perceived value in the feedback loop by \\nteachers and students.  \\nImplications for Teaching and Learning  \\nReal-time instructional feedback can be beneficial when it helps learners and teachers to \\nimprove. But common experience too often leaves students and teachers with unpleasant \\nfeelings toward assessment and thus poses a provocative conflict between the potential benefits \\n \\n49 Zhai, X., He, P., Krajcik, J. (2022). Applying machine learning to automatically assess scientific models. Journal of Research \\nin Science Teaching. https://doi.org/10.1002/tea.21773 \\n50 Shao, Q., Sniffen, A., Blanchet, J., Hillis, M.E., Shi, X., Haris, T.K., & Balkcom, D. (2020). Teaching american sign language \\nin mixed reality. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 4(4), 1-27. \\nhttps://doi.org/10.1145/3432211 \\n51 Godwin-Jones, R. (2021). Big data and language learning: Opportunities and challenges. \\u2028Language Learning & Technology, \\n25(1), 4–19. http://hdl.handle.net/10125/44747 \\n52 Wiggins, G. (2015). Seven keys to effective feedback. ACSD. https://www.ascd.org/el/articles/seven-keys-to-effective-\\nfeedback'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 42, 'page_label': '43', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"39 \\nof data collected through formative assessments and the practical implications of administering \\nadditional assessments in classrooms and schools. \\nSome AI-enabled systems and tools seek to address this potential conflict. For example, one AI-\\nenabled reading tutor listens to students as they read aloud and provides on-the-spot feedback to \\nimprove their reading.53 Students reportedly enjoyed reading aloud, and the approach was \\neffective. Researchers have also embedded formative assessments in games so that students can \\nshow how well they understand Newtonian physics as they play increasingly difficult levels of a \\ngame.54 If a student can more easily ask for and receive help when they feel frustrated or \\nconfused, reducing those feelings can feel encouraging. Student feelings of safety, confidence, \\nand trust in the feedback generated by these AI-enabled systems and tools are essential to \\nshowcase their learning. That focus on learning growth and gains is optimal (absent negative \\nconsequences or a high-stakes environment).55 \\nAI-enhanced formative assessments may have the potential to save teachers’ time (e.g., time \\nspent on grading), allowing the instructor to spend more time engaged in helping students. AI-\\nenhanced assessments may also benefit teachers if they provide detailed insights about student \\nstrengths or needs that may not be visible and if they support instructional adaptation or \\nimprovement by suggesting a small set of evidence-based recommendations for helping students \\nmaster content. Such assessments may also be helpful outside of the classroom if it can provide \\nfeedback when the teacher is not available, for example, in completing homework or practicing a \\nconcept during study hall. As we discussed in the Teaching section, an essential aspect of \\ndeploying AI-based formative assessment must be centering teachers in system design. \\nInsight: AI Can Enhance Feedback Loops \\nThe term “formative assessment” does not singularly mean a test or a measurement. Assessment \\nbecomes formative when it results in useful reflections and changes to the course of teaching, \\nlearning, or both.56 The term “feedback loops” emphasizes that measurement is only part of the \\nprocess. Feedback loops that lead to instructional improvement—including adaptations in \\nteaching and learning—yield the strongest outcomes for students.  \\nWe also use “feedback loops” as a plural term because there are many types and levels of loops \\nthat are important. Students can benefit from feedback when they work individually, as a \\nmember of a small group, or in a classroom discussion. Feedback loops are valuable “in the \\nmoment”—for example, as a student practices a skill. Further, feedback loops are valuable when \\nthey cover larger spans of effort and reflections, such as at the end of presenting a project or \\nterm paper. In addition, feedback loops can assist teachers, for example, helping them notice \\n \\n53 Mostow, J., Aist, G., Burkhead, P., Corbett, A., Cuneo, A., Eitelman, S., Huang, C., Junker, B., Sklar, M.B., & Tobin, B. \\n(2003). Evaluation of an automated reading tutor that listens: Comparison to human tutoring and classroom instruction. \\nJournal of Educational Computing Research, 29(1), 61–117. https://doi.org/10.2190/06AX-QW99-EQ5G-RDCF \\n54 Shute, V.J., Ventura, M., & Kim, Y.J. (2013). Assessment and learning of qualitative physics in Newton's Playground. The \\nJournal of Educational Research, 106(6), 423–430. https://doi.org/10.1080/00220671.2013.832970 \\n55 Shute, V J. (2008). Focus on formative feedback. Review of Educational Research, 78(1), 153–189. \\nhttps://doi.org/10.3102/0034654307313795 \\n56 Black, P., & Wiliam, D. (2009). Developing the theory of formative assessment. Educational Assessment, Evaluation and \\nAccountability, 21(1), 5-31. https://doi.org/10.1007/s11092-008-9068-5\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 43, 'page_label': '44', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='40 \\ntheir own patterns of responding to students’ ideas. Moreover, feedback loops are critical to the \\ncontinuous improvement of products and the implementation of programs.  \\nDue to the importance of feedback loops, formative assessment could be a leading area for \\nschools’ explorations of powerful uses of AI in teaching and learning. Educators can build upon \\nalignments between their long-standing visions for formative assessment and the emerging \\ncapabilities that AI holds. Further, the professional assessment community brings a toolkit for \\nasking and answering questions about topics like bias and fairness. The psychometric toolkit of \\nmethods is a strong start toward the questions that must be asked and answered because it \\nalready contains ways to measure bias and fairness and, more generally, to benchmark the \\nquality of formative assessments. But as our discussion reveals, AI can only make feedback loops \\nbetter if we keep a firm eye on the weaknesses of AI and how AI introduces new concerns. \\nAn Example: Automated Essay Scoring \\nOne instructive example is Automated Essay Scoring (AES). To become strong writers, which is a \\nvaluable life skill, students need regular and specific feedback. However, reviewing and \\nproviding feedback on essays is very time consuming for humans. Hence, Ellis Page provided a \\nfirst vision for computer programs that could review and provide feedback on student essays in 196657, \\nand much effort has gone into AES technologies in the intervening 56 years. Many research \\nreview articles are available to summarize the progress, which has been impressive.58 Further, \\nsome of today’s applications of AES technologies will be familiar to readers, such as Grammarly, \\nTurnitin, and the various essay analysis engines used by publishers and assessment companies. \\nAlso note that while the traditional AES functionality emphasizes scoring or rating essays, newer \\nAI-enabled products focus more on providing students with constructive criticism and \\ndeveloping their skills as writers. Writing is a life skill that is important to the pursuit of college \\nand career ambitions, and developing writers require comprehensive feedback. If developers \\ncould inexpensively augment human feedback to developing writers with AI feedback, it’s \\npossible that support for learning to write could become more equitable. \\nAnd yet, AES is an instructive example because researchers have analyzed limitations, too.59 AES \\ntechnologies in AI can analyze some features of student essays but can also be misled by the \\nlength of an essay, by a student who places appropriate keywords in sentences that don’t make \\nsense, and other flaws that a human reader would easily notice. In a telling quote, one team that \\nreviewed the state of the art wrote this: \\nThe authors further note that while human and AI judgements of essays may correlate, people \\nand computers are not noticing the same things in student writing. Due to these limitations, we \\nmust continue to emphasize a human in the loop foundation for AI-enhanced formative \\nassessment. AI may support but not replace high-quality, human-led processes and practices of \\nformative assessment in schools. \\n \\n57 Page, E.B. (1966). The imminence of grading essays by computer. Phi Delta Kappan, 47(5), 238–243 \\n58 Ke, Z., & Ng, V. (2019). Automated essay scoring: A survey of the state of the art. In Proceedings of the Twenty-Eighth \\nInternational Joint Conference on Artificial Intelligence, 6300–6308. https://doi.org/10.24963/ijcai.2019/879 \\n59 Doewes, A. & Pechenizkiy, M. (2021). On the limitations of human-computer agreement in automated essay scoring. In \\nProceedings of the 14th International Conference on Educational Data Mining (EDM21). \\nhttps://educationaldatamining.org/EDM2021/virtual/static/pdf/EDM21_paper_243.pdf'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 44, 'page_label': '45', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='41 \\n \\n“Nevertheless, the time when AES systems will be able to operate on a \\npar with human judges, with similar levels of connoisseurship for such \\nfeatures as meaning, emotion, originality, creativity, fluency, sense of \\naudience and so on, arguably remains a long way off.” \\n—Gardner, O’Leary, and Yuan60  \\nKey Opportunities for AI in Formative Assessment \\nBased on the listening sessions we held, we see three key areas of opportunity in supporting \\nformative assessment using AI systems and models.  \\nFirst, we recommend a strong focus on measuring what matters61 and particularly those things \\nthat have not been easily measured before and that many constituents would like to include in \\nfeedback loops. The example above, AES, was chosen because writing remains a valuable \\nacademic, workplace, and life skill. Looking at community goals through the lens of their visions \\nfor their high school graduates, we see that families/caregivers, students, and community leaders \\nwant to nurture graduates who solve problems adaptively, who communicate and collaborate \\nwell, who persevere and self-regulate when they experience challenges. “What matters” today \\nreaches beyond a sole focus on the core academic content measured by large-scale summative \\nassessments, to support students and teachers with actionable feedback that nurtures the broader \\nskills students need to succeed and thrive. Further, within core academic content, AI may help us \\nto provide feedback on the more realistic and complex aspects of doing math, for example, or \\ninvestigating scientific phenomena, understanding history, or discussing literature.  \\nSecond, we’d like to see a strong focus on improving help-seeking and help-giving.62 Asking for \\nand giving help is crucial to learning63 and practicing a growth-mindset and central to the notion \\nof human feedback loops. Students may not always know when they need help. In one example, \\ncomputer algorithms can detect a student who is “wheel spinning” (working hard on mastering \\ncontent but not making progress).64 A student who is working hard may not feel like they need \\nhelp, and the teacher may not be aware that the student is struggling if he or she appears to be \\n“on task.” AI may also be helpful by highlighting for students and teachers what forms of \\nassistance have been most useful to the student in the recent past so that an educator can expand \\naccess to specific assistance that works for that individual student. Finally, educators may learn \\nthings from AI-enabled systems and tools that give feedback and hints during the completion of \\n \\n60 Gardner, J., O\\'Leary, M. & Yuan, L. (2021). Artificial intelligence in educational assessment: \"Breakthrough? Or \\nbuncombe and ballyhoo?\" Journal of Computer Assisted Learning, 37(5), 1207–1216. https://doi.org/10.1111/jcal.12577 \\n61 Merrill, S. (2020). In schools, are we measuring what matters? Edutopia. https://www.edutopia.org/article/schools-are-we-\\nmeasuring-what-matters \\n62 Roll, I., Aleven, V., McLaren, B.M., Koedinger, K.R. (2011). Improving students’ help-seeking skills using metacognitive \\nfeedback in an intelligent tutoring system, Learning and Instruction, 21(2), 267–280. \\nhttps://doi.org/10.1016/j.learninstruc.2010.07.004. \\n63 Webb, N.M., & Farivar, S. (1994). Promoting helping behavior in cooperative small groups in middle school \\nmathematics. American Educational Research Journal, 31(2), 369–395. https://doi.org/10.3102/00028312031002369 \\n64 Kai, S., Almeda, M.V., Baker, R. S., Heffernan, C., & Heffernan, N. (2018). Decision tree modeling of wheel-spinning and \\nproductive persistence in skill builders. Journal of Educational Data Mining, 10(1), 36–71. \\nhttps://doi.org/10.5281/zenodo.3344810'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 45, 'page_label': '46', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='42 \\nhomework, utilizing that feedback to later reinforce concepts in direct instruction and \\nstrengthen the one-on-one support provided to students.65 AI-enabled systems and tools can \\nprovide teachers with additional information about the students’ recent work, so their instructor \\nhas a greater contextual sense as they begin to provide help. \\nThird, we advocate for teachers and students to be strongly involved in designing feedback \\nloops as developers produce AI-enhanced formative assessments so they can directly voice what \\nwould make assessments less onerous and more convenient and valuable to them.66 Earlier in the \\nTeaching section, we emphasized how important it is to involve teachers in designing, selecting, \\nand evaluating AI-enhanced technologies. Students need to be centered, too. They are \\nexperiencing AI in their everyday lives, and they have strong opinions on what is valuable and \\nsafe. There are local and cultural variations in how people provide and receive feedback, so \\nadjusting feedback to align with community norms is important. \\nKey Recommendation: Harness Assessment Expertise to Reduce Bias \\nBias and fairness are important issues in assessment design and administration,67 and they hold \\nrelevance for the area of AI-enabled assessment. In traditional assessment, a test item might be \\nbiased if unnecessary details are included that differentially advantage some students (e.g., a \\nstory-based item that references a sport that only boys play regularly may be less helpful to \\ngirls). As discussed earlier, with AI, we now must worry about algorithmic discrimination which \\ncan arise due to the manner in which AI algorithms are developed and improved from large \\ndatasets of parameters and values that may not represent all cohorts of learners. \\nAlgorithmic discrimination is not just about the measurement side of formative assessment; it is \\nalso about the feedback loop and the instructional interventions and supports that may be \\nundertaken in response to data collected by formative assessments. There is a question both \\nabout access to such interventions and the quality or appropriateness of such interventions or \\nsupports. When an algorithm suggests hints, next steps, or resources to a student, we have to \\ncheck whether the help-giving is unfair because one group systematically does not get useful \\nhelp which is discriminatory. Fairness goes beyond bias as well. In AI-enabled formative \\nassessment, both the opportunity to learn through feedback loops, as well as the quality of \\nlearning in and outside of such loops, should be addressed. Issues of bias and fairness have arisen \\nin traditional assessments, and the field of psychometrics has already developed valuable tools to \\nchallenge and address these issues.68 Assessment as a field may have a head start on tackling bias \\nand fairness for AI in education. And yet the issues expand with AI, so the work is not done. \\nStrong and deliberate attention to bias and fairness is needed as future formative assessments are \\ndeveloped. \\n \\n65 Walker, E., Rummel, N. & Koedinger, K.R. (2015). Adaptive intelligent support to improve peer tutoring in algebra. \\nInternational Journal of Artificial Intelligence in Education, 24, 33–61 https://doi.org/10.1007/s40593-013-0001-9 \\n66 Swiecki, Z., Khosravi, H., Chen, G., Martinez-Maldonado, R., Lodge, J.M., Milligan, S., Selwyn, B. & Gašević,D. (2022). \\nAssessment in the age of artificial intelligence. Computers and Education: Artificial Intelligence, 3. k \\nhttps://doi.org/10.1016/j.caeai.2022.100075 \\n67 Reynolds, C.R., & Suzuki, L.A. (2012). Bias in psychological assessment: An empirical review and recommendations. \\nHandbook of Psychology, Second Edition. https://doi.org/10.1002/9781118133880.hop210004 \\n68 Kaplan, R.M., & Saccuzzo, D.P. (2017). Psychological testing: Principles, applications, and issues. Cengage Learning.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 46, 'page_label': '47', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='43 \\nRelated Questions \\nAs indicated, formative assessment is an area in which AI is expanding along a continuum that \\ncan be guided by visions already in place, such as the 2017 NETP. It is an area in which AI is \\npoised to grow, especially with capabilities that power more feedback loops in student learning. \\nAs this growth takes place, we suggest ongoing attention to the following questions: \\n● Is formative assessment bringing benefits to the student learning experience and to the \\nefficacy of classroom instruction?  \\n● Are humans being centered in AI-enabled formative assessment and feedback loops? \\n● Are we providing empowering professional development to teachers so they can leverage \\nfeedback loops and safeguard against concerns? \\n● To what extent are the developers and implementers of AI-enabled systems and tools \\ntackling new sources of algorithmic bias and continuing to make assessment fairer? \\n● Are governance policies regarding who owns, controls, and can view or use AI-enabled \\nformative assessment data appropriate and adequate? \\n● Do we have sufficient guardrails against misuse of formative assessment data or \\nautomatically generated interpretations of student achievement and learning, such as on \\ndashboards?  \\n● Is trust in an AI-enabled assessment system, feedback loops, and data generated by such \\nassessments growing or diminishing?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 47, 'page_label': '48', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='44 \\nResearch and Development \\nPolicy relies upon research-based knowledge; likewise, improving practice depends on feedback \\nloops that analyze empirical evidence. Consequently, the 2010 NETP specified a series of “grand \\nchallenges” which were “R&D problems that might be funded and coordinated at a national \\nlevel.” One 2010 NETP grand challenge was to create personalized learning systems that \\ncontinuously improve as they are used: \\n“Design and validate an integrated system that provides real-time access \\nto learning experiences tuned to the levels of difficulty and assistance \\nthat optimize learning for all learners and that incorporates self-\\nimproving features that enable it to become increasingly effective \\nthrough interaction with learners.”69 \\nSince 2010, much R&D has addressed this challenge. Conferences about learning analytics, \\neducational data mining, and learning at scale have blossomed. Developers have created \\nplatforms that use algorithms and the analysis of big data to tune learning experiences. The \\nchallenge has not been fully achieved, and further work on this challenge is still relevant today.  \\nInsight: Research Can Strengthen the Role of Context in AI \\nDespite the relevance of 2010’s grand challenges, it has become apparent that the R&D \\ncommunity is now looking to expand their attention. The 2010 challenges were stated as \\ntechnical problems. Today’s researchers want to more deeply investigate context, and today’s \\ntech companies want to develop platforms that are responsive to the learners’ characteristics and \\nsituations more broadly—not just in terms of narrow cognitive attributes. We see a push to \\ntransform R&D to address context sensitivity. We look forward to new meanings of “adaptive” \\nthat broaden outward from what the term has meant in the past decade. For example, “adaptive” \\nshould not always be a synonym of “individualized” because people are social learners. \\nResearchers therefore are broadening “adaptivity” to include support for what students do as \\nthey learn in groups, a form of learning that is prevalent in schools across the U.S. \\nThe focus on context is not an accident. Context is a traditional challenge in AI.70 Thus, \\nresearchers and developers are wise to prioritizing context. Unless we invest more in AI that is \\ncontext-sensitive, it is quite likely that AI will break and fail to achieve educational goals. \\nAgreeing to prioritize context won’t be easy. As illustrated above in Figure 12, there will be a \\ntension between depth of context and pace of technological advances in AI R&D. On the one \\nhand, AI is sometimes presented as a race to be the first to advance new techniques or scale new \\napplications—innovation is sometimes portrayed as rapidly going to scale with a minimally \\nviable product, failing fast, and only after failure, dealing with context. On the other hand, \\nresearchers and developers see that achieving good innovations with AI in education will clearly \\n \\n69 U.S. Department of Education, Office of Educational Technology. (2010). Transforming American Education: Learning \\nPowered by Technology. U.S. Department of Education. p. 78 \\n70 Boden, M.A. (2018). Artificial intelligence: A very short introduction. Oxford. ISBN: 978-0199602919'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 48, 'page_label': '49', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='45 \\nrequire bringing more context into the process early and often. For example, researchers \\nhighlight that humans must be continually adjusting the goals for technology and have noted \\nthat when we set forth goals, we often don’t yet fully understand context; and as we learn about \\ncontext, the goals must change.71 This suggests that context must be prioritized early and \\nhabitually in R&D; we don’t want to win a race to the wrong finish line. \\nFigure 12: The tension between depth of context and pace of technological advances in AI \\n \\nFurther, intensifying focus on context in this work will change the nature of the R&D. There \\nwon’t be just one type of change in R&D because context has multiple meanings. Attendees in \\nour listening sessions described four types of context necessary for the future. \\nWe list these four types of context below and then expand on each one in its own section. These \\nfour types emerged as topics of provocations to think differently about R&D but certainly do not \\nexhaust the important ways of investigating context. \\n1. Focus on the Long Tail: How could we use big data and AI to pay more attention to the \\n“long tail” of edtech use—going beyond a few “most typical” ways of using emerging \\ntechnology and instead solving for digital equity and inclusion? \\n2. Partnership in Design-Based Research: How can we change who is involved and \\ninfluential in designing the future of AI in education to more centrally include students, \\nteachers, and other educational constituents?  \\n3. Connect with Public Policy: How can work on AI in education build on general advances \\nin AI ethics, safety, and regulation and contribute additional advances specific to \\neducational policy?  \\n4. Rethink Teacher Professional Development: How can we solve for new systems of \\nteacher professional development (both pre-service and in-service) that align to the \\nincreasingly core role of technology in the teaching profession? \\n \\n71 Russell, S. (2019). Human compatible: Artificial intelligence and the problem of control. Penguin. ISBN: 9780525558637'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 49, 'page_label': '50', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"46 \\n“We can't necessarily always apply traditional research methodologies to \\nthis topic because educational technology changes so quickly.”  \\n—Kristina Ishmael, Office of Educational Technology \\nAttention to the Long Tail of Learner Variability \\nAt the core of R&D of AI in education, innovators will be building models that fit available data. \\nThe increasing scale and prevalence of technologies means that the data is coming from and \\nincluding a wide range of different contexts and varied ways that people in those contexts engage \\nin teaching and learning. Researchers in our listening sessions drew attention to the promise of \\nAI for addressing “context” by reference to the long tail of learner variability. \\nFigure 13: The long tail of learner variability\\n \\nAs depicted in Figure 13, learners vary in their strengths and needs. The most frequently \\noccurring mix of strength and needs (also known as “teaching to the middle”) is depicted \\nleftmost, with less frequently occurring mixes spreading to the right. Rising upward, the figure \\ndepicts the number of learners who benefit from a particular learning design, pathway, or \\napproach. We argue that AI can bring opportunities to address a wider spectrum of strengths and \\nneeds but only if developers and innovators focus on the long tail and not only “teaching to the \\nmiddle.”  \\nFor the sake of argument, the figure indicates three zones. In a first zone, curricular resources are \\nmostly standardized, with perhaps a dimension or two of adaptivity. For example, many existing \\nproducts adapt based on the correctness of student answers and may also provide options to read \\nor hear text in a second language. However, the core of the instructional approach is highly \\nstandardized. In a second zone, there is greater balance between how much standardization and \\nhow much adaptivity students can access. Universal Design for Learning (UDL) is one set of \\nrecommendations for providing learning opportunities in multiple formats and for\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 50, 'page_label': '51', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"47 \\naccommodating different learning progressions.72 UDL can enable accommodating more ways in \\nwhich learners vary, and as teachers know, there are many more important ways to adapt to \\nstudents than found in today’s edtech products.  \\nStudents are neurodiverse. They bring different assets from their experiences at home, in their \\ncommunities, and in their cultures. They have different interests and motivations. And they \\nlearn in varied settings—classrooms and schools differ, and at-home students learn in informal \\nsettings in ways that could complement school learning. These are all important dimensions of \\n“context.” Zone 3 indicates highly adaptive learning, where standardization is less successful and \\nwhere we need to discover a wider variety of approaches to engage learners and sustain powerful \\nlearning. Researchers in our listening sessions noted the promise of Zone 3 because AI’s ability to \\nrecognize patterns in data can extend beyond the most common patterns and because AI's ability \\nto generate customized content can extend beyond what people can reasonably generate on their \\nown. \\nNotice that although the Zone 1 bar appears to be the tallest, and thus tends to attract initial \\nattention, there are more students in Zones 2 and 3, the regions where AI can provide more help. \\nThus, it’s important to ask where AI researchers and developers are directing their attention. \\nWhen we say a model “fits,” are we saying it fits the most common and typical uses by teachers \\nand learners? This sort of R&D is easier to do. However, machine learning and AI also can tailor a \\nmodel to the less common and more culturally specific contexts, too. Therefore, how can \\nconstituents cultivate interdisciplinary expertise to direct attention among researchers and \\ndevelopers to focus on the long tail? If we do, the quality of what we do for those represented in \\nthat tail can be more adaptive and more context-sensitive. And to be most effective, it will \\nrequire the integration of contextual, content, and technical expertise. \\nWithin the long-tail challenge, the community is wondering how we can get to research insights \\nthat are both general and specific enough. When research produces very general abstractions \\nabout learning, it often doesn’t give developers enough guidance on exactly how to adjust their \\nlearning environments. Conversely, when research produces a specific adaptive algorithm that \\nworks on one educational platform, it often remains hard to apply to additional platforms; \\nresearch can be too detailed as well. The research community is also thinking about new \\npartnerships that could bring more data and more diverse perspectives to the table, the topic of \\nthe next section.  \\nFocusing on the long tail of learner variability is particularly important to addressing a long-\\nstanding key research question: “Do new AI-enhanced approaches work to improve learning, and for \\nwhom and under what conditions?” \\nPartnership in Design-Based Research \\nOf course, teachers must be included in rethinking their own professional development. This \\nthought leads to another priority aspect of context: partnership in design-based research. With \\nregard to inclusive design, attendees in our listening sessions brought up a variety of co-design73 \\n \\n72 Rose, D. (2000). Universal design for learning. Journal of Special Education Technology, 15(4), 47-51. \\nhttps://doi.org/10.1177/016264340001500407 \\n73 Roschelle, J., Penuel, W., & Shechtman, N. (2006). Co-design of innovations with teachers: definition and dynamics. In \\nProceedings of the 7th International Conference on Learning Sciences, Bloomington, IN. https://doi.dx.org/10.22318/icls2006.606\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 51, 'page_label': '52', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='48 \\nand other participatory processes and goals that can be used in R&D.74 By co-design, they mean \\nsharing power with non-researchers and non-developers through all the phases of design and \\ndevelopment, which would result in more influence by teachers, students, and other constituents \\nin the shape of AI-enabled edtech. The shift toward co-design was palpable throughout our \\nlistening sessions, but as researchers and developers have not standardized on one particular co-\\ndesign method, we share some representative examples. \\n● Youth can powerfully participate in design when researcher methods include participant \\nco-design. Such research can investigate how to improve edtech while educating students. \\nA listening session attendee asked about developing students’ awareness of what data are \\nbeing collected and how data are being used by developers. \\n● There is a near future need to go beyond representation so that co-designed solutions \\nconsider more generous contexts for broader possibilities, according to attendees. \\n● The shift of power dynamics is another research-worthy interest of the panel and \\nattendees to understand the balance between a teacher’s agency and a machine’s \\nsuggestions. \\n● Likewise, such longitudinal research will require both the infrastructure and institutional \\nsupport to fund necessary experimentation and requisite failures to elicit positive results \\nand safe innovation. \\n● There is a desire for rapid cycle evaluations with inclusive feedback loops that return to \\nthe educators themselves as essential relative to traditional research approaches. \\n● Many researchers also mentioned a focus on explainable AI as essential to enable \\nparticipation in the design and evaluation of emerging AI approaches in education. \\nThe conversations raised this question: how can co-design provide an empowering form of \\nparticipation in design and thus achieve digital inclusion goals? Such digital inclusion can span \\nmany layers of design, including diverse representation in design of policies around data, design \\nof adaptivity, and other user experiences in AI systems, design of plans for cultivating AI literacy \\nfor users of new platforms, and lastly, the design of plans to evaluate systems. \\nRe-thinking Teacher Professional Development \\nWith regard to teachers as professionals, both researchers and other educators attending our \\nlistening sessions were highly concerned about the disconnect between how teachers are \\nprepared versus how they are expected to work with emerging technology. When we discuss \\nlearning, teachers are central actors, and thus the contexts in which they are prepared is centrally \\nimportant to their ability to do great work in current and emerging technological environments.  \\nTeacher professional development, professional learning, and leadership (PD or PL) for \\nemerging technologies was seen as an area needing intense re-thinking, and research could lead \\nthe way. Today, few who prepare to become a teacher in an established pre-service program \\nlearn about the effective use of educational technology in schools and classrooms; those who do \\n \\n74 Center for Integrative Research in Computing and Learning Sciences (CIRCLS). (2022, Feb.). From Broadening to \\nEmpowering: Reflecting on the CIRCLS’21 Convening. https://circls.org/circls21report'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 52, 'page_label': '53', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='49 \\nhave the opportunity to investigate technology rarely think about the structures that shape its \\nuse in the classroom and in educational leadership. Consequently, a troubling dichotomy arises \\nbetween a small set of investigators who specifically consider educational technology in their \\nresearch on teaching and a broader group of educators who see educational technology as a \\ngeneric instructional resource. The challenge is high because teacher professional development \\nwill remain highly varied by local contexts. Yet insufficient attention to teachers as leaders in the \\nuse and further development of effective educational technology is widespread in teacher \\nprofessional development research. \\nOne response can be in terms of investigating how to nurture greater AI literacy for all teachers. \\nAI literacy is not only important to protect educators and students from possible dangers but also \\nvaluable to support teachers to harness the good and do so in innovative ways. A panelist \\nreminded the group that this work implies how we prepare educators with a baseline AI literacy \\nand understanding. More transparency and authentic dialogue can foster trust, which was \\nmentioned by a researcher as a chief concern for all teachers and students. \\nThis is not to suggest that AI literacy is a complete or even a simple fix. Researchers want to ask \\nfundamental questions about what it means for teachers to be professionals, especially as \\nemerging technologies gain ground in schools and classrooms—our teachers’ professional \\nworkplaces. Researchers want to broadly reconceptualize teacher professionalism and to stop \\ntreating technology as an add-on element of professional development. \\nConnecting with Public Policy \\nDefining human-centered AI for education requires the embrace of a human-centered principle \\nand foundation for developing and formulating policies that govern the application and use of \\nAI more generally throughout society. For example, power dynamics that arise between \\ncompanies and consumers in society around issues like data ownership will also arise in the \\neducation-specific ecosystem. Further, the public discourse in which people are discussing ethics, \\nbias, responsibility, and many other necessary concepts will be happening simultaneously in \\npublic policy and in educational ecosystems.  \\nOne clear implication in our listening sessions was that efforts to improve AI literacy in \\neducation could be important and helpful to society more generally. For example, one panelist \\nsaid that an overarching goal of improving AI literacy is necessary if they are to contribute to \\nhow those technologies are designed. Another researcher was interested in how edtech can \\nprovide environments where students can experience having difficult discussions across \\nperspectives, an issue which is endemic to present society. A third researcher noted the \\ninsufficiencies of prior efforts to contend with algorithmic bias, ethics, and inclusion due to a \\nclassroom’s complex social dynamics. \\nResearchers want to take a lead in going beyond checkbox approaches to take these issues \\nseriously. And they also acknowledge that engaging with policy is often a new form of context \\nfor edtech and AI researchers, many of whom don’t have long experiences in policy arenas. \\nLikewise, developers often do have experience with some policy issues, such as data privacy and \\nsecurity, but are now needing to become part of new conversations about ethics, bias,'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 53, 'page_label': '54', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='50 \\ntransparency, and more, a problem that the EdSAFE AI Alliance is addressing through multi-\\nsector working groups and policy advocacy.75  \\nKey Recommendation: Focus R&D on Addressing Context \\nAttendees who have participated in listening sessions leading up to this report were exceptionally \\nclear that their view of future R&D involved a shift from narrow technical questions to richer \\ncontextual questions. This expansive shift toward context, as detailed below, is the foundational \\norientation that the listening session attendees saw as being necessary to advancing R&D. \\nAttendees included these as dimensions of context: \\n• learner variability, e.g., in disabilities, languages spoken, and other relevant \\ncharacteristics; \\n• interactions with peers, teachers, and others in the learning settings; \\n• relationships across home, school, and community settings, including cultural assets; \\n• instructional resources available while learning; \\n• teacher preparation; and \\n• policies and systems that structure teaching and learning. \\n \\nTo more fully represent the context of teaching and learning, including these and other \\ndimensions of text, researchers will have to work in partnership with others to understand which \\naspects of context are most relevant to teaching and learning and how they can be usefully \\nincorporated into AI models. \\nOngoing Questions for Researchers \\nAs mentioned earlier, people are good at context; AI—not so much. R&D investment in context-\\nrich edtech thus could serve multiple national interests because finding ways to do a better job \\nwith context would be a fundamental advancement in AI. Indeed, questions like these \\nreverberate across all applications of AI in society, and education is a centrally good context for \\ninvestigating them: \\n● Are AI systems moving beyond the tall portions of the “long tail” to adapt to a greater \\nrange of conditions, factors, and variations in how people learn?  \\n● To what extent are AI technologies enhancing rather than replacing human control and \\njudgment of student learning? \\n● How will users understand the legal and ethical implications of sharing data with AI \\nenabled technologies and how to mitigate privacy risks? \\n● To what extent does technology account for the complex social dynamics of how people \\nwork and learn together, or is technology leading humans to narrow or oversimplify? \\n● How can we more clearly define what we mean by a context-sensitive technology in \\nterms that are both concrete and broad enough? How can we measure it? \\n \\n75 Nentrup, E. (2022). How Policymakers Can Support Educators and Technology Vendors Towards SAFE AI. EdSAFE AI \\nAlliance. https://www.edsafeai.org/post/how-policymakers-can-support-aied'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 54, 'page_label': '55', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='51 \\n● To what extent are technical indicators and human observations of bias or unfairness \\nworking together with human observations? How can concerns about ethics and equity in \\nAI technologies become actionable both in R&D, and later, when AI is widely used? \\n● Are we learning for whom and under what conditions AI systems produce desired \\nbenefits and impacts and avoid undesirable discrimination, bias, or negative outcomes?  \\nDesired National R&D Objectives \\nAttendees sought immediate progress on some key R&D issues, such as these: \\n• Clarifying and achieving a consensus on the terms that go beyond data privacy and data \\nsecurity, including ideas like human-centered, value-sensitive, responsible, ethical, and \\nsafe so constituents can advocate for their needs meaningfully and consistently \\n• Creating and studying effective programs for AI literacy for students, teachers, and \\neducational constituents in general, including literacy with regard to the ethics and equity \\nissues specific to AI in educational settings \\n• Advancing research and development to increase fairness, accountability, transparency, \\nand safety in AI systems used in educational settings \\n• Defining participatory or co-designed research processes that include educators in the \\ndevelopment and conduct of research related to the development, use, and efficacy of AI-\\nenabled systems and tools  \\n• Highlighting and advancing R&D efforts that empower the participation and voices of \\nyouth regarding research, data, and design of AI applications for teaching and learning \\nLonger term desires for a national R&D program include some of the following objectives: \\n• Funding sustainable partnerships that uncover what context means and how it can be \\naddressed over longer periods of time \\n• Better connecting goals for “broadening participation” (for example, in STEM learning \\npathways) to strategies for addressing learner variability and diversity \\n• Prioritizing research to revitalize support for instructors in light of the increasingly \\ntechnological nature of K-12, higher education, and workplace learning settings \\n• Creating infrastructure and new ways of working together beyond individual field-\\ninitiated grants so that R&D with big data and leveraging emerging AI capabilities \\nbecomes safer and more productive'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 55, 'page_label': '56', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='52 \\nRecommendations  \\nEarlier, we asked two guiding questions: \\n1. What is our collective vision of a desirable and achievable educational system that \\nleverages automation while protecting and centering human agency? \\n2. On what timeline will we be ready with necessary guidelines and guardrails along with \\nconvincing evidence of positive impacts, so that we can ethically and equitably \\nimplement this vision widely? \\nAnswers to the first question are provided throughout the Learning, Teaching, Assessment, and \\nResearch sections. This section turns to a call to action to education leaders and to \\nrecommendations. Core to the Department’s perspective is that education will need leadership \\nspecific to our sector. Leadership should recognize and build on prior accomplishments in \\nedtech (such as strong prior work on student privacy and school data security) as well as broad \\nframeworks for safe AI (such as the Blueprint for an AI Bill of Rights). Leadership must also reach \\nbeyond these accomplishments and frameworks to address emerging opportunities and risks \\nthat are specific to novel capabilities and uses of AI in education.  \\nInsight: Aligning AI to Policy Objectives \\nIndividual sections of this policy report provided insights in each of four areas—learning, \\nteaching, assessment, and research. These insights, synthesized from extensive stakeholder \\nconsultation and listening sessions, show that the advances in AI can bring opportunities to \\nadvance the Department’s policy objectives: \\n● In support of our objective of attracting and retaining teachers, our nation could focus on \\nAI assistants that make teaching jobs better and provide teachers with the information \\nthey need to work closely and empathically with students. An emphasis on teachers in the \\nloop could ensure that AI-enabled classroom technologies keep teachers in the know, in \\ntouch with their students, and in control of important instructional decisions. Keeping the \\nteacher in the loop is important to managing risks, as well. \\n● In support of equitable learning, especially for those most affected by the pandemic, AI \\ncould shift edtech from a current deficit-based model to a strengths-based alternative. In \\naddition to finding student weaknesses and assigning fixes, edtech could make \\nrecommendations based on strengths that students bring to learning and how adapting to \\nthe whole student—a cognitive, social, and self-regulating person—could enable more \\npowerful learning. Adapting to the whole student should include supporting students \\nwith disabilities as well as English learners. With regard to equity, we must remain highly \\nattuned to the challenges of bias (which are inherent to how AI systems are developed) \\nand take firm action to ensure fairness. \\n● With regard to growth trajectories to successful careers, AI-enabled assessments could \\nprovide students and teachers with formative guidance on a wider range of valuable \\nskills, focusing on providing information that enhances learning. Aligned with the \\nhuman-centric view, we should take a systems view of assessments where students, \\nteachers, and others remain at the center of instructional decision making.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 56, 'page_label': '57', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='53 \\n● With regard to equity, as research advances and brings more context into AI, we will be \\nbetter able to use AI to support goals that require customization of learning resources, \\nsuch as enabling teachers to more easily transform materials to support neurodiverse \\nlearners and increase responsiveness to local communities and cultures.  \\nGoing forward, educational leaders need to bring these and their own policy priorities to the \\ntable at every discussion about AI, driving the conversation around human priorities and not \\nonly their excitement about what new technology might do. Fundamentally, AI seeks to \\nautomate processes that achieve goals, and yet, AI should never set goals. The goals must come \\nfrom educators’ vision of teaching and learning and educators’ understanding of students’ \\nstrengths and needs. \\nCalling Education Leaders to Action \\nWe summarize seven recommendations for policy action. These recommendations are for \\neducation leaders. In the introduction, we note the necessity of involving education constituents \\nin determining policies for AI. We also observed throughout our listening sessions that people \\ncoming from many different roles in education all have passion, knowledge, and insights to \\ncontribute. In our view, all types of constituents can be education leaders. We are reluctant to \\nsuggest any constituent role is more important to advance any of the recommendations, but we \\ncall out specific needs for action within some of the recommendations where it is warranted. \\nRecommendation #1: Emphasize Humans in the Loop \\nWe start with a central recommendation throughout this report. This recommendation was a \\nclear constituent favorite. Indeed, across more than 700 attendees in our listening sessions, the \\npredominant discussion tackled how constituents can achieve a consensus vision for AI-enabled \\nedtech where humans are firmly at the center. The Blueprint for an AI Bill of Rights similarly calls \\nfor “access to timely human consideration and remedy by a fallback and escalation process if an \\nautomated system fails, it produces an error, or you would like to appeal or contest its impacts…” \\nBuilding on this consensus, we call upon all constituents to adopt “humans in the loop” as a key \\ncriterion for educational use of AI.  \\nWe envision a technology-enhanced future more like an electric bike and less like robot \\nvacuums. On an electric bike, the human is fully aware and fully in control, but their burden is \\nless, and their effort is multiplied by a complementary technological enhancement. Robot \\nvacuums do their job, freeing the human from involvement or oversight.  \\nAlthough teachers should not be the only humans involved in loops, Figure 5 provided examples \\nof three types of teacher loops that are central to education and can be used to illustrate what \\n“human in the loop” means. Here, we use the example of an AI chatbot to elaborate on the \\nmeaning of the loops. First, as students become involved in extended interactions with AI \\nchatbots, teachers will need to educate students about safe AI use, monitor their use, and provide \\nhuman recourse when things go astray. Second, teachers are beginning to use chatbots to plan \\npersonalized instruction for their students; they will need to be involved in loops with other \\nteachers to understand effective prompts, to know how to analyze AI-generated lesson plans for \\nflaws, and to avoid the human tendency to overly trust AI systems and underapply human \\njudgement. Third, teachers need to be involved in the design and evaluation of AI systems before \\nthey are used in classrooms and when needs for improvement are observed. In one example, to \\ndesign AI-generated homework support for students, teachers’ in-depth understanding of the'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 57, 'page_label': '58', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"54 \\ncognitive, motivational, and social supports their students need will provide much-needed \\nguidance as a homework-support chatbot is designed.  \\nIn framing AI in education, this report advances a key recommendation of “human in the loop” \\nAI because the phrase readily communicates a criterion that everyone can use as they determine \\nwhich AI-enabled systems and tools are appropriate for use in teaching and learning. In a rather \\ntechnical field, human in the loop is an approachable and humanistic criterion. Rather than \\nsuggesting that AI-enabled systems and tools should replace teachers, this term instead solidifies \\nthe central role of educators as instructors and instructional decision makers, while reinforcing \\nthe responsibility of teachers to exercise judgement and control over the use of AI in education. \\nIt resonates with the important idea of feedback loops, which are highly important to how \\npeople teach and learn. It also aligns with the ideas of inspectable, explainable, severable, and \\noverridable AI.  \\nThe Department agrees with listening session participants who argued that teachers should not \\nbe the only humans in the loop and calls upon parents, families, students, policy makers, and \\nsystem leaders to likewise examine the “loops” for which they are responsible, critically analyze \\nthe increasing role of AI in those loops, and determine what they need to do to retain support for \\nthe primacy of human judgement in educational systems. \\nRecommendation #2: Align AI Models to a Shared Vision for Education \\n“All models are wrong, but some are useful.”  \\n —George Box, Statistician \\nAs we have discussed across every section of this report, AI technologies are grounded in models, \\nand these models are inevitably incomplete in some way. It is up to humans to name educational \\ngoals and measure the degree to which models fit and are useful—or don’t fit and might be \\nharmful. Such an assessment of how well certain tools serve educational priorities may seem \\nobvious, but the romance of technology can lead to a “let’s see what the tech can do'' attitude, \\nwhich can weaken the focus on goals and cause us to adopt models that fit our priorities poorly.  \\nHere we call upon educational policy and decision makers at the local, state, and federal level to \\nuse their power to align priorities, educational strategies, and technology adoption decisions to \\nplace the educational needs of students ahead of the excitement about emerging AI capabilities. \\nWe want to strengthen their attention to existing state, district, and school-level policies that \\nguide edtech adoption and use, such as the four levels of evidence in ESSA, the privacy \\nrequirements of FERPA, and enhanced policies to come. Local education leaders know best what \\ntheir urgent educational priorities are. Every conversation about AI (or any emerging \\ntechnology) should start with the educational needs and priorities of students front and center \\nand conclude with a discussion about the evaluation of effectiveness re-centered on those needs \\nand priorities. Equity, of course, is one of those priorities that requires constant attention, \\nespecially given the worrisome consequences of potentially biased AI models.  \\nWe especially call upon leaders to avoid romancing the magic of AI or only focusing on \\npromising applications or outcomes, but instead to interrogate with a critical eye how AI-enabled \\nsystems and tools function in the educational environment. We ask leaders to distrust broad \\nclaims and ask six types of questions, listed below. Throughout this report, we elaborated on\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 58, 'page_label': '59', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='55 \\nwhich characteristics of AI model use in education are most important to evaluate for alignment \\nto intended educational goals. To aid leaders, we summarize our insights about AI models and \\ntheir use in educational tools and systems in Figure 14.  \\nFigure 14: Recommendation for desired qualities of AI tools and systems in education \\n \\nIn this figure, we center teaching and learning in all considerations about the suitability of an AI \\nmodel for an educational use. Humans remain in the loop of defining, refining, and using AI \\nmodels. We highlight the six desirable characteristics of AI models for education (elaborating \\nfrom principles in the Blueprint for an AI Bill of Rights to fit the specifics of educational systems): \\n1. Alignment of the AI Model to Educators’ Vision for Learning: When choosing to use AI \\nin educational systems, decision makers prioritize educational goals, the fit to all we know \\nabout how people learn, and alignment to evidence-based best practices in education. \\n2. Data Privacy: Ensuring security and privacy of student, teacher, and other human data in \\nAI systems is essential. \\n3. Notice and Explanation: Educators can inspect edtech to determine whether and how AI \\nis being incorporated within edtech systems. Educators’ push for AI models can explain \\nthe basis for detecting patterns and/or for making recommendations, and people retain \\ncontrol over these suggestions. \\n4. Algorithmic Discrimination Protections: Developers and implementers of AI in \\neducation take strong steps to minimizing bias and promoting fairness in AI models.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 59, 'page_label': '60', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='56 \\n5. Safe and Effective Systems: The use of AI models in education is based on evidence of \\nefficacy (using standards already established in education for this purpose) and work for \\ndiverse learners and in varied educational settings. \\n6. Human Alternatives, Consideration and Feedback: AI models that support transparent, \\naccountable, and responsible use of AI in education by involving humans in the loop to \\nensure that educational values and principles are prioritized. \\nAlthough we first address our recommendation to interrogate how educational systems use AI \\nmodels to educational leaders who adopt technologies, other leaders also have integral roles to \\nplay. Teachers and students, as well as their families/caregivers, contribute significantly to \\nadoption decisions also. And leaders and parents must support educators when they question or \\noverride an AI model based on their professional wisdom. Developers of technologies need to be \\nforthcoming about the models they use, and we may need policymakers to create requirements \\nfor disclosure so that the marketplace can function on the basis of information about AI models \\nand not only by the claims of their benefits. \\nWe also emphasize the need for a government role. AI models are made by people and are only \\nan approximation to reality. Thus, we need policies that require transparency about the AI \\nmodels that are embedded in educational systems, as well as models that are inspectable, \\nexplainable, and overridable. Our listening sessions featured constituent calls for government \\ndoing more to hold developers accountable for disclosing the types of AI models they employ in \\nlarge-scale products and the safeguards included in their systems. Government leaders can make \\na positive contribution to market conditions that enable building trust as AI systems are \\nprocured and implemented in education. We discuss these guidelines more in recommendation \\n#4, which is about building trust. \\nRecommendation #3: Design Using Modern Learning Principles \\nWe call for the R&D sector to ensure that product designs are based on best and most current \\nprinciples of teaching and learning. The first decade of adaptivity in edtech drew upon many \\nimportant principles, for example, around how to sequence learning experiences and how to \\ngive students feedback. And yet the underlying conception was often deficit-based. The system \\nfocused on what was wrong with the student and chose pre-existing learning resources that \\nmight fix that weakness. Going forward, we must harness AI’s ability to sense and build upon \\nlearner strengths. Likewise, the past decade of approaches was individualistic, and yet we know \\nthat humans are fundamentally social and that learning is powerfully social. Going forward, we \\nmust build on AI capabilities that connect with principles of collaborative and social learning and \\nwhich respect the student not just for their cognition but also for the whole human skill set. \\nGoing forward, we also must seek to create AI systems that are culturally responsive and \\nculturally sustaining, leveraging the growth of published techniques for doing so. Further, most \\nearly AI systems had few specific supports for students with disabilities and English learners. \\nGoing forward, we must ensure that AI-enabled learning resources are intentionally inclusive of \\nthese students. The field has yet to develop edtech that builds upon each student’s ability to \\nmake choices and to self-regulate in increasingly complex environments. We have to develop \\nedtech that expands students’ abilities to learn in creative modes and to expand their ability to \\ndiscuss, write, present, and lead. \\nWe also call upon educators to reject uses of AI that are based solely on machine learning from \\ndata—without triangulation based on learning theory and knowledge from practice. Achieving'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 60, 'page_label': '61', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='57 \\neffective and equitable educational systems requires more than processing “big data,” and \\nalthough we want to harness insights from data, human interpretation of data remains highly \\nimportant. We reject a technological determinism in which patterns in data, on their own, tell us \\nwhat to do. Applications of AI in education must be grounded in established, modern learning \\nprinciples, the wisdom of educational practitioners, and should leverage the expertise in the \\neducational assessment community around detecting bias and improving fairness.  \\nRecommendation #4: Prioritize Strengthening Trust \\nTechnology can only help us to achieve educational objectives when we trust it. Yet, our listening \\nsessions revealed the ways in which distrust of edtech and AI is commonplace. Constituents \\ndistrust emerging technologies for multiple reasons. They may have experienced privacy \\nviolations. The user experience may be more burdensome than anticipated. Promised increases \\nin student learning may not be backed by efficacy research. They may have experienced \\nunanticipated consequences. Unexpected costs may arise. Constituents may distrust complexity. \\nTrust needs to incorporate safety, usability, and efficacy. \\nThe Department firmly takes the stance that constituents want AI that supports teachers and \\nrejects AI visions that replace teachers. And yet, teachers, students, and their families/caregivers \\nneed support to build appropriate levels of trust in systems that affect their work. In the broader \\necosystem, trustworthy AI is recognized as a multidimensional problem (including the \\ndimensions of Figure 14, above). If every step forward does not include strong elements of trust \\nbuilding, we worry that distrust will distract from innovation serving the public good that AI \\ncould help realize. \\nWe expect that associations and societies have a key role in strengthening trust. Some important \\nassociations like the State Educational Technology Directors Association and the Consortium for \\nSchool Network work with edtech leaders, and parallel organizations like EDUCAUSE work with \\npostsecondary leaders. Other associations and societies work with teachers, education leaders, \\nand education staff developers. Industry networks, like the EdSAFE AI Alliance, can bring \\ntogether industry leaders to work together to foster trust. Additional societies bring researchers \\ntogether. These societies and associations have the reach necessary to bring all parts of the \\neducational ecosystem into discussions about trust and also the ability to represent the views of \\ntheir constituents in cross-cutting policy discussions. \\nRecommendation #5: Inform and Involve Educators \\nOur listening sessions also asked for more specific direction on the question of what education \\nleaders should do (see Figure 15). The most frequent responses fit three clusters: the need for \\nguidelines and guardrails, strengthening the role of teachers, and re-focusing research and \\ndevelopment. These are activities that constituents are asking for and that could expand trust. \\nThe recommendations that follow respond to these requests.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 61, 'page_label': '62', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='58 \\nFigure 15: Listening session attendees prioritized involving practitioners, research, and \\nevaluation and the need for guidelines and guardrails. \\n \\nIn particular, one concern that repeatedly arose in our listening sessions was the potential for AI \\nto result in less respect for educators or less value for their skills. Across the nation, we are now \\nresponding to decreasing interest in entering or remaining in the teaching profession. Now is the \\ntime to show the respect and value we hold for educators by informing and involving them in \\nevery step of the process of designing, developing, testing, improving, adopting, and managing \\nAI-enabled edtech. This includes involving educators in reviewing existing AI-enabled systems, \\ntools, and data use in schools, designing new applications of AI based on teacher input, carrying \\nout pilot evaluations of proposed new instructional tools, collaborating with developers to \\nincrease the trustworthiness of the deployed system, and raising issues about risks and \\nunexpected consequences as the system is implemented. \\nWe have already seen educators rise to the challenge of creating overall guidelines, designing \\nspecific uses of available AI-enabled systems and tools, and ferreting out concerns. And yet, the \\ninfluence of educators in the future of AI-enabled products cannot be assumed; instead, \\nconstituents need policies that put muscle behind it. Could we create a national corps of leading \\neducators representing every state and region to provide leadership? Could we commit to \\ndeveloping necessary professional development supports? Can we find ways to compensate \\neducators so they can be at the forefront of designing the future of education? Our policies \\nshould enable educators to be closely involved in design of AI-enabled educational systems. \\nAlthough we know that the responsibility for informing and involving educators must be \\ndistributed at all levels of national and school governance, the Office of Educational Technology'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 62, 'page_label': '63', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='59 \\ncan play a key role in informing and involving educators through its reports, events, outreach, \\nand in a future NETP. Although examples above refer to K-12 teachers, higher education \\ninstructors must also be included. We also call on the edtech industry to involve educators \\nthroughout their design and development processes. For example, AI-enabled teaching assistants \\nare only likely to help teachers do their job if teachers are thoroughly involved as the assistants \\nare designed. We call upon institutions that prepare teachers to integrate technology more \\nsystematically into their programs; for example, the use of technology in teaching and learning \\nshould be a core theme across teacher preparation programs, not an issue that arises only in one \\ncourse. \\nRecommendation #6: Focus R&D on Addressing Context and \\nEnhancing Trust and Safety \\nResearch that focuses on how AI-enabled systems can adapt to context (including variability \\namong learners) in instructional approaches and across educational settings is essential to \\nanswering the question of, “Do specific applications of AI work in education, and if so, for whom \\nand under what conditions?” The italicized phrase points to variability among learners and \\ndiversity in the settings for learning. We call upon innovators in R&D to focus their efforts to \\nadvance AI on the long tail of learning variability, where large populations of students would \\nbenefit from customization of learning. We also call on R&D to lead by establishing how trust \\ncan be strengthened in AI-enabled systems, building on the Blueprint’s call for safe and effective \\nsystems yet also including education-specific requirements, such as how teachers can be \\nmeaningfully involved in design phases, not only in implementation and evaluation. \\nAlthough many products today are adaptive, some adapt on just one or a few dimensions of \\nvariability, such as student’s accuracy in problem solving. As teachers know, there are many \\nmore important ways to adapt to students’ strengths and needs. Students are neurodiverse and \\nmay have specific disabilities. They bring different assets from their experiences at home, in \\ncommunities, and in their cultures. They have different interests and motivations. They are in \\ndifferent places in their journeys to master the English language. And they learn in varied \\nsettings. Classrooms and schools are different, and at home, students learn in informal settings in \\nways that could complement school learning. We recommend attention to “context” as a means \\nfor expressing the multiple dimensions that must be considered when elaborating the phrase \\n“for whom and under what conditions.” We also acknowledge the role of researchers in \\nconducting evaluations, which must now consider not only efficacy but must also explore where \\nharm may arise and the system problems that can occur through weak trust or over-trust in AI \\nsystems. \\nR&D must take the lead in making AI models more context-sensitive and ensuring that they are \\neffective, safe, and trustworthy for use with varied learners in diverse settings. Although AI has \\ncapabilities to find patterns beyond the limited number of variables that people normally think \\nabout, AI is not particularly good at understanding and working with context in the ways people \\ndo. Over time, we’ve seen learning sciences grow to be less about individualistic cognitive \\nprinciples and more encompassing first of social learning and then of the many dimensions of \\ncontext that matter in learning. Our use of AI needs to follow this trajectory toward context to \\nsupport educational applications. \\nTo achieve human-centric vision, listening session attendees argued that teams will need time \\nand freedom to explore how best to manage the tension between the pace of technological'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 63, 'page_label': '64', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='60 \\nadvancement and the need for broader contextual insights—for trust and for safety. They will \\nneed time and freedom to pioneer new processes that better involve teachers and students as co-\\ndesigners, with attention to balancing power dynamics. And they will need to shift attention \\nfrom older ways of framing priorities (such as achievement gaps) to new ways of prioritizing \\ndigital equity. We call on R&D funders to focus resources on the long tail of learner variability, \\nthe need for AI-enabled systems that better incorporate context, and time required to get \\ncontextual considerations right. We call upon researchers and developers to prioritize challenges \\nof context, trust, and safety in their work to advance AI.  \\nRecommendation #7: Develop Education-Specific Guidelines and \\nGuardrails \\nOur final recommendation is central to policymakers. A feature of the American educational \\nsystem is the emphasis on local decision making. With technology growing in complexity at such \\na rapid pace, it is becoming difficult for local leaders to make informed decisions about the \\ndeployment of artificial intelligence. As we have discussed, the issues are not only data privacy \\nand security but extend to new topics such as bias, transparency, and accountability. It will be \\nharder to evaluate promising edtech platforms that rely on AI systems against this evolving, \\ncomplex set of criteria.  \\nRegulations related to key student and family data privacy laws like the Family Educational \\nRights & Privacy Act (FERPA), the Children’s Internet Privacy Act (CIPA), and the Children’s \\nOnline Privacy Protection Act (COPPA) warrant review and further consideration in light of new \\nand emerging technologies in schools. Laws such as the Individuals with Disabilities Education \\nAct (IDEA) may likewise be considered as new situations arise in the use of AI-enabled learning \\ntechnologies. As discussed throughout this document, the Blueprint for an AI Bill of Rights is an \\nimportant framework throughout this work.  \\nThe Department encourages parallel work by constituents in all levels of the educational system. \\nIn addition to the key federal laws cited immediately above, many states have also passed privacy \\nlaws that govern the use of educational technology and edtech platforms in classrooms. Further \\nconstituents can expect general frameworks for responsible AI in parallel sectors like health, \\nsafety, and consumer products to be informative but not sufficient for education’s specific needs. \\nLeaders at every level need awareness of how this work reaches beyond implications for privacy \\nand security (e.g., to include awareness of potential bias and unfairness), and they need \\npreparation to effectively confront the next level of issues.  \\nNext Steps \\nWe are heartened to see intensifying discussions throughout the educational ecosystem about \\nthe role of AI. We see progress that we can build upon occurring, as constituents discuss these \\nthree types of questions: What are the most significant opportunities and risks? How can we \\nachieve trustworthy educational AI? How can we understand the models at the heart of \\napplications of AI and ensure they have the qualities that align to educational aspirations?  \\nThe Department developed this report with awareness of contributions arising from many types \\nof organizations and collectives. Internationally, we recognize parallel efforts to consider AI in \\nthe European Union, at the United Nations, and indeed throughout the world. We are aware of \\nprogress being led by organizations such as UNESCO, the EdSAFE AI Alliance, and research'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 64, 'page_label': '65', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='61 \\norganizations in many countries. We plan to continue cross-agency work, for example, by \\ncontinuing to coordinate with the Office of Science and Technology Policy and other Federal \\nagencies as agencies implement next steps guided by the Blueprint for an AI Bill of Rights. We see a \\nbroad and fertile context for necessary next steps:  \\n● Working within this context and with others, the Department will consider specific \\npolicies and regulations so that educators can realize the opportunities of AI in edtech \\nwhile minimizing risks. For example, the Department is developing a set of AI usage \\nscenarios to strengthen the process of evaluating and enhancing policies and regulations. \\nThe principles and practices in the Blueprint for an AI Bill of Rights will be used to ensure \\nthe scenarios mitigate important risks and harms.  \\n● Working with constituents (including education leaders; teachers, faculty, support staff, \\nand other educators; researchers; policymakers; funders; technology developers; \\ncommunity members and organizations; and above all, learners and their \\nfamilies/caregivers), we will develop additional resources and events to increase \\nunderstanding of AI and to involve those who will be most affected by these new \\ntechnologies.  \\n● Working across sectors, such as education, innovation, research, and policy, we will revise \\nand update the NETP to guide all constituents toward safe, equitable, and effective AI in \\neducation in the United States, in alignment with our overall educational priorities.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 65, 'page_label': '66', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='62 \\nCommon Acronyms and \\nAbbreviations \\n⚫ AES: Automated Essay Scoring \\n⚫ AI: Artificial Intelligence \\n⚫ CIPA: Children’s Internet Protection Act \\n⚫ COPPA: Children’s Online Privacy Protection Act \\n⚫ Edtech: Educational Technology \\n⚫ ESEA: Elementary and Secondary Education Act \\n⚫ ESSA: Every Student Succeeds Act \\n⚫ FERPA: Family Educational Rights and Privacy Act \\n⚫ IA: Intelligence Augmentation \\n⚫ IDEA: Individuals with Disabilities Education Act \\n⚫ IEP: Individualized Education Program \\n⚫ ITS: Intelligent Tutoring Systems \\n⚫ NETP: National Education Technology Plan \\n⚫ R&D: Research & Development'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 66, 'page_label': '67', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='63 \\nAcknowledgements \\nProject Team \\nArtificial Intelligence and the Future of Teaching and Learning was developed under the leadership \\nand guidance of Roberto J. Rodríguez, Assistant Secretary for the Office of Planning, Evaluation, \\nand Policy Development, Kristina Ishmael, Deputy Director of the Office of Educational \\nTechnology, and Bernadette Adams, Senior Policy Advisor for the Office of Educational \\nTechnology at the U.S. Department of Education.  \\nSupport for the creation of this document was provided by Digital Promise, led by Jeremy \\nRoschelle with Carly Chillmon, Judi Fusco, Gabrielle Lue, Eric Nentrup, My Nguyen, Pati \\nRuiz, and Zohal Shah. Special thanks to Center for Integrative Research in Computing and \\nLearning Sciences postdocs Michael Chang and Aditi Mallavarapu. \\nListening Session Panelists and Hosts\\nHal Abelson \\nRyan Baker \\nNancye Blair Black \\nMarcelo Aaron Bonilla \\nWorsley \\nMichael Chang \\nCarly Chillmon \\nSherice Clarke \\nTammy Clegg \\nSidney d’Mello \\nJudi Fusco \\nDragan Gasevic \\nKip Glazer \\nJanice Gobert \\nSarah Hampton \\nKristina Ishmael \\nJim Larimore \\nNicol Turner Lee \\nSherry Loftin \\nGabrielle Lue \\nAditi Mallavarapu \\nOle Molvig \\nPeter Norvig \\nThomas Philip \\nVidula Plante \\nJeremy Roschelle \\nPati Ruiz \\nAlina Von Davier \\nErin Walker \\nDiego Zapata \\nWe also thank 1,075 people who registered for Listening Sessions and 700 who attended.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 67, 'page_label': '68', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"64 \\nReferences \\nAkgun, S., Greenhow, C. (2022). Artificial intelligence in education: Addressing ethical \\nchallenges in K-12 settings. AI Ethics, 2, 431–440. https://doi.org/10.1007/s43681-021-\\n00096-7 \\nAleven, V., McLaughlin, E. A., Glenn, R. A., & Koedinger, K. R. (2016). Instruction based on \\nadaptive learning technologies. In Mayer, R.E. & Alexander, P.A., Handbook of research on \\nlearning and instruction, 522-560. ISBN: 113883176X \\nBaker, R.S., Esbenshade, L., Vitale, J., & Karumbaiah, S. (2022). Using demographic data as \\npredictor variables: A questionable choice. https://doi.org/10.35542/osf.io/y4wvj \\nBlack, P. & Wiliam, D. (1998). Inside the black box: Raising standards through classroom \\nassessment. Phi Delta Kappan, 92(1), 81-90. https://kappanonline.org/inside-the-black-\\nbox-raising-standards-through-classroom-assessment/ \\nBlack, P., & Wiliam, D. (2009). Developing the theory of formative assessment. Educational \\nAssessment, Evaluation and Accountability, 21(1), 5-31. https://doi.org/10.1007/s11092-008-\\n9068-5 \\nBoden, M.A. (2018). Artificial intelligence: A very short introduction. Oxford. ISBN: 978-0199602919 \\nBryant, J., Heitz,C., Sanghvi, S., & Wagle, D. (2020, January 14). How artificial intelligence will \\nimpact K-12 teachers. McKinsey. https://www.mckinsey.com/industries/education/our-\\ninsights/how-artificial-intelligence-will-impact-k-12-teachers \\nCelik, I., Dindar, M., Muukkonen, H. & Järvelä, S. (2022). The promises and challenges of \\nartificial intelligence for teachers: A systematic review of research. TechTrends, 66, 616–\\n630. https://doi.org/10.1007/s11528-022-00715-y \\nCenter for Integrative Research in Computing and Learning Sciences (CIRCLS). (2022, Feb.). \\nFrom Broadening to empowering: Reflecting on the CIRCLS’21 Convening. \\nhttps://circls.org/circls21report \\nChen, C., Park, H.W. & Breazeal, C. (2020). Teaching and learning with children: Impact of \\nreciprocal peer learning with a social robot on children’s learning and emotive \\nengagement. Computers & Education, 150, https://doi.org/10.1016/j.compedu.2020.103836 \\nChen, G., Clarke, S., & Resnick, L.B. (2015). Classroom Discourse Analyzer (CDA): A discourse \\nanalytic tool for teachers. Technology, Instruction, Cognition and Learning, 10(2), 85-105 \\nDieterle, E., Dede, C. & Walker, M. (2022). The cyclical ethical effects of using artificial \\nintelligence in education. AI & Society. https://link.springer.com/article/10.1007/s00146-\\n022-01497-w \\nDoewes, A. & Pechenizkiy, M. (2021). On the limitations of human-computer agreement in \\nautomated essay scoring. In Proceedings of the 14th International Conference on Educational \\nData Mining (EDM21). \\nhttps://educationaldatamining.org/EDM2021/virtual/static/pdf/EDM21_paper_243.pdf \\nEnglebart, D.C. (October 1962). Augmenting human intellect: A conceptual framework. SRI Summary \\nReport AFOSR-3223. https://www.dougengelbart.org/pubs/augment-3906.html \\nErsozlu, Z., Ledger, S., Ersozlu, A., Mayne, F., & Wildy, H. (2021). Mixed-reality learning \\nenvironments in teacher education: An analysis of TeachLivETM Research. SAGE Open, \\n11(3). https://doi.org/10.1177/21582440211032155. \\nEuropean Commission, Directorate-General for Education, Youth, Sport and Culture. \\n(2022). Ethical guidelines on the use of artificial intelligence (AI) and data in teaching and \\nlearning for educators. Publications Office of the European \\nUnion. https://data.europa.eu/doi/10.2766/153756 \\nForsyth, S., Dalton, B., Foster, E.H., Walsh, B., Smilack, J., & Yeh, T. (2021, May). Imagine a more \\nethical AI: Using stories to develop teens' awareness and understanding of artificial \\nintelligence and its societal impacts. In 2021 Conference on Research in Equitable and \\nSustained Participation in Engineering, Computing, and Technology (RESPECT). IEEE. \\nhttps://doi.org/10.1109/RESPECT51740.2021.9620549 \\nFriedman, L., Blair Black, N., Walker, E., & Roschelle, J. (November 8, 2021) Safe AI in education \\nneeds you. Association of Computing Machinery BLOG@ACM, \\nhttps://cacm.acm.org/blogs/blog-cacm/256657-safe-ai-in-education-needs-you/fulltext\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 68, 'page_label': '69', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='65 \\nGardner, J., O\\'Leary, M. & Yuan, L. (2021). Artificial intelligence in educational assessment: \\n\"Breakthrough? Or buncombe and ballyhoo?\" Journal of Computer Assisted Learning, 37(5), \\n1207–1216. https://doi.org/10.1111/jcal.12577 \\nGartner (n.d.) Gartner glossary: Augmented intelligence. Gartner. \\nhttps://www.gartner.com/en/information-technology/glossary/augmented-intelligence \\nGay, G. (2018). Culturally responsive teaching: Theory, research, and practice. Teachers College Press. \\nISBN: 978-0807758762 \\nGodwin-Jones, R. (2021). Big data and language learning: Opportunities and challenges. \\u2028\\nLanguage Learning & Technology, 25(1), 4–19. http://hdl.handle.net/10125/44747 \\nHammerness, K., Darling-Hammond, L., & Bransford, J. (2005). Preparing teachers for a changing \\nworld: What teachers should learn and be able to do. Jossey-Bass. ISBN: 0787996343 \\nHolmes, W. & Porayska-Pomsta, K. (Eds.) (2022). The ethics of artificial intelligence in education. \\nRoutledge. ISBN 978-0367349721 \\nHolstein, K., McLaren, B.M., & Aleven, V. (2019). Co-designing a real-time classroom \\norchestration tool to support teacher–AI complementarity. Journal of Learning Analytics, \\n6(2). https://doi.org/10.18608/jla.2019.62.3 \\nIEEE-USA Board of Directors. (February 10, 2017). Artificial intelligence research, development and \\nregulation. IEEE http://globalpolicy.ieee.org/wp-content/uploads/2017/10/IEEE17003.pdf \\nJensen, E., Dale, M., Donnelly, P.J., Stone, C., Kelly, S., Godley, A. & D\\'Mello, S.K. (2020). Toward \\nautomated feedback on teacher discourse to enhance teacher learning. In Proceedings of \\nthe 2020 CHI Conference on Human Factors in Computing Systems (CHI \\'20). \\nhttps://doi.org/10.1145/3313831.3376418 \\nKai, S., Almeda, M.V., Baker, R. S., Heffernan, C., & Heffernan, N. (2018). Decision tree modeling \\nof wheel-spinning and productive persistence in skill builders. Journal of Educational Data \\nMining, 10(1), 36–71. https://doi.org/10.5281/zenodo.3344810 \\nKaplan, R.M., & Saccuzzo, D.P. (2017). Psychological testing: Principles, applications, and issues. \\nCengage Learning. \\nKe, Z., & Ng, V. (2019). Automated essay scoring: A survey of the state of the art. In Proceedings of \\nthe Twenty-Eighth International Joint Conference on Artificial Intelligence, 6300–6308. \\nhttps://doi.org/10.24963/ijcai.2019/879 \\nKhosravi, H., Shum, S.B., Chen, G, Conati, C., Tsai,Y-S., Kay, J., Knight, S., Martinez-Maldonado, \\nR., Sadiq, S., Gašević, D. (2022). Explainable artificial intelligence in education. \\nComputers and Education: Artificial Intelligence, 3. \\nhttps://doi.org/10.1016/j.caeai.2022.100074 \\nKulik, J.A., & Fletcher, J.D. (2016). Effectiveness of intelligent tutoring systems: A meta-analytic \\nreview. Review of Educational Research, 86(1), 42–78 \\nMa, W., Adescope, O.O, Nesbit, J.C. & Liu, Q. (2014). Intelligent tutoring systems and learning \\noutcomes: A meta-analysis. Journal of Educational Psychology, 106(4), 901–918. \\nhttp://dx.doi.org/10.1037/a0037123 \\nMaslej, N., Fattorini, L., Brynjolfsson E., Etchemendy, J., Ligett, K., Lyons, T., Manyika, J., Ngo, \\nH., Niebles, J.C., Parli, V., Shoham, Y., Wald, R., Clark, J. and Perrault, R., (2023). The AI \\nindex 2023 annual report. Stanford University: AI Index Steering Committee, Institute for \\nHuman-Centered AI.  \\nMerrill, S. (2020). In schools, are we measuring what matters? Edutopia. \\nhttps://www.edutopia.org/article/schools-are-we-measuring-what-matters \\nMolenaar, I. (2022). Towards hybrid human-AI learning technologies. European Journal of \\nEducation, 00, 1–14. https://doi.org/10.1111/ejed.12527 \\nMostow, J., Aist, G., Burkhead, P., Corbett, A., Cuneo, A., Eitelman, S., Huang, C., Junker, B., \\nSklar, M.B., & Tobin, B. (2003). Evaluation of an automated reading tutor that listens: \\nComparison to human tutoring and classroom instruction. Journal of Educational \\nComputing Research, 29(1), 61–117. https://doi.org/10.2190/06AX-QW99-EQ5G-RDCF \\nMousavinasab, E., Zarifsanaiey, N., R. Niakan Kalhori, S., Rakhshan, M., Keikha, L., & Ghazi \\nSaeedi, M. (2021). Intelligent tutoring systems: A systematic review of characteristics, \\napplications, and evaluation methods. Interactive Learning Environments, 29(1), 142–163. \\nhttps://psycnet.apa.org/doi/10.1080/10494820.2018.1558257 \\nNational Academies of Sciences, Engineering, and Medicine. 2018. How people learn II: Learners, \\ncontexts, and cultures. The National Academies Press. https://doi.org/10.17226/24783'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 69, 'page_label': '70', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"66 \\nNational Research Council. 2000. How people learn: Brain, mind, experience, and school. The \\nNational Academies Press. https://doi.org/10.17226/9853 \\nNentrup, E. (2022). How Policymakers Can Support Educators and Technology Vendors Towards SAFE \\nAI. EdSAFE AI Alliance. https://www.edsafeai.org/post/how-policymakers-can-support-\\naied \\nPage, E.B. (1966). The imminence of grading essays by computer. Phi Delta Kappan, 47(5), 238–\\n243 \\nParis, D., & Alim, H.S. (Eds.). (2017). Culturally sustaining pedagogies: Teaching and learning for \\njustice in a changing world. Teachers College Press. ISBN: 978-0807758342 \\nPlass, J.L., & Pawar, S. (2020). Toward a taxonomy of adaptivity for learning. Journal of Research \\non Technology in Education, 52(3), 275–300. https://doi.org/10.1080/15391523.2020.1719943  \\nRegona, Massimo & Yigitcanlar, Tan & Xia, Bo & Li, R.Y.M. (2022). Opportunities and adoption \\nchallenges of AI in the construction industry: A PRISMA review. Journal of Open \\nInnovation Technology Market and Complexity, 8(45). https://doi.org/10.3390/joitmc8010045 \\nReynolds, C.R., & Suzuki, L.A. (2012). Bias in psychological assessment: An empirical review and \\nrecommendations. Handbook of Psychology, Second Edition. \\nhttps://doi.org/10.1002/9781118133880.hop210004 \\nRitter, S., Anderson, J.R., Koedinger, K.R. & Corbett, A. (2007). Cognitive Tutor: Applied \\nresearch in mathematics education. Psychonomic Bulletin & Review, 14, 249–255/ \\nhttps://doi.org/10.3758/BF03194060 \\nRoll, I., Aleven, V., McLaren, B.M., Koedinger, K.R. (2011). Improving students’ help-seeking \\nskills using metacognitive feedback in an intelligent tutoring system, Learning and \\nInstruction, 21(2), 267–280. https://doi.org/10.1016/j.learninstruc.2010.07.004. \\nRoschelle, J., Dimitriadis, Y. & Hoppe, U. (2013). Classroom orchestration: Synthesis. Computers \\n& Education, 69, 512-526. https://doi.org/10.1016/j.compedu.2013.04.010 \\nRoschelle, J., Feng, M., Murphy, R. & Mason, C.A. (2016). Online mathematics homework \\nincreases student achievement. AERA Open, 2(4), 1-12. DOI: 10.1177/2332858416673968 \\nRoschelle, J., Penuel, W., & Shechtman, N. (2006). Co-design of innovations with teachers: \\ndefinition and dynamics. In Proceedings of the 7th International Conference on Learning \\nSciences, Bloomington, IN. https://doi.dx.org/10.22318/icls2006.606 \\nRose, D. (2000). Universal design for learning. Journal of Special Education Technology, 15(4), 47-51. \\nhttps://doi.org/10.1177/016264340001500407 \\nRuiz, P. & Fusco, J. (2022). Teachers partnering with artificial intelligence: Augmentation and \\nautomation. Digital Promise. https://digitalpromise.org/2022/07/06/teachers-partnering-\\nwith-artificial-intelligence-augmentation-and-automation/ \\nRussell, S. (2019). Human compatible: Artificial intelligence and the problem of control. Viking. ISBN \\n978-0-525-55861-3. \\nShao, Q., Sniffen, A., Blanchet, J., Hillis, M.E., Shi, X., Haris, T.K., & Balkcom, D. (2020). \\nTeaching american sign language in mixed reality. Proceedings of the ACM on Interactive, \\nMobile, Wearable and Ubiquitous Technologies, 4(4), 1-27. https://doi.org/10.1145/3432211 \\nSharples, M. & Pérez y Pérez, R. (2022). Story machines: How computers have become creative writers. \\nRoutledge. ISBN 9780367751951 \\nShemshack, A., Spector, J.M. (2020) A systematic literature review of personalized learning \\nterms. Smart Learning Environments, 7(33). https://doi.org/10.1186/s40561-020-00140-9 \\nShute, V J. (2008). Focus on formative feedback. Review of Educational Research, 78(1), 153–189. \\nhttps://doi.org/10.3102/0034654307313795 \\nShute, V. J., Ventura, M., & Kim, Y. J. (2013). Assessment and learning of qualitative physics in \\nNewton's Playground. The Journal of Educational Research, 106(6), 423-430. \\nhttps://doi.org/10.1080/00220671.2013.832970 \\nSwiecki, Z., Khosravi, H., Chen, G., Martinez-Maldonado, R., Lodge, J.M., Milligan, S., Selwyn, B. \\n& Gašević,D. (2022). Assessment in the age of artificial intelligence. Computers and \\nEducation: Artificial Intelligence, 3. https://doi.org/10.1016/j.caeai.2022.100075 \\nThe White House (February 17, 2023). Executive order on further advancing racial equity and support \\nfor underserved communities through the federal government. \\nhttps://www.whitehouse.gov/briefing-room/presidential-actions/2023/02/16/executive-\\norder-on-further-advancing-racial-equity\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 70, 'page_label': '71', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='67 \\nThe White House (September 8, 2022). Readout of White House listening session on tech platform \\naccountability. https://www.whitehouse.gov/briefing-room/statements-\\nreleases/2022/09/08/readout-of-white-house-listening-session-on-tech-platform-\\naccountability/ \\nU.S. Department of Education, Office of Educational Technology (2022). Advancing digital equity \\nfor all: Community-based recommendations for developing effective digital equity plans to close the \\ndigital divide and enable technology-empowered learning. US Department of Education. \\nU.S. Department of Education, Office of Educational Technology. (2010). Transforming American \\nEducation: Learning Powered by Technology. U.S. Department of Education. p. 78 \\nVan Lehn, K. (2011) The relative effectiveness of human tutoring, intelligent tutoring systems, \\nand other tutoring systems. Educational Psychologist, 46(4), 197-221. \\nhttps://doi.org/10.1080/00461520.2011.611369 \\nWagner, A.R., Borenstein, J. & Howard, A. (September 2018). Overtrust in the robotics age. \\nCommunications of the ACM, 61(9), 22-24. https://doi.org/10.1145/3241365 \\nWalker, E., Rummel, N. & Koedinger, K.R. (2015). Adaptive intelligent support to improve peer \\ntutoring in algebra. International Journal of Artificial Intelligence in Education, 24, 33–61 \\nhttps://doi.org/10.1007/s40593-013-0001-9 \\nWalton Family Foundation (March 1, 2023). Teachers and students embrace ChatGPT for education. \\nhttps://www.waltonfamilyfoundation.org/learning/teachers-and-students-embrace-\\nchatgpt-for-education \\nWebb, N.M., & Farivar, S. (1994). Promoting helping behavior in cooperative small groups in \\nmiddle school mathematics. American Educational Research Journal, 31(2), 369–395. \\nhttps://doi.org/10.3102/00028312031002369 \\nWhite House Office of Science and Technology Policy (October 2022), Blueprint for an AI bill of \\nrights: Making automated systems work for the American people. The White House Office of \\nScience and Technology Policy. https://www.whitehouse.gov/ostp/ai-bill-of-rights/  \\nWiggins, G. (2015). Seven keys to effective feedback. ACSD. https://www.ascd.org/el/articles/seven-\\nkeys-to-effective-feedback \\nWinne, P.H. (2021). Open learner models working in symbiosis with self-regulating learners: A \\nresearch agenda. International Journal of Artificial Intelligence in Education, 31(3), 446-459. \\nhttps://doi.org/10.1007/s40593-020-00212-4 \\nZacamy, J. & Roschelle, J. (2022). Navigating the tensions: How could equity-relevant research also be \\nagile, open, and scalable? Digital Promise. http://hdl.handle.net/20.500.12265/159 \\nZhai, X., He, P., Krajcik, J. (2022). Applying machine learning to automatically assess scientific \\nmodels. Journal of Research in Science Teaching. https://doi.org/10.1002/tea.21773 \\nZhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., & Breazeal, C. (2022). Integrating ethics and \\ncareer futures with technical learning to promote AI literacy for middle school students: \\nAn exploratory study. International Journal of Artificial Intelligence in Education, 1–35. \\nhttps://doi.org/10.1007/s40593-022-00293-3'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 0, 'page_label': '1', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='Attention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser ∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.0 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature.\\n1 Introduction\\nRecurrent neural networks, long short-term memory [12] and gated recurrent [7] neural networks\\nin particular, have been ﬁrmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 29, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [31, 21, 13].\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 1, 'page_label': '2', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='Recurrent models typically factor computation along the symbol positions of the input and output\\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\\nstates ht, as a function of the previous hidden state ht−1 and the input for position t. This inherently\\nsequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsigniﬁcant improvements in computational efﬁciency through factorization tricks [18] and conditional\\ncomputation [26], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [2, 16]. In all but a few cases [22], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for signiﬁcantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2 Background\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[20], ByteNet [15] and ConvS2S [8], all of which use convolutional neural networks as basic building\\nblock, computing hidden representations in parallel for all input and output positions. In these models,\\nthe number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difﬁcult to learn dependencies between distant positions [ 11]. In the Transformer this is\\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribed in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 22, 23, 19].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [28].\\nTo the best of our knowledge, however, the Transformer is the ﬁrst transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [14, 15] and [8].\\n3 Model Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 29].\\nHere, the encoder maps an input sequence of symbol representations (x1,...,x n) to a sequence\\nof continuous representations z = (z1,...,z n). Given z, the decoder then generates an output\\nsequence (y1,...,y m) of symbols one element at a time. At each step the model is auto-regressive\\n[9], consuming the previously generated symbols as additional input when generating the next.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1 Encoder and Decoder Stacks\\nEncoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. The ﬁrst is a multi-head self-attention mechanism, and the second is a simple, position-\\n2'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 2, 'page_label': '3', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='Figure 1: The Transformer - model architecture.\\nwise fully connected feed-forward network. We employ a residual connection [10] around each of\\nthe two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\\nLayerNorm(x+ Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.\\nDecoder: The decoder is also composed of a stack of N = 6identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\\npredictions for position ican depend only on the known outputs at positions less than i.\\n3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1 Scaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\n3'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 3, 'page_label': '4', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='Scaled Dot-Product Attention\\n Multi-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nquery with all keys, divide each by √dk, and apply a softmax function to obtain the weights on the\\nvalues.\\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\\ninto a matrix Q. The keys and values are also packed together into matrices Kand V. We compute\\nthe matrix of outputs as:\\nAttention(Q,K,V ) = softmax(QKT\\n√dk\\n)V (1)\\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\\nof 1√dk\\n. Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\\nmuch faster and more space-efﬁcient in practice, since it can be implemented using highly optimized\\nmatrix multiplication code.\\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\\ndot product attention without scaling for larger values of dk [3]. We suspect that for large values of\\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\\nextremely small gradients 4. To counteract this effect, we scale the dot products by 1√dk\\n.\\n3.2.2 Multi-Head Attention\\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,\\nwe found it beneﬁcial to linearly project the queries, keys and values htimes with different, learned\\nlinear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of\\nqueries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\\noutput values. These are concatenated and once again projected, resulting in the ﬁnal values, as\\ndepicted in Figure 2.\\nMulti-head attention allows the model to jointly attend to information from different representation\\nsubspaces at different positions. With a single attention head, averaging inhibits this.\\n4To illustrate why the dot products get large, assume that the components of q and k are independent random\\nvariables with mean 0 and variance 1. Then their dot product, q · k = ∑dk\\ni=1 qiki, has mean 0 and variance dk.\\n4'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 4, 'page_label': '5', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='MultiHead(Q,K,V ) = Concat(head1,..., headh)WO\\nwhere headi = Attention(QWQ\\ni ,KW K\\ni ,VW V\\ni )\\nWhere the projections are parameter matricesWQ\\ni ∈Rdmodel×dk , WK\\ni ∈Rdmodel×dk , WV\\ni ∈Rdmodel×dv\\nand WO ∈Rhdv×dmodel .\\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\\ndk = dv = dmodel/h= 64. Due to the reduced dimension of each head, the total computational cost\\nis similar to that of single-head attention with full dimensionality.\\n3.2.3 Applications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[31, 2, 8].\\n• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\\nand queries come from the same place, in this case, the output of the previous layer in the\\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder.\\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward\\ninformation ﬂow in the decoder to preserve the auto-regressive property. We implement this\\ninside of scaled dot-product attention by masking out (setting to −∞) all values in the input\\nof the softmax which correspond to illegal connections. See Figure 2.\\n3.3 Position-wise Feed-Forward Networks\\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\\nconnected feed-forward network, which is applied to each position separately and identically. This\\nconsists of two linear transformations with a ReLU activation in between.\\nFFN(x) = max(0,xW1 + b1)W2 + b2 (2)\\nWhile the linear transformations are the same across different positions, they use different parameters\\nfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.\\nThe dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality\\ndff = 2048.\\n3.4 Embeddings and Softmax\\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input\\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\\nmation and softmax function to convert the decoder output to predicted next-token probabilities. In\\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\\nlinear transformation, similar to [24]. In the embedding layers, we multiply those weights by √dmodel.\\n3.5 Positional Encoding\\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\\norder of the sequence, we must inject some information about the relative or absolute position of the\\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\\n5'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 5, 'page_label': '6', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\\nfor different layer types. nis the sequence length, dis the representation dimension, kis the kernel\\nsize of convolutions and rthe size of the neighborhood in restricted self-attention.\\nLayer Type Complexity per Layer Sequential Maximum Path Length\\nOperations\\nSelf-Attention O(n2 ·d) O(1) O(1)\\nRecurrent O(n·d2) O(n) O(n)\\nConvolutional O(k·n·d2) O(1) O(logk(n))\\nSelf-Attention (restricted) O(r·n·d) O(1) O(n/r)\\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\\nas the embeddings, so that the two can be summed. There are many choices of positional encodings,\\nlearned and ﬁxed [8].\\nIn this work, we use sine and cosine functions of different frequencies:\\nPE(pos,2i) = sin(pos/100002i/dmodel )\\nPE(pos,2i+1) = cos(pos/100002i/dmodel )\\nwhere posis the position and iis the dimension. That is, each dimension of the positional encoding\\ncorresponds to a sinusoid. The wavelengths form a geometric progression from 2πto 10000 ·2π. We\\nchose this function because we hypothesized it would allow the model to easily learn to attend by\\nrelative positions, since for any ﬁxed offset k, PEpos+k can be represented as a linear function of\\nPEpos.\\nWe also experimented with using learned positional embeddings [8] instead, and found that the two\\nversions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version\\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\\nduring training.\\n4 Why Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one variable-length sequence of symbol representations\\n(x1,...,x n) to another sequence of equal length (z1,...,z n), with xi,zi ∈Rd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\\nconsider three desiderata.\\nOne is the total computational complexity per layer. Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.\\nThe third is the path length between long-range dependencies in the network. Learning long-range\\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to\\ntraverse in the network. The shorter these paths between any combination of positions in the input\\nand output sequences, the easier it is to learn long-range dependencies [11]. Hence we also compare\\nthe maximum path length between any two input and output positions in networks composed of the\\ndifferent layer types.\\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially\\nexecuted operations, whereas a recurrent layer requires O(n) sequential operations. In terms of\\ncomputational complexity, self-attention layers are faster than recurrent layers when the sequence\\nlength n is smaller than the representation dimensionality d, which is most often the case with\\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\\n[31] and byte-pair [25] representations. To improve computational performance for tasks involving\\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size rin\\n6'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 6, 'page_label': '7', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='the input sequence centered around the respective output position. This would increase the maximum\\npath length to O(n/r). We plan to investigate this approach further in future work.\\nA single convolutional layer with kernel width k<n does not connect all pairs of input and output\\npositions. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels,\\nor O(logk(n)) in the case of dilated convolutions [ 15], increasing the length of the longest paths\\nbetween any two positions in the network. Convolutional layers are generally more expensive than\\nrecurrent layers, by a factor of k. Separable convolutions [ 6], however, decrease the complexity\\nconsiderably, to O(k·n·d+ n·d2). Even with k = n, however, the complexity of a separable\\nconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.\\nAs side beneﬁt, self-attention could yield more interpretable models. We inspect attention distributions\\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\\nand semantic structure of the sentences.\\n5 Training\\nThis section describes the training regime for our models.\\n5.1 Training Data and Batching\\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\\nsentence pairs. Sentences were encoded using byte-pair encoding [ 3], which has a shared source-\\ntarget vocabulary of about 37000 tokens. For English-French, we used the signiﬁcantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\\nvocabulary [31]. Sentence pairs were batched together by approximate sequence length. Each training\\nbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000\\ntarget tokens.\\n5.2 Hardware and Schedule\\nWe trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We\\ntrained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the\\nbottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps\\n(3.5 days).\\n5.3 Optimizer\\nWe used the Adam optimizer [17] with β1 = 0.9, β2 = 0.98 and ϵ= 10−9. We varied the learning\\nrate over the course of training, according to the formula:\\nlrate= d−0.5\\nmodel ·min(step_num−0.5,step_num·warmup_steps−1.5) (3)\\nThis corresponds to increasing the learning rate linearly for the ﬁrst warmup_stepstraining steps,\\nand decreasing it thereafter proportionally to the inverse square root of the step number. We used\\nwarmup_steps= 4000.\\n5.4 Regularization\\nWe employ three types of regularization during training:\\nResidual Dropout We apply dropout [27] to the output of each sub-layer, before it is added to the\\nsub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the\\npositional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\\nPdrop = 0.1.\\n7'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 7, 'page_label': '8', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\\nModel\\nBLEU Training Cost (FLOPs)\\nEN-DE EN-FR EN-DE EN-FR\\nByteNet [15] 23.75\\nDeep-Att + PosUnk [32] 39.2 1.0 ·1020\\nGNMT + RL [31] 24.6 39.92 2.3 ·1019 1.4 ·1020\\nConvS2S [8] 25.16 40.46 9.6 ·1018 1.5 ·1020\\nMoE [26] 26.03 40.56 2.0 ·1019 1.2 ·1020\\nDeep-Att + PosUnk Ensemble [32] 40.4 8.0 ·1020\\nGNMT + RL Ensemble [31] 26.30 41.16 1.8 ·1020 1.1 ·1021\\nConvS2S Ensemble [8] 26.36 41.29 7.7 ·1019 1.2 ·1021\\nTransformer (base model) 27.3 38.1 3.3 · 1018\\nTransformer (big) 28.4 41.0 2.3 ·1019\\nLabel Smoothing During training, we employed label smoothing of value ϵls = 0.1 [30]. This\\nhurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\\n6 Results\\n6.1 Machine Translation\\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\\nin Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The conﬁguration of this model is\\nlisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model\\nsurpasses all previously published models and ensembles, at a fraction of the training cost of any of\\nthe competitive models.\\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\\noutperforming all of the previously published single models, at less than 1/4 the training cost of the\\nprevious state-of-the-art model. The Transformer (big) model trained for English-to-French used\\ndropout rate Pdrop = 0.1, instead of 0.3.\\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which\\nwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We\\nused beam search with a beam size of 4 and length penalty α= 0.6 [31]. These hyperparameters\\nwere chosen after experimentation on the development set. We set the maximum output length during\\ninference to input length + 50, but terminate early when possible [31].\\nTable 2 summarizes our results and compares our translation quality and training costs to other model\\narchitectures from the literature. We estimate the number of ﬂoating point operations used to train a\\nmodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained\\nsingle-precision ﬂoating-point capacity of each GPU 5.\\n6.2 Model Variations\\nTo evaluate the importance of different components of the Transformer, we varied our base model\\nin different ways, measuring the change in performance on English-to-German translation on the\\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no\\ncheckpoint averaging. We present these results in Table 3.\\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\\n5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.\\n8'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 8, 'page_label': '9', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\\nmodel. All metrics are on the English-to-German translation development set, newstest2013. Listed\\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\\nper-word perplexities.\\nN d model dff h d k dv Pdrop ϵls\\ntrain PPL BLEU params\\nsteps (dev) (dev) ×106\\nbase 6 512 2048 8 64 64 0.1 0.1 100K 4.92 25.8 65\\n(A)\\n1 512 512 5.29 24.9\\n4 128 128 5.00 25.5\\n16 32 32 4.91 25.8\\n32 16 16 5.01 25.4\\n(B) 16 5.16 25.1 58\\n32 5.01 25.4 60\\n(C)\\n2 6.11 23.7 36\\n4 5.19 25.3 50\\n8 4.88 25.5 80\\n256 32 32 5.75 24.5 28\\n1024 128 128 4.66 26.0 168\\n1024 5.12 25.4 53\\n4096 4.75 26.2 90\\n(D)\\n0.0 5.77 24.6\\n0.2 4.95 25.5\\n0.0 4.67 25.3\\n0.2 5.47 25.7\\n(E) positional embedding instead of sinusoids 4.92 25.7\\nbig 6 1024 4096 16 0.3 300K 4.33 26.4 213\\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This\\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\\nfunction than dot product may be beneﬁcial. We further observe in rows (C) and (D) that, as expected,\\nbigger models are better, and dropout is very helpful in avoiding over-ﬁtting. In row (E) we replace our\\nsinusoidal positional encoding with learned positional embeddings [8], and observe nearly identical\\nresults to the base model.\\n7 Conclusion\\nIn this work, we presented the Transformer, the ﬁrst sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained signiﬁcantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\\nmodel outperforms even all previously reported ensembles.\\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efﬁciently handle large inputs and outputs\\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\\nThe code we used to train and evaluate our models is available at https://github.com/\\ntensorflow/tensor2tensor.\\nAcknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\\ncomments, corrections and inspiration.\\n9'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 9, 'page_label': '10', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='References\\n[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\\narXiv:1607.06450, 2016.\\n[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\\nlearning to align and translate. CoRR, abs/1409.0473, 2014.\\n[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V . Le. Massive exploration of neural\\nmachine translation architectures. CoRR, abs/1703.03906, 2017.\\n[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\\nreading. arXiv preprint arXiv:1601.06733, 2016.\\n[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,\\nand Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical\\nmachine translation. CoRR, abs/1406.1078, 2014.\\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\\npreprint arXiv:1610.02357, 2016.\\n[7] Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation\\nof gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\\n[8] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-\\ntional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\\n[9] Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint\\narXiv:1308.0850, 2013.\\n[10] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\\nRecognition, pages 770–778, 2016.\\n[11] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient ﬂow in\\nrecurrent nets: the difﬁculty of learning long-term dependencies, 2001.\\n[12] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation,\\n9(8):1735–1780, 1997.\\n[13] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring\\nthe limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\\n[14] Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\\non Learning Representations (ICLR), 2016.\\n[15] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\\nray Kavukcuoglu. Neural machine translation in linear time.arXiv preprint arXiv:1610.10099v2,\\n2017.\\n[16] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.\\n[17] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\\n[18] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\\narXiv:1703.10722, 2017.\\n[19] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130, 2017.\\n[20] Samy Bengio Łukasz Kaiser. Can active memory replace attention? In Advances in Neural\\nInformation Processing Systems, (NIPS), 2016.\\n10'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 10, 'page_label': '11', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='[21] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\\nbased neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\\n[22] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention\\nmodel. In Empirical Methods in Natural Language Processing, 2016.\\n[23] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\\nsummarization. arXiv preprint arXiv:1705.04304, 2017.\\n[24] Oﬁr Press and Lior Wolf. Using the output embedding to improve language models. arXiv\\npreprint arXiv:1608.05859, 2016.\\n[25] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words\\nwith subword units. arXiv preprint arXiv:1508.07909, 2015.\\n[26] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,\\nand Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\\nlayer. arXiv preprint arXiv:1701.06538, 2017.\\n[27] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\\nnov. Dropout: a simple way to prevent neural networks from overﬁtting. Journal of Machine\\nLearning Research, 15(1):1929–1958, 2014.\\n[28] Sainbayar Sukhbaatar, arthur szlam, Jason Weston, and Rob Fergus. End-to-end memory\\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,\\nAdvances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates,\\nInc., 2015.\\n[29] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural\\nnetworks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\\n[30] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.\\nRethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\\n[31] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\\nMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine\\ntranslation system: Bridging the gap between human and machine translation. arXiv preprint\\narXiv:1609.08144, 2016.\\n[32] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\\nfast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\\n11')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Read all the pdf files inside the directory\n",
    "\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    \"\"\"Process all PDF files in a directory\"\"\"\n",
    "\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "\n",
    "    # find all pdf files recursively\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "\n",
    "    print(f\"Found {len(pdf_files)} PDF files to process.\")\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcessing: {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "\n",
    "            # add source information to metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata[\"source_file\"] = pdf_file.name\n",
    "                doc.metadata[\"file_type\"] = \"pdf\"\n",
    "            \n",
    "            all_documents.extend(documents)\n",
    "            print(f\"✔️ Loaded {len(documents)} pages\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error: {e}\")\n",
    "    \n",
    "    print(f\"\\nTotal documents loaded: {len(all_documents)}\")\n",
    "    return all_documents\n",
    "\n",
    "all_pdf_documents = process_all_pdfs(\"../data\")\n",
    "\n",
    "all_pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87b19fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Text splitting get into chunks\n",
    "\n",
    "def split_documents(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"Split documents into smaller chunks for better RAG performance\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "\n",
    "    # show example of a chunk\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "    \n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8c90669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 82 documents into 326 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content: 1 \n",
      " \n",
      " \n",
      "Artificial Intelligence \n",
      "and the Future of \n",
      "Teaching and Learning \n",
      "Insights and Recommendations \n",
      "May 2023...\n",
      "Metadata: {'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 0, 'page_label': '1', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 0, 'page_label': '1', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='1 \\n \\n \\nArtificial Intelligence \\nand the Future of \\nTeaching and Learning \\nInsights and Recommendations \\nMay 2023'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 1, 'page_label': '2', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Artificial Intelligence and the Future of Teaching and Learning \\nMiguel A. Cardona, Ed.D. \\nSecretary, U.S. Department of Education \\nRoberto J. Rodríguez \\nAssistant Secretary, Office of Planning, Evaluation, and Policy Development \\nKristina Ishmael \\nDeputy Director, Office of Educational Technology \\nMay 2023 \\n \\nExamples Are Not Endorsements \\nThis document contains examples and resource materials that are provided for the user’s \\nconvenience. The inclusion of any material is not intended to reflect its importance nor is it \\nintended to endorse any views expressed or products or services offered. These materials may \\ncontain the views and recommendations of various subject matter experts as well as hypertext links, \\ncontact addresses, and websites to information created and maintained by other public and private \\norganizations. The opinions expressed in any of these materials do not necessarily reflect the'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 1, 'page_label': '2', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='contact addresses, and websites to information created and maintained by other public and private \\norganizations. The opinions expressed in any of these materials do not necessarily reflect the \\npositions or policies of the U.S. Department of Education. The U.S. Department of Education does \\nnot control or guarantee the accuracy, relevance, timeliness, or completeness of any information \\nfrom other sources that are included in these materials. Other than statutory and regulatory \\nrequirements included in the document, the contents of this guidance do not have the force and \\neffect of law and are not meant to bind the public. \\nContracts and Procurement \\nThis document is not intended to provide legal advice or approval of any potential federal \\ncontractor’s business decision or strategy in relation to any current or future federal procurement \\nand/or contract. Further, this document is not an invitation for bid, request for proposal, or other \\nsolicitation. \\nLicensing and Availability'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 1, 'page_label': '2', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='and/or contract. Further, this document is not an invitation for bid, request for proposal, or other \\nsolicitation. \\nLicensing and Availability \\nThis report is in the public domain and available on the U.S. Department of Education’s \\n(Department’s) website at https://tech.ed.gov. \\nRequests for alternate format documents such as Braille or large print should be submitted to the \\nAlternate Format Center by calling 1-202-260-0852 or by contacting the 504 coordinator via email \\nat om_eeos@ed.gov. \\nNotice to Limited English Proficient Persons \\nIf you have difficulty understanding English, you may request language assistance services for \\nDepartment information that is available to the public. These language assistance services are \\navailable free of charge. If you need more information about interpretation or translation services, \\nplease call 1-800-USA-LEARN (1-800-872-5327) (TTY: 1-800-437-0833); email us at'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 1, 'page_label': '2', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='available free of charge. If you need more information about interpretation or translation services, \\nplease call 1-800-USA-LEARN (1-800-872-5327) (TTY: 1-800-437-0833); email us at \\nEd.Language.Assistance@ed.gov; or write to U.S. Department of Education, Information Resource \\nCenter, LBJ Education Building, 400 Maryland Ave. SW, Washington, DC 20202. \\nHow to Cite \\nWhile permission to reprint this publication is not necessary, the suggested citation is as follows:  \\nU.S. Department of Education, Office of Educational Technology, Artificial Intelligence and \\nFuture of Teaching and Learning: Insights and Recommendations, Washington, DC, 2023.  \\nThis report is available at https://tech.ed.gov'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 2, 'page_label': '3', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Table of Contents \\nIntroduction ................................ ................................ ................................ ..........................  1 \\nRising Interest in AI in Education ......................................................................................................................................................... 1 \\nThree Reasons to Address AI in Education Now................................................................................................................... 2 \\nToward Policies for AI in Education .................................................................................................................................................. 3 \\nBuilding Ethical, Equitable Policies Together................................ ........................  6'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 2, 'page_label': '3', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Building Ethical, Equitable Policies Together................................ ........................  6 \\nGuiding Questions ........................................................................................................................................................................................... 6 \\nFoundation 1: Center People (Parents, Educators, and Students) ......................................................................... 6 \\nFoundation 2: Advance Equity...............................................................................................................................................................7 \\nFoundation 3: Ensure Safety, Ethics, and Effectiveness ................................................................................................ 8 \\nFoundation 4: Promote Transparency ........................................................................................................................................... 9'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 2, 'page_label': '3', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Foundation 4: Promote Transparency ........................................................................................................................................... 9 \\nOverview of Document ............................................................................................................................................................................ 10 \\nWhat is AI? ................................ ................................ ................................ ..........................  11 \\nPerspective: Human-Like Reasoning ........................................................................................................................................... 12 \\nPerspective: An Algorithm that Pursues a Goal................................................................................................................... 12'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 2, 'page_label': '3', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Perspective: An Algorithm that Pursues a Goal................................................................................................................... 12 \\nPerspective: Intelligence Augmentation ................................................................................................................................... 14 \\nDefinition of “Model”.................................................................................................................................................................................... 14 \\nInsight: AI Systems Enable New Forms of Interaction ................................................................................................... 15 \\nKey Recommendation: Human in the Loop AI ..................................................................................................................... 16'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 2, 'page_label': '3', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Key Recommendation: Human in the Loop AI ..................................................................................................................... 16 \\nLearning ................................ ................................ ................................ ..............................  18 \\nInsight: AI Enables Adaptivity in Learning................................................................................................................................. 18 \\nIntelligent Tutoring Systems: An Example of AI Models ............................................................................................. 19 \\nImportant Directions for Expanding AI-Based Adaptivity .......................................................................................... 20 \\nA Duality: Learning With and About AI ........................................................................................................................................ 22'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 2, 'page_label': '3', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='A Duality: Learning With and About AI ........................................................................................................................................ 22 \\nA Challenge: Systems Thinking About AI in Education ................................................................................................. 22 \\nOpen Questions About AI for Learning ....................................................................................................................................... 23 \\nKey Recommendation: Seek AI Models Aligned to a Vision for Learning .................................................... 24 \\nTeaching ................................ ................................ ................................ .............................  25 \\nAlways Center Educators in Instructional Loops ............................................................................................................... 25'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 2, 'page_label': '3', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Always Center Educators in Instructional Loops ............................................................................................................... 25 \\nInsight: Using AI to Improve Teaching Jobs .......................................................................................................................... 26 \\nPreparing and Supporting Teachers in Planning and Reflecting ........................................................................ 29 \\nDesigning, Selecting, and Evaluating AI Tools .................................................................................................................... 30 \\nChallenge: Balancing Human and Computer Decision-Making .......................................................................... 30 \\nChallenge: Making Teaching Jobs Easier While Avoiding Surveillance ........................................................ 31'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 2, 'page_label': '3', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Challenge: Making Teaching Jobs Easier While Avoiding Surveillance ........................................................ 31 \\nChallenge: Responding to Students’ Strengths While Protecting Their Privacy .................................... 32 \\nQuestions Worth Asking About AI for Teaching .................................................................................................................34 \\nKey Recommendation: Inspectable, Explainable, Overridable AI .......................................................................34'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 3, 'page_label': '4', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Formative Assessment ................................ ................................ ................................ . 37 \\nBuilding on Best Practices ..................................................................................................................................................................... 37 \\nImplications for Teaching and Learning ................................................................................................................................... 38 \\nInsight: AI Can Enhance Feedback Loops ............................................................................................................................... 39 \\nAn Example: Automated Essay Scoring .................................................................................................................................... 40 \\nKey Opportunities for AI in Formative Assessment ......................................................................................................... 41'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 3, 'page_label': '4', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Key Opportunities for AI in Formative Assessment ......................................................................................................... 41 \\nKey Recommendation: Harness Assessment Expertise to Reduce Bias ...................................................... 42 \\nRelated Questions.........................................................................................................................................................................................43 \\nResearch and Development ................................ ................................ .......................  44 \\nInsight: Research Can Strengthen the Role of Context in AI ....................................................................................44 \\nAttention to the Long Tail of Learner Variability ................................................................................................................ 46'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 3, 'page_label': '4', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Attention to the Long Tail of Learner Variability ................................................................................................................ 46 \\nPartnership in Design-Based Research ......................................................................................................................................47 \\nRe-thinking Teacher Professional Development .............................................................................................................. 48 \\nConnecting with Public Policy ........................................................................................................................................................... 49 \\nKey Recommendation: Focus R&D on Addressing Context.................................................................................... 50'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 3, 'page_label': '4', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Key Recommendation: Focus R&D on Addressing Context.................................................................................... 50 \\nOngoing Questions for Researchers ............................................................................................................................................ 50 \\nDesired National R&D Objectives .................................................................................................................................................... 51 \\nRecommendations ................................ ................................ ................................ .........  52 \\nInsight: Aligning AI to Policy Objectives ..................................................................................................................................... 52 \\nCalling Education Leaders to Action ............................................................................................................................................ 53'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 3, 'page_label': '4', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Calling Education Leaders to Action ............................................................................................................................................ 53 \\nRecommendation #1: Emphasize Humans in the Loop ............................................................................................... 53 \\nRecommendation #2: Align AI Models to a Shared Vision for Education .....................................................54 \\nRecommendation #3: Design Using Modern Learning Principles ..................................................................... 56 \\nRecommendation #4: Prioritize Strengthening Trust .....................................................................................................57 \\nRecommendation #5: Inform and Involve Educators ....................................................................................................57 \\nRecommendation #6: Focus R&D on Addressing Context and Enhancing Trust and Safety .... 59'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 3, 'page_label': '4', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Recommendation #6: Focus R&D on Addressing Context and Enhancing Trust and Safety .... 59 \\nRecommendation #7: Develop Education-Specific Guidelines and Guardrails..................................... 60 \\nNext Steps .......................................................................................................................................................................................................... 60 \\nCommon Acronyms and Abbreviations ................................ ................................ . 62 \\nAcknowledgements ................................ ................................ ................................ .......  63 \\nReferences................................ ................................ ................................ .........................  64'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 4, 'page_label': '5', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='1 \\nIntroduction \\nThe U.S. Department of Education (Department) is committed to supporting the use of \\ntechnology to improve teaching and learning and to support innovation throughout educational \\nsystems. This report addresses the clear need for sharing knowledge and developing policies for \\n“Artificial Intelligence,” a rapidly advancing class of foundational capabilities which are \\nincreasingly embedded in all types of educational technology systems and are also available to \\nthe public. We will consider “educational technology” (edtech) to include both (a) technologies \\nspecifically designed for educational use, as well as (b) general technologies that are widely used \\nin educational settings. Recommendations in this report seek to engage teachers, educational \\nleaders, policy makers, researchers, and educational technology innovators and providers as they \\nwork together on pressing policy issues that arise as Artificial Intelligence (AI) is used in \\neducation.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 4, 'page_label': '5', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='work together on pressing policy issues that arise as Artificial Intelligence (AI) is used in \\neducation.  \\nAI can be defined as “automation based on associations.” When computers automate reasoning \\nbased on associations in data (or associations deduced from expert knowledge), two shifts \\nfundamental to AI occur and shift computing beyond conventional edtech: (1) from capturing \\ndata to detecting patterns in data and (2) from providing access to instructional resources to \\nautomating decisions about instruction and other educational processes. Detecting patterns and \\nautomating decisions are leaps in the level of responsibilities that can be delegated to a computer \\nsystem. The process of developing an AI system may lead to bias in how patterns are detected \\nand unfairness in how decisions are automated. Thus, educational systems must govern their use \\nof AI systems. This report describes opportunities for using AI to improve education, recognizes'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 4, 'page_label': '5', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='and unfairness in how decisions are automated. Thus, educational systems must govern their use \\nof AI systems. This report describes opportunities for using AI to improve education, recognizes \\nchallenges that will arise, and develops recommendations to guide further policy development.  \\nRising Interest in AI in Education  \\nToday, many priorities for improvements to teaching and learning are unmet. Educators seek \\ntechnology-enhanced approaches addressing these priorities that would be safe, effective, and \\nscalable. Naturally, educators wonder if the rapid advances in technology in everyday lives could \\nhelp. Like all of us, educators use AI-powered services in their everyday lives, such as voice \\nassistants in their homes; tools that can correct grammar, complete sentences, and write essays; \\nand automated trip planning on their phones. Many educators are actively exploring AI tools as'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 4, 'page_label': '5', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='assistants in their homes; tools that can correct grammar, complete sentences, and write essays; \\nand automated trip planning on their phones. Many educators are actively exploring AI tools as \\nthey are newly released to the public1. Educators see opportunities to use AI-powered capabilities \\nlike speech recognition to increase the support available to students with disabilities, multilingual \\nlearners, and others who could benefit from greater adaptivity and personalization in digital \\ntools for learning. They are exploring how AI can enable writing or improving lessons, as well as \\ntheir process for finding, choosing, and adapting material for use in their lessons.  \\nEducators are also aware of new risks. Useful, powerful functionality can also be accompanied \\nwith new data privacy and security risks. Educators recognize that AI can automatically produce \\noutput that is inappropriate or wrong. They are wary that the associations or automations'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 4, 'page_label': '5', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='with new data privacy and security risks. Educators recognize that AI can automatically produce \\noutput that is inappropriate or wrong. They are wary that the associations or automations \\ncreated by AI may amplify unwanted biases. They have noted new ways in which students may \\n \\n1 Walton Family Foundation (March 1, 2023). Teachers and students embrace ChatGPT for education. \\nhttps://www.waltonfamilyfoundation.org/learning/teachers-and-students-embrace-chatgpt-for-education'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 5, 'page_label': '6', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='2 \\nrepresent others’ work as their own. They are well-aware of “teachable moments” and \\npedagogical strategies that a human teacher can address but are undetected or misunderstood by \\nAI models. They worry whether recommendations suggested by an algorithm would be fair. \\nEducators’ concerns are manifold. Everyone in education has a responsibility to harness the \\ngood to serve educational priorities while also protecting against the dangers that may arise as a \\nresult of AI being integrated in edtech. \\nTo develop guidance for edtech, the Department works closely with educational constituents. \\nThese constituents include educational leaders—teachers, faculty, support staff, and other \\neducators—researchers; policymakers; advocates and funders; technology developers; \\ncommunity members and organizations; and, above all, learners and their families/caregivers. \\nRecently, through its activities with constituents, the Department noticed a sharp rise in interest'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 5, 'page_label': '6', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='community members and organizations; and, above all, learners and their families/caregivers. \\nRecently, through its activities with constituents, the Department noticed a sharp rise in interest \\nand concern about AI. For example, a 2021 field scan found that developers of all kinds of \\ntechnology systems—for student information, classroom instruction, school logistics, parent-\\nteacher communication, and more—expect to add AI capabilities to their systems. Through a \\nseries of four listening sessions conducted in June and August 2022 and attended by more than \\n700 attendees, it became clear that constituents believe that action is required now in order to get \\nahead of the expected increase of AI in education technology—and they want to roll up their \\nsleeves and start working together. In late 2022 and early 2023, the public became aware of new \\ngenerative AI chatbots and began to explore how AI could be used to write essays, create lesson'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 5, 'page_label': '6', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='sleeves and start working together. In late 2022 and early 2023, the public became aware of new \\ngenerative AI chatbots and began to explore how AI could be used to write essays, create lesson \\nplans, produce images, create personalized assignments for students, and more. From public \\nexpression in social media, at conferences, and in news media, the Department learned more \\nabout risks and benefits of AI-enabled chatbots. And yet this report will not focus on a specific AI \\ntool, service, or announcement, because AI-enabled systems evolve rapidly. Finally, the \\nDepartment engaged the educational policy expertise available internally and in its relationships \\nwith AI policy experts to shape the findings and recommendations in this report.  \\nThree Reasons to Address AI in Education Now \\n“I strongly believe in the need for stakeholders to understand the cyclical \\neffects of AI and education. By understanding how different activities'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 5, 'page_label': '6', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Three Reasons to Address AI in Education Now \\n“I strongly believe in the need for stakeholders to understand the cyclical \\neffects of AI and education. By understanding how different activities \\naccrue, we have the ability to support virtuous cycles. Otherwise, we will \\nlikely allow vicious cycles to perpetuate.”  \\n —Lydia Liu \\nDuring the listening sessions, constituents articulated three reasons to address AI now: \\nFirst, AI may enable achieving educational priorities in better ways, at scale, and with lower costs. \\nAddressing varied unfinished learning of students due to the pandemic is a policy priority, and \\nAI may improve the adaptivity of learning resources to students’ strengths and needs. Improving \\nteaching jobs is a priority, and via automated assistants or other tools, AI may provide teachers \\ngreater support. AI may also enable teachers to extend the support they offer to individual'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 5, 'page_label': '6', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='teaching jobs is a priority, and via automated assistants or other tools, AI may provide teachers \\ngreater support. AI may also enable teachers to extend the support they offer to individual \\nstudents when they run out of time. Developing resources that are responsive to the knowledge \\nand experiences students bring to their learning—their community and cultural assets—is a \\npriority, and AI may enable greater customizability of curricular resources to meet local needs.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 6, 'page_label': '7', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='3 \\nAs seen in voice assistants, mapping tools, shopping recommendations, essay-writing capabilities, \\nand other familiar applications, AI may enhance educational services.  \\nSecond, urgency and importance arise through awareness of system-level risks and anxiety about \\npotential future risks. For example, students may become subject to greater surveillance. Some \\nteachers worry that they may be replaced—to the contrary, the Department firmly rejects the \\nidea that AI could replace teachers. Examples of discrimination from algorithmic bias are on the \\npublic’s mind, such as a voice recognition system that doesn’t work as well with regional dialects, \\nor an exam monitoring system that may unfairly identify some groups of students for \\ndisciplinary action. Some uses of AI may be infrastructural and invisible, which creates concerns \\nabout transparency and trust. AI often arrives in new applications with the aura of magic, but'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 6, 'page_label': '7', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='disciplinary action. Some uses of AI may be infrastructural and invisible, which creates concerns \\nabout transparency and trust. AI often arrives in new applications with the aura of magic, but \\neducators and procurement policies require that edtech show efficacy. AI may provide \\ninformation that appears authentic, but actually is inaccurate or lacking a basis in reality. Of the \\nhighest importance, AI brings new risks in addition to the well-known data privacy and data \\nsecurity risks, such as the risk of scaling pattern detectors and automations that result in \\n“algorithmic discrimination” (e.g., systematic unfairness in the learning opportunities or \\nresources recommended to some populations of students). \\nThird, urgency arises because of the scale of possible unintended or unexpected consequences. \\nWhen AI enables instructional decisions to be automated at scale, educators may discover \\nunwanted consequences. In a simple example, if AI adapts by speeding curricular pace for some'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 6, 'page_label': '7', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='When AI enables instructional decisions to be automated at scale, educators may discover \\nunwanted consequences. In a simple example, if AI adapts by speeding curricular pace for some \\nstudents and by slowing the pace for other students (based on incomplete data, poor theories, or \\nbiased assumptions about learning), achievement gaps could widen. In some cases, the quality of \\navailable data may produce unexpected results. For example, an AI-enabled teacher hiring \\nsystem might be assumed to be more objective than human-based résumé scoring. Yet, if the AI \\nsystem relies on poor quality historical data, it might de-prioritize candidates who could bring \\nboth diversity and talent to a school’s teaching workforce. \\nIn summary, it is imperative to address AI in education now to realize key opportunities, prevent \\nand mitigate emergent risks, and tackle unintended consequences. \\nToward Policies for AI in Education'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 6, 'page_label': '7', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='and mitigate emergent risks, and tackle unintended consequences. \\nToward Policies for AI in Education \\nThe 2023 AI Index Report from the Stanford Institute for Human-Centered AI has documented \\nnotable acceleration of investment in AI as well as an increase of research on ethics, including \\nissues of fairness and transparency.2 Of course, research on topics like ethics is increasing \\nbecause problems are observed. Ethical problems will occur in education, too.3 The report found \\na striking interest in 25 countries in the number of legislative proposals that specifically include \\nAI. In the United States, multiple executive orders are focused on ensuring AI is trustworthy and \\nequitable, and the White House Office of Science and Technology Policy has introduced a \\n \\n2 Maslej, N., Fattorini, L., Brynjolfsson E., Etchemendy, J., Ligett, K., Lyons, T., Manyika, J., Ngo, H., Niebles, J.C., Parli, V.,'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 6, 'page_label': '7', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='2 Maslej, N., Fattorini, L., Brynjolfsson E., Etchemendy, J., Ligett, K., Lyons, T., Manyika, J., Ngo, H., Niebles, J.C., Parli, V., \\nShoham, Y., Wald, R., Clark, J. and Perrault, R., (2023). The AI index 2023 annual report. Stanford University: AI Index \\nSteering Committee, Institute for Human-Centered AI.  \\n3 Holmes, W. & Porayska-Pomsta, K. (Eds.) (2022). The ethics of artificial intelligence in education. Routledge. ISBN 978-\\n0367349721'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 7, 'page_label': '8', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='4 \\nBlueprint for an AI Bill of Rights (Blueprint)4 that provides principles and practices that help \\nachieve this goal. These initiatives, along with other AI-related policy activities occurring in both \\nthe executive and legislative branches, will guide the use of AI throughout all sectors of society. \\nIn Europe, the European Commission recently released Ethical guidelines on the use of artificial \\nintelligence (AI) and data in teaching and learning for educators.5 \\nAI is moving fast and heralding societal changes that require a national policy response. In \\naddition to broad policies for all sectors of society, education-specific policies are needed to \\naddress new opportunities and challenges within existing frameworks that take into \\nconsideration federal student privacy laws (such as the Family Educational Rights and Privacy \\nAct, or FERPA), as well as similar state related laws. AI also makes recommendations and takes'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 7, 'page_label': '8', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='consideration federal student privacy laws (such as the Family Educational Rights and Privacy \\nAct, or FERPA), as well as similar state related laws. AI also makes recommendations and takes \\nactions automatically in support of student learning, and thus educators will need to consider \\nhow such recommendations and actions can comply with laws such as the Individuals with \\nDisabilities Education Act (IDEA). We discuss specific policies in the concluding section. \\nFigure 1: Research about AI is growing rapidly. Other indicators, such as dollars invested and \\nnumber of people employed, show similar trends. \\n \\nAI is advancing exponentially (see Figure 1), with powerful new AI features for generating images \\nand text becoming available to the public, and leading to changes in how people create text and \\n \\n4 White House Office of Science and Technology Policy (October 2022), Blueprint for an AI bill of rights: Making automated'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 7, 'page_label': '8', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='4 White House Office of Science and Technology Policy (October 2022), Blueprint for an AI bill of rights: Making automated \\nsystems work for the American people. The White House Office of Science and Technology Policy. \\nhttps://www.whitehouse.gov/ostp/ai-bill-of-rights/  \\n5 European Commission, Directorate-General for Education, Youth, Sport and Culture. (2022). Ethical guidelines on the use of \\nartificial intelligence (AI) and data in teaching and learning for educators, Publications Office of the European \\nUnion. https://data.europa.eu/doi/10.2766/153756'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 8, 'page_label': '9', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='5 \\nimages6. The advances in AI are not only happening in research labs but also are making news in \\nmainstream media and in educational-specific publications.  \\nResearchers have articulated a range of concepts and frameworks for ethical AI7, as well as for \\nrelated concepts such as equitable, responsible, and human-centered AI. Listening session \\nparticipants called for building on these concepts and frameworks but also recognized the need \\nto do more; participants noted a pressing need for guardrails and guidelines that make \\neducational use of AI advances safe, especially given this accelerating pace of incorporation of AI \\ninto mainstream technologies. As policy development takes time, policy makers and educational \\nconstituents together need to start now to specify the requirements, disclosures, regulations, and \\nother structures that can shape a positive and safe future for all constituents—especially students \\nand teachers.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 8, 'page_label': '9', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='other structures that can shape a positive and safe future for all constituents—especially students \\nand teachers.  \\nPolicies are urgently needed to implement the following:  \\n1. leverage automation to advance learning outcomes while protecting human decision \\nmaking and judgment;  \\n2. interrogate the underlying data quality in AI models to ensure fair and unbiased pattern \\nrecognition and decision making in educational applications, based on accurate \\ninformation appropriate to the pedagogical situation;  \\n3. enable examination of how particular AI technologies, as part of larger edtech or \\neducational systems, may increase or undermine equity for students; and \\n4. take steps to safeguard and advance equity, including providing for human checks and \\nbalances and limiting any AI systems and tools that undermine equity. \\n  \\n \\n6 Sharples, M. & Pérez y Pérez, R. (2022). Story machines: How computers have become creative writers. Routledge. ISBN \\n9780367751951'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 8, 'page_label': '9', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='6 Sharples, M. & Pérez y Pérez, R. (2022). Story machines: How computers have become creative writers. Routledge. ISBN \\n9780367751951 \\n7 Akgun, S., Greenhow, C. (2022). Artificial intelligence in education: Addressing ethical challenges in K-12 settings. AI \\nEthics, 2, 431–440. https://doi.org/10.1007/s43681-021-00096-7'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 9, 'page_label': '10', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='6 \\n \\nBuilding Ethical, Equitable \\nPolicies Together \\nIn this report, we aim to build on the listening sessions the Department hosted to engage and \\ninform all constituents involved in making educational decisions so they can prepare for and \\nmake better decisions about the role of AI in teaching and learning. AI is a complex and broad \\ntopic, and we are not able to cover everything nor resolve issues that still require more \\nconstituent engagement. This report is intended to be a starting point. \\nThe opportunities and issues of AI in education are equally important in K-12, higher education, \\nand workforce learning. Due to scope limitations, the examples in this report will focus on K-12 \\neducation. The implications are similar at all levels of education, and the Department intends \\nfurther activities in 2023 to engage constituents beyond K-12 schools. \\nGuiding Questions \\nUnderstanding that AI increases automation and allows machines to do some tasks that only'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 9, 'page_label': '10', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='further activities in 2023 to engage constituents beyond K-12 schools. \\nGuiding Questions \\nUnderstanding that AI increases automation and allows machines to do some tasks that only \\npeople did in the past leads us to a pair of bold, overarching questions:  \\n1. What is our collective vision of a desirable and achievable educational system that \\nleverages automation to advance learning while protecting and centering human agency? \\n2. How and on what timeline will we be ready with necessary guidelines and guardrails, as \\nwell as convincing evidence of positive impacts, so that constituents can ethically and \\nequitably implement this vision widely? \\nIn the Learning, Teaching, and Assessment sections of this report, we elaborate on elements of \\nan educational vision grounded in what today’s learners, teachers, and educational systems need, \\nand we describe key insights and next steps required. Below, we articulate four key foundations'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 9, 'page_label': '10', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='an educational vision grounded in what today’s learners, teachers, and educational systems need, \\nand we describe key insights and next steps required. Below, we articulate four key foundations \\nfor framing these themes. These foundations arise from what we know about the effective use of \\neducational technology to improve opportunity, equity, and outcomes for students and also \\nrelate to the new Blueprint. \\nFoundation 1: Center People (Parents, Educators, and Students) \\nEducation-focused AI policies at the federal, state, and district levels will be needed to guide and \\nempower local and individual decisions about which technologies to adopt and use in schools \\nand classrooms. Consider what is happening in everyday lives. Many of us use AI-enabled \\nproducts because they are often better and more convenient. For example, few people want to \\nuse paper maps anymore; people find that technology helps us plan the best route to a'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 9, 'page_label': '10', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='products because they are often better and more convenient. For example, few people want to \\nuse paper maps anymore; people find that technology helps us plan the best route to a \\ndestination more efficiently and conveniently. And yet, people often do not realize how much \\nprivacy they are giving up when they accept AI-enabled systems into their lives. AI will bring \\nprivacy and other risks that are hard to address only via individual decision making; additional \\nprotections will be needed.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 10, 'page_label': '11', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='7 \\nThere should be clear limits on the ability to collect, use, transfer, and \\nmaintain our personal data, including limits on targeted advertising. \\nThese limits should put the burden on platforms to minimize how much \\ninformation they collect, rather than burdening Americans with reading \\nfine print.8 \\nAs protections are developed, we recommend that policies center people, not machines. To this \\nend, a first recommendation in this document (in the next section) is an emphasis on AI with \\nhumans in the loop. Teachers, learners, and others need to retain their agency to decide what \\npatterns mean and to choose courses of action. The idea of humans in the loop builds on the \\nconcept of “Human Alternatives, Consideration, and Fallback” in the Blueprint and ethical \\nconcepts used more broadly in evaluating AI, such as preserving human dignity. A top policy \\npriority must be establishing human in the loop as a requirement in educational applications,'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 10, 'page_label': '11', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='concepts used more broadly in evaluating AI, such as preserving human dignity. A top policy \\npriority must be establishing human in the loop as a requirement in educational applications, \\ndespite contrary pressures to use AI as an alternative to human decision making. Policies should \\nnot hinder innovation and improvement, nor should they be burdensome to implement. Society \\nneeds an education-focused AI policy that protects civil rights and promotes democratic values \\nin the building, deployment, and governance of automated systems to be used across the many \\ndecentralized levels of the American educational system. \\nFoundation 2: Advance Equity \\n“AI brings educational technology to an inflection point. We can either \\nincrease disparities or shrink them, depending on what we do now.”  \\n—Dr. Russell Shilling \\nA recent Executive Order9 issued by President Biden sought to strengthen the connection among'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 10, 'page_label': '11', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='increase disparities or shrink them, depending on what we do now.”  \\n—Dr. Russell Shilling \\nA recent Executive Order9 issued by President Biden sought to strengthen the connection among \\nracial equity, education and AI, stating that “members of underserved communities—many of \\nwhom have endured generations of discrimination and disinvestment—still confront significant \\nbarriers to realizing the full promise of our great Nation, and the Federal Government has a \\nresponsibility to remove these barriers” and that the Federal Government shall both “pursue \\neducational equity so that our Nation’s schools put every student on a path to success” and also \\n“root out bias in the design and use of new technologies, such as artificial intelligence.” A specific \\nvision of equity, such as described in the Department’s recent report, Advancing Digital Equity for \\nAll10 is essential to policy discussion about AI in education. This report defines digital equity as'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 10, 'page_label': '11', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='All10 is essential to policy discussion about AI in education. This report defines digital equity as \\n \\n8 The White House (September 8, 2022). Readout of White House listening session on tech platform accountability. \\nhttps://www.whitehouse.gov/briefing-room/statements-releases/2022/09/08/readout-of-white-house-listening-session-\\non-tech-platform-accountability/ \\n9 The White House (February 17, 2023). Executive order on further advancing racial equity and support for underserved \\ncommunities through the federal government. https://www.whitehouse.gov/briefing-room/presidential-\\nactions/2023/02/16/executive-order-on-further-advancing-racial-equity  \\n10 U.S. Department of Education, Office of Educational Technology (2022). Advancing digital equity for all: Community-\\nbased recommendations for developing effective digital equity plans to close the digital divide and enable technology-\\nempowered learning. US Department of Education.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 11, 'page_label': '12', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='8 \\n“the condition in which individuals and communities have the information technology capacity \\nthat is needed for full participation in the society and economy of the United States.” \\nIssues related to racial equity and unfair bias were at the heart of every listening session we held. \\nIn particular, we heard a conversation that was increasingly attuned to issues of data quality and \\nthe consequences of using poor or inappropriate data in AI systems for education. Datasets are \\nused to develop AI, and when they are non-representative or contain undesired associations or \\npatterns, resulting AI models may act unfairly in how they detect patterns or automate decisions. \\nSystematic, unwanted unfairness in how a computer detects patterns or automates decisions is \\ncalled “algorithmic bias.” Algorithmic bias could diminish equity at scale with unintended \\ndiscrimination. As this document discussed in the Formative Assessment section, this is not a new'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 11, 'page_label': '12', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='called “algorithmic bias.” Algorithmic bias could diminish equity at scale with unintended \\ndiscrimination. As this document discussed in the Formative Assessment section, this is not a new \\nconversation. For decades, constituents have rightly probed whether assessments are unbiased \\nand fair. Just as with assessments, whether an AI model exhibits algorithmic bias or is judged to \\nbe fair and trustworthy is critical as local school leaders make adoption decisions about using AI \\nto achieve their equity goals.  \\nWe highlight the concept of “algorithmic discrimination” in the Blueprint. Bias is intrinsic to \\nhow AI algorithms are developed using historical data, and it can be difficult to anticipate all \\nimpacts of biased data and algorithms during system design. The Department holds that biases \\nin AI algorithms must be addressed when they introduce or sustain unjust discriminatory \\npractices in education. For example, in postsecondary education, algorithms that make'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 11, 'page_label': '12', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='in AI algorithms must be addressed when they introduce or sustain unjust discriminatory \\npractices in education. For example, in postsecondary education, algorithms that make \\nenrollment decisions, identify students for early intervention, or flag possible student cheating \\non exams must be interrogated for evidence of unfair discriminatory bias—and not only when \\nsystems are designed, but also later, as systems become widely used. \\nFoundation 3: Ensure Safety, Ethics, and Effectiveness \\nA central safety argument in the Department’s policies is the need for data privacy and security \\nin the systems used by teachers, students, and others in educational institutions. The \\ndevelopment and deployment of AI requires access to detailed data. This data goes beyond \\nconventional student records (roster and gradebook information) to detailed information about \\nwhat students do as they learn with technology and what teachers do as they use technology to'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 11, 'page_label': '12', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='conventional student records (roster and gradebook information) to detailed information about \\nwhat students do as they learn with technology and what teachers do as they use technology to \\nteach. AI’s dependence on data requires renewed and strengthened attention to data privacy, \\nsecurity, and governance (as also indicated in the Blueprint). As AI models are not generally \\ndeveloped in consideration of educational usage or student privacy, the educational application \\nof these models may not be aligned with the educational institution’s efforts to comply with \\nfederal student privacy laws, such as FERPA, or state privacy laws.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 12, 'page_label': '13', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='9 \\nFigure 2: The Elementary and Secondary Education Act defines four levels of evidence.\\n \\nFurther, educational leaders are committed to basing their decisions about the adoption of \\neducational technology on evidence of effectiveness—a central foundation of the Department’s \\npolicy. For example, the requirement to base decisions on evidence also arises in the Elementary \\nand Secondary Education Act (ESEA), as amended, which introduced four tiers of evidence (see \\nFigure 2). Our nation’s research agencies, including the Institute of Education Sciences, are \\nessential to producing the needed evidence. The Blueprint calls for evidence of effectiveness, but \\nthe education sector is ahead of that game: we need to insist that AI-enhanced edtech rises to \\nmeet ESEA standards as well. \\nFoundation 4: Promote Transparency  \\nThe central role of complex AI models in a technology’s detection of patterns and'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 12, 'page_label': '13', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='meet ESEA standards as well. \\nFoundation 4: Promote Transparency  \\nThe central role of complex AI models in a technology’s detection of patterns and \\nimplementation of automation is an important way in which AI-enabled applications, products, \\nand services will be different from conventional edtech. The Blueprint introduces the need for \\ntransparency about AI models in terms of disclosure (“notice”) and explanation. In education, \\ndecision makers will need more than notice—they will need to understand how AI models work \\nin a range of general educational use cases, so they can better anticipate limitations, problems, \\nand risks.  \\nAI models in edtech will be approximations of reality and, thus, constituents can always ask these \\nquestions: How precise are the AI models? Do they accurately capture what is most important? \\nHow well do the recommendations made by an AI model fit educational goals? What are the \\nbroader implications of using AI models at scale in educational processes?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 12, 'page_label': '13', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='How well do the recommendations made by an AI model fit educational goals? What are the \\nbroader implications of using AI models at scale in educational processes?  \\nBuilding on what was heard from constituents, the sections of this report develop the theme of \\nevaluating the quality of AI systems and tools using multiple dimensions as follows: \\n● About AI: AI systems and tools must respect data privacy and security. Humans must be \\nin the loop. \\n● Learning: AI systems and tools must align to our collective vision for high-quality \\nlearning, including equity. \\n● Teaching: AI systems and tools must be inspectable, explainable, and provide human \\nalternatives to AI-based suggestions; educators will need support to exercise professional \\njudgment and override AI models, when necessary.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 13, 'page_label': '14', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='10 \\n● Formative Assessment: AI systems and tools must minimize bias, promote fairness, and \\navoid additional testing time and burden for students and teachers. \\n● Research and Development: AI systems and tools must account for the context of \\nteaching and learning and must work well in educational practice, given variability in \\nstudents, teachers, and settings. \\n● Recommendations: Use of AI systems and tools must be safe and effective for students. \\nThey must include algorithmic discrimination protections, protect data privacy, provide \\nnotice and explanation, and provide a recourse to humans when problems arise. The \\npeople most affected by the use of AI in education must be part of the development of \\nthe AI model, system, or tool, even if this slows the pace of adoption. \\n \\nWe return to the idea that these considerations fit together in a comprehensive perspective on \\nthe quality of AI models in the Recommendations section. \\nOverview of Document'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 13, 'page_label': '14', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='We return to the idea that these considerations fit together in a comprehensive perspective on \\nthe quality of AI models in the Recommendations section. \\nOverview of Document \\nWe begin in the next section by elaborating a definition of AI, followed by addressing learning, \\nteaching, assessment, and research and development. Organizing key insights by these topics \\nkeeps us focused on exploring implications for improving educational opportunity and \\noutcomes for students throughout the report. \\nWithin these topics, three important themes are explored: \\n1. Opportunities and Risks. Policies should focus on the most valuable educational \\nadvances while mitigating risks. \\n2. Trust and Trustworthiness. Trust and safeguarding are particularly important in \\neducation because we have an obligation to keep students out of harm’s way and \\nsafeguard their learning experiences.  \\n3. Quality of AI Models. The process of developing and then applying a model is at the'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 13, 'page_label': '14', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='safeguard their learning experiences.  \\n3. Quality of AI Models. The process of developing and then applying a model is at the \\nheart of any AI system. Policies need to support evaluation of the qualities of AI models \\nand their alignment to goals for teaching and learning during the processes of \\neducational adoption and use. \\n“AI in education can only grow at the speed of trust.” \\n—Dr. Dale Allen'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 14, 'page_label': '15', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='11 \\nWhat is AI? \\nOur preliminary definition of AI as automation based on associations requires elaboration. \\nBelow we address three additional perspectives on what constitutes AI. Educators will find these \\ndifferent perspectives arise in the marketing of AI functionality and are important to understand \\nwhen evaluating edtech systems that incorporate AI. One useful glossary of AI for Education \\nterms is the CIRCLS Glossary of Artificial Intelligence Terms for Educators.11  \\nAI is not one thing but an umbrella term for a growing set of modeling capabilities, as visualized \\nin Figure 3. \\nFigure 3: Components, types, and subfields of AI based on Regona et al (2022).12  \\n \\n \\n11 Search for “AI Glossary Educators” to find other useful definitions. \\n12 Regona, Massimo & Yigitcanlar, Tan & Xia, Bo & Li, R.Y.M. (2022). Opportunities and adoption challenges of AI in the \\nconstruction industry: A PRISMA review. Journal of Open Innovation Technology Market and Complexity, 8(45).'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 14, 'page_label': '15', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='construction industry: A PRISMA review. Journal of Open Innovation Technology Market and Complexity, 8(45). \\nhttps://doi.org/10.3390/joitmc8010045'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 15, 'page_label': '16', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='12 \\nPerspective: Human-Like Reasoning \\n“The theory and development of computer systems able to perform tasks \\nnormally requiring human intelligence such as, visual perception, speech \\nrecognition, learning, decision-making, and natural language  \\nprocessing.” 13 \\nBroad cultural awareness of AI may be traced to the landmark 1968 film “2001: A Space \\nOdyssey”—in which the “Heuristically-programmed ALgorithmic” computer, or “HAL,” \\nconverses with astronaut Frank. HAL helps Frank pilot the journey through space, a job that \\nFrank could not do on his own. However, Frank eventually goes outside the spacecraft, HAL \\ntakes over control, and this does not end well for Frank. HAL exhibits human-like behaviors, \\nsuch as reasoning, talking, and acting. Like all applications of AI, HAL can help humans but also \\nintroduces unanticipated risks—especially since AI reasons in different ways and with different \\nlimitations than people do.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 15, 'page_label': '16', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='introduces unanticipated risks—especially since AI reasons in different ways and with different \\nlimitations than people do. \\nThe idea of “human-like” is helpful because it can be a shorthand for the idea that computers \\nnow have capabilities that are very different from the capabilities of early edtech applications. \\nEducational applications will be able to converse with students and teachers, co-pilot how \\nactivities unfold in classrooms, and take actions that impact students and teachers more broadly. \\nThere will be both opportunities to do things much better than we do today and risks that must \\nbe anticipated and addressed. \\nThe “human-like” shorthand is not always useful, however, because AI processes information \\ndifferently from how people process information. When we gloss over the differences between \\npeople and computers, we may frame policies for AI in education that miss the mark. \\nPerspective: An Algorithm that Pursues a Goal'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 15, 'page_label': '16', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='people and computers, we may frame policies for AI in education that miss the mark. \\nPerspective: An Algorithm that Pursues a Goal \\n“Any computational method that is made to act independently towards a \\ngoal based on inferences from theory or patterns in data.” 14 \\nThis second definition emphasizes that AI systems and tools identify patterns and choose actions \\nto achieve a given goal. These pattern recognition capabilities and automated recommendations \\nwill be used in ways that impact the educational process, including student learning and teacher \\ninstructional decision making. For example, today’s personalized learning systems may \\nrecognize signs that a student is struggling and may recommend an alternative instructional \\nsequence. The scope of pattern recognition and automated recommendations will expand. \\n \\n13 IEEE-USA Board of Directors. (February 10, 2017). Artificial intelligence research, development and regulation. IEEE'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 15, 'page_label': '16', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='13 IEEE-USA Board of Directors. (February 10, 2017). Artificial intelligence research, development and regulation. IEEE \\nhttp://globalpolicy.ieee.org/wp-content/uploads/2017/10/IEEE17003.pdf \\n14 Friedman, L., Blair Black, N., Walker, E., & Roschelle, J. (November 8, 2021) Safe AI in education needs you. Association of \\nComputing Machinery blog, https://cacm.acm.org/blogs/blog-cacm/256657-safe-ai-in-education-needs-you/fulltext'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 16, 'page_label': '17', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='13 \\nCorrespondingly, humans must determine the types and degree of responsibility we will grant to \\ntechnology within educational processes, which is not a new dilemma.  \\nFor decades, the lines between the role of teachers and computers have been discussed in \\neducation, for example, in debates using terms such as “’computer-aided instruction,” “blended \\ninstruction,” and “personalized learning.” Yet, how are instructional choices made in systems that \\ninclude both humans and algorithms? Today, AI systems and tools are already enabling the \\nadaptation of instructional sequences to student needs to give students feedback and hints, for \\nexample, during mathematics problem solving or foreign language learning. This discussion \\nabout the use of AI in classroom pedagogy and student learning will be renewed and intensify as \\nAI-enabled systems and tools advance in capability and become more ubiquitous.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 16, 'page_label': '17', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='about the use of AI in classroom pedagogy and student learning will be renewed and intensify as \\nAI-enabled systems and tools advance in capability and become more ubiquitous. \\nLet’s start with another simple example. When a teacher says, “Display a map of ancient Greece \\non the classroom screen,” an AI system may choose among hundreds of maps by noting the \\nlesson objectives, what has worked well in similar classrooms, or which maps have desirable \\nfeatures for student learning. In this case, when an AI system suggests an instructional resource \\nor provides a choice among a few options, the instructor may save time and may focus on more \\nimportant goals. However, there are also forms of AI-enabled automation that the classroom \\ninstructor may reject, for example, enabling an AI system or tool to select the most appropriate \\nand relevant readings for students associated with a historical event. In this case, an educator'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 16, 'page_label': '17', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='instructor may reject, for example, enabling an AI system or tool to select the most appropriate \\nand relevant readings for students associated with a historical event. In this case, an educator \\nmay choose not to utilize AI-enabled systems or tools given the risk of AI creating false facts \\n(“hallucinating”) or steering students toward inaccurate depictions of historical events found on \\nthe internet. Educators will be weighing benefits and risks like these daily. \\nComputers process theory and data differently than humans. AI’s success depends on \\nassociations or relationships found in the data provided to an algorithm during the AI model \\ndevelopment process. Although some associations may be useful, others may be biased or \\ninappropriate. Finding bad associations in data is a major risk, possibly leading to algorithmic \\ndiscrimination. Every guardian is familiar with the problem: A person or computer may say,'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 16, 'page_label': '17', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='inappropriate. Finding bad associations in data is a major risk, possibly leading to algorithmic \\ndiscrimination. Every guardian is familiar with the problem: A person or computer may say, \\n“Our data suggests your student should be placed in this class,” and the guardian may well argue, \\n“No, you are using the wrong data. I know my child better, and they should instead be placed in \\nanother class.” This problem is not limited exclusively to AI systems and tools, but the use of AI \\nmodels can amplify the problem when a computer uses data to make a recommendation because \\nit may appear to be more objective and authoritative, even if it is not. \\nAlthough this perspective can be useful, it can be misleading. A human view of agency, pursuing \\ngoals, and reasoning includes our human abilities to make sense of multiple contexts. For \\nexample, a teacher may see three students each make the same mathematical error but recognize'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 16, 'page_label': '17', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='goals, and reasoning includes our human abilities to make sense of multiple contexts. For \\nexample, a teacher may see three students each make the same mathematical error but recognize \\nthat one student has an Individualized Education Program to address vision issues, another \\nmisunderstands a mathematical concept, and a third just experienced a frustrating interaction on \\nthe playground; the same instructional decision is therefore not appropriate. However, AI \\nsystems often lack data and judgement to appropriately include context as they detect patterns \\nand automate decisions. Further, case studies show that technology has the potential to quickly \\nderail from safe to unsafe or from effective to ineffective when the context shifts even slightly. \\nFor this and other reasons, people must be involved in goal setting, pattern analysis, and \\ndecision-making.15 \\n \\n15 Russell, S. (2019). Human compatible: Artificial intelligence and the problem of control. Viking. ISBN 978-0-525-55861-3.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 17, 'page_label': '18', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='14 \\nPerspective: Intelligence Augmentation \\n“Augmented intelligence is a design pattern for a human-centered \\npartnership model of people and artificial intelligence (AI) working \\ntogether to enhance cognitive performance, including learning, decision \\nmaking, and new experiences.” 16 \\nFoundation #1 (above) keeps humans in the loop and positions AI systems and tools to support \\nhuman reasoning. “Intelligence Augmentation” (IA)17 centers “intelligence” and “decision \\nmaking” in humans but recognizes that people sometimes are overburdened and benefit from \\nassistive tools. AI may help teachers make better decisions because computers notice patterns \\nthat teachers can miss. For example, when a teacher and student agree that the student needs \\nreminders, an AI system may provide reminders in whatever form a student likes without \\nadding to the teacher’s workload. Intelligence Automation (IA) uses the same basic capabilities of'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 17, 'page_label': '18', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='reminders, an AI system may provide reminders in whatever form a student likes without \\nadding to the teacher’s workload. Intelligence Automation (IA) uses the same basic capabilities of \\nAI, employing associations in data to notice patterns, and, through automation, takes actions \\nbased on those patterns. However, IA squarely focuses on helping people in human activities of \\nteaching and learning, whereas AI tends to focus attention on what computers can do. \\nDefinition of “Model” \\nThe above perspectives open a door to making sense of AI. Yet, to assess AI meaningfully, \\nconstituents must consider specific models and how they are developed. In everyday usage, the \\nterm “model” has multiple definitions. We clarify our intended meaning, which is a meaning \\nsimilar to “mathematical model,” below. (Conversely, note that “model” as used in “AI model” is \\nunlike the usage in “model school” or “instructional model” as AI model is not a singular case'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 17, 'page_label': '18', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='similar to “mathematical model,” below. (Conversely, note that “model” as used in “AI model” is \\nunlike the usage in “model school” or “instructional model” as AI model is not a singular case \\ncreated by experts to serve as an exemplar.) \\nAI models are like financial models: an approximation of reality that is useful for identifying \\npatterns, making predictions, or analyzing alternative decisions. In a typical middle school math \\ncurriculum, students use a mathematical model to analyze which of two cell phone plans is \\nbetter. Financial planners use this type of model to provide guidance on a retirement portfolio. \\nAt its heart, AI is a highly advanced mathematical toolkit for building and using models. Indeed, \\nin well-known chatbots, complex essays are written one word at a time. The underlying AI model \\npredicts which next words would likely follow the text written so far; AI chatbots use a very large'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 17, 'page_label': '18', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='in well-known chatbots, complex essays are written one word at a time. The underlying AI model \\npredicts which next words would likely follow the text written so far; AI chatbots use a very large \\nstatistical model to add one likely word at a time, thereby writing surprisingly coherent essays. \\nWhen we ask about the model at the heart of AI, we begin to get answers about “what aspects of \\nreality does the model approximate well?” and “how appropriate is it to the decision to be made?” \\nOne could similarly ask about algorithms—the specific decision-making processes that an AI \\nmodel uses to go from inputs to outputs. One could also ask about the quality of the data used to \\nbuild the model—for example, how representative is that data? Switching among three terms—\\n \\n16 Gartner (n.d.) Gartner glossary: Augmented intelligence. Gartner. https://www.gartner.com/en/information-\\ntechnology/glossary/augmented-intelligence'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 17, 'page_label': '18', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='16 Gartner (n.d.) Gartner glossary: Augmented intelligence. Gartner. https://www.gartner.com/en/information-\\ntechnology/glossary/augmented-intelligence \\n17 Englebart, D.C. (October 1962). Augmenting human intellect: A conceptual framework. SRI Summary Report AFOSR-\\n3223. https://www.dougengelbart.org/pubs/augment-3906.html'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 18, 'page_label': '19', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"15 \\nmodels, algorithms, and data—will become confusing. Because the terms are closely related, \\nwe’ve chosen to focus on the concept of AI models. We want to bring to the fore the idea that \\nevery AI model is incomplete, and it's important to know how well the AI model fits the reality \\nwe care about, where the model will break down, and how. \\nSometimes people avoid talking about the specifics of models to create a mystique. Talking as \\nthough AI is unbounded in its potential capabilities and a nearly perfect approximation to reality \\ncan convey an excitement about the possibilities of the future. The future, however, can be \\noversold. Similarly, sometimes people stop calling a model AI when its use becomes \\ncommonplace, yet such systems are still AI models with all of the risks discussed here. We need \\nto know exactly when and where AI models fail to align to visions for teaching and learning. \\nInsight: AI Systems Enable New Forms of Interaction\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 18, 'page_label': '19', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='to know exactly when and where AI models fail to align to visions for teaching and learning. \\nInsight: AI Systems Enable New Forms of Interaction \\nAI models allow computational processes to make recommendations or plans and also enable \\nthem to support forms of interaction that are more natural, such as speaking to an assistant. AI-\\nenabled educational systems will be desirable in part due to their ability to support more natural \\ninteractions during teaching and learning. In classic edtech platforms, the ways in which teachers \\nand students interact with edtech are limited. Teachers and students may choose items from a \\nmenu or in a multiple-choice question. They may type short answers. They may drag objects on \\nthe screen or use touch gestures. The computer provides outputs to students and teachers \\nthrough text, graphics, and multimedia. Although these forms of inputs and outputs are versatile,'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 18, 'page_label': '19', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='the screen or use touch gestures. The computer provides outputs to students and teachers \\nthrough text, graphics, and multimedia. Although these forms of inputs and outputs are versatile, \\nno one would mistake this style of interaction with the way two people interact with one another; \\nit is specific to human-computer interaction. With AI, interactions with computers are likely to \\nbecome more like human-to-human interactions (see Figure 4). A teacher may speak to an AI \\nassistant, and it may speak back. A student may make a drawing, and the computer may highlight \\na portion of the drawing. A teacher or student may start to write something, and the computer \\nmay finish their sentence—as when today’s email programs can complete thoughts faster than \\nwe can type them. \\nAdditionally, the possibilities for automated actions that can be executed by AI tools are \\nexpanding. Current personalization tools may automatically adjust the sequence, pace, hints, or'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 18, 'page_label': '19', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Additionally, the possibilities for automated actions that can be executed by AI tools are \\nexpanding. Current personalization tools may automatically adjust the sequence, pace, hints, or \\ntrajectory through learning experiences.18 Actions in the future might look like an AI system or \\ntool that helps a student with homework19 or a teaching assistant that reduces a teacher’s \\nworkload by recommending lesson plans that fit a teacher’s needs and are similar to lesson plans \\na teacher previously liked.20 Further, an AI-enabled assistant may appear as an additional \\n“partner” in a small group of students who are working together on a collaborative assignment.21 \\nAn AI-enabled tool may also help teachers with complex classroom routines.22 For example, a \\n \\n18 Shemshack, A., Spector, J.M. (2020) A systematic literature review of personalized learning terms. Smart Learning \\nEnvironments, 7(33). https://doi.org/10.1186/s40561-020-00140-9'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 18, 'page_label': '19', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='18 Shemshack, A., Spector, J.M. (2020) A systematic literature review of personalized learning terms. Smart Learning \\nEnvironments, 7(33). https://doi.org/10.1186/s40561-020-00140-9 \\n19 Roschelle, J., Feng, M., Murphy, R. & Mason, C.A. (2016). Online mathematics homework increases student achievement. \\nAERA Open, 2(4), 1-12. DOI: 10.1177/2332858416673968 \\n20 Celik, I., Dindar, M., Muukkonen, H. & Järvelä, S. (2022). The promises and challenges of artificial intelligence for \\nteachers: A systematic review of research. TechTrends, 66, 616–630. https://doi.org/10.1007/s11528-022-00715-y \\n21 Chen, C., Park, H.W. & Breazeal, C. (2020). Teaching and learning with children: Impact of reciprocal peer learning with \\na social robot on children’s learning and emotive engagement. Computers & Education, 150, \\nhttps://doi.org/10.1016/j.compedu.2020.103836 \\n22 Holstein, K., McLaren, B.M., & Aleven, V. (2019). Co-designing a real-time classroom orchestration tool to support'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 18, 'page_label': '19', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='https://doi.org/10.1016/j.compedu.2020.103836 \\n22 Holstein, K., McLaren, B.M., & Aleven, V. (2019). Co-designing a real-time classroom orchestration tool to support \\nteacher–AI complementarity. Journal of Learning Analytics, 6(2). https://doi.org/10.18608/jla.2019.62.3'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 19, 'page_label': '20', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='16 \\ntool may help teachers with orchestrating23 the movement of students from a full class discussion \\ninto small groups and making sure each group has the materials needed to start their work. \\nFigure 4. Differences that teachers and students may experience in future technologies. \\n \\nKey Recommendation: Human in the Loop AI \\nMany have experienced a moment where technology surprised them with an uncanny ability to \\nrecommend what feels like a precisely personalized product, song, or even phrase to complete a \\nsentence in a word processor such as the one being used to draft this document. Throughout this \\nsupplement, we talk about specific, focused applications where AI systems may bring value (or \\nrisks) into education. At no point do we intend to imply that AI can replace a teacher, a guardian, \\nor an educational leader as the custodian of their students’ learning. We talk about the limitations'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 19, 'page_label': '20', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='or an educational leader as the custodian of their students’ learning. We talk about the limitations \\nof models in AI and the conversations that educational constituents need to have about what \\nqualities they want AI models to have and how they should be used. \\n“We can use AI to study the diversity, the multiplicity of effective learning \\napproaches and think about the various models to help us get a broader \\nunderstanding of what effective, meaningful engagement might look like \\nacross a variety of different contexts.” \\n—Dr. Marcelo Aaron Bonilla Worsley \\n \\n \\n23 Roschelle, J., Dimitriadis, Y. & Hoppe, U. (2013). Classroom orchestration: Synthesis. Computers & Education, 69, 512-526. \\nhttps://doi.org/10.1016/j.compedu.2013.04.010'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 20, 'page_label': '21', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='17 \\nThese limitations lead to our first recommendation: that we pursue a vision of AI where humans \\nare in the loop. That means that people are part of the process of noticing patterns in an \\neducational system and assigning meaning to those patterns. It also means that teachers remain \\nat the helm of major instructional decisions. It means that formative assessments involve teacher \\ninput and decision making, too. One loop is the cycle of recognizing patterns in what students do \\nand selecting next steps or resources that could support their learning. Other loops involve \\nteachers planning and reflecting on lessons. Response to Intervention is another well-known \\ntype of loop.  \\nThe idea of humans in the loop is part of our broader discussions happening about AI and \\nsociety, not just AI in education. Interested readers could look for more on human-centered AI, \\nresponsible AI, value-sensitive AI, AI for social good, and other similar terms that ally with'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 20, 'page_label': '21', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='society, not just AI in education. Interested readers could look for more on human-centered AI, \\nresponsible AI, value-sensitive AI, AI for social good, and other similar terms that ally with \\nhumans in the loop, such as “human-centered AI.” \\nExercising judgement and control in the use of AI systems and tools is an essential part of \\nproviding the best opportunity to learn for all students—especially when educational decisions \\ncarry consequence. AI does not have the broad qualities of contextual judgment that people do. \\nTherefore, people must remain responsible for the health and safety of our children, for all \\nstudents’ educational success and preparation for their futures, and for creating a more equitable \\nand just society.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 21, 'page_label': '22', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='18 \\nLearning \\nThe Department’s long-standing edtech vision sees students as active learners; students \\nparticipate in discussions that advance their understanding, use visualizations and simulations to \\nexplain concepts as they relate to the real world, and leverage helpful scaffolding and timely \\nfeedback as they learn. Constituents want technology to align to and build on these and other \\nresearch-based understandings of how people learn. Educators can draw upon two books titled \\nHow People Learn and How People Learn II by the National Academies of Sciences, Engineering, \\nand Medicine for a broad synthesis of what we know about learning.24 As we shape AI-enhanced \\nedtech around research-based principles, a key goal must be to strengthen and support learning \\nfor those who have experienced unfavorable circumstances for learning, such as caused by the \\nCOVID-19 pandemic or by broader inequities. And we must keep a firm eye toward the forms of'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 21, 'page_label': '22', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='for those who have experienced unfavorable circumstances for learning, such as caused by the \\nCOVID-19 pandemic or by broader inequities. And we must keep a firm eye toward the forms of \\nlearning that will most benefit learners in their future lives in communities and workplaces. \\nExamples of AI supporting learning principles in this section include the following: AI-based \\ntutoring for students as they solve math problems (based on cognitive learning theories), \\nadapting to learners with special needs (based on the Universal Design for Learning framework \\nand related theories), and AI support for effective student teamwork (based on theories in the \\nfield called “Computer Supported Collaborative Learning”). \\nInsight: AI Enables Adaptivity in Learning \\nAdaptivity has been recognized as a key way in which technology can improve learning.25 AI can \\nbe a toolset for improving the adaptivity of edtech. AI may improve a technology’s ability to'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 21, 'page_label': '22', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Adaptivity has been recognized as a key way in which technology can improve learning.25 AI can \\nbe a toolset for improving the adaptivity of edtech. AI may improve a technology’s ability to \\nmeet students where they are, build on their strengths, and grow their knowledge and skills. \\nBecause of AI’s powers of work with natural forms of input and the foundational strengths of AI \\nmodels (as discussed in the What is AI? section), AI can be an especially strong toolkit for \\nexpanding the adaptivity provided to students. \\nAnd yet, especially with AI, adaptivity is always more specific and limited than what a broad \\nphrase like “meet students where they are” might suggest. Core limits arise from the nature of \\nthe model at the heart of any specific AI-enabled system. Models are approximations of reality. \\nWhen important parts of human learning are left out of the model or less fully developed, the'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 21, 'page_label': '22', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='the model at the heart of any specific AI-enabled system. Models are approximations of reality. \\nWhen important parts of human learning are left out of the model or less fully developed, the \\nresulting adaptivity will also be limited, and the resulting supports for learning may be brittle or \\nnarrow. Consequently, this section on Learning focuses on one key concept: Work toward AI \\nmodels that fit the fullness of visions for learning—and avoid limiting learning to what AI can \\ncurrently model well. \\nAI models are demonstrating greater skills because of advances in what are called “large language \\nmodels” or sometimes “foundational models.” These very general models still have limits. For \\nexample, generative AI models discussed in the mainstream news can quickly generate \\nconvincing essays about a wide variety of topics while other models can draw credible images \\nbased on just a few prompts. Despite the excitement about foundational models, experts in our'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 21, 'page_label': '22', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='convincing essays about a wide variety of topics while other models can draw credible images \\nbased on just a few prompts. Despite the excitement about foundational models, experts in our \\n \\n24 National Research Council. 2000. How people learn: Brain, mind, experience, and school. The National Academies Press. \\nhttps://doi.org/10.17226/9853; National Academies of Sciences, Engineering, and Medicine. 2018. How people learn II: \\nLearners, contexts, and cultures. The National Academies Press. https://doi.org/10.17226/24783 \\n25 Aleven, V., McLaughlin, E. A., Glenn, R. A., & Koedinger, K. R. (2016). Instruction based on adaptive learning \\ntechnologies. In Mayer, R.E. & Alexander, P.A., Handbook of research on learning and instruction, 522-560. ISBN: 113883176X'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 22, 'page_label': '23', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='19 \\nlistening sessions warned that AI models are narrower than visions for human learning and that \\ndesigning learning environments with these limits in mind remains very important. The models \\nare also brittle and can’t perform well when contexts change. In addition, they don’t have the \\nsame “common sense” judgment that people have, often responding in ways that are unnatural \\nor incorrect.26 Given the unexpected ways in which foundational models miss the mark, keeping \\nhumans in the loop remains highly important. \\nIntelligent Tutoring Systems: An Example of AI Models \\nOne long-standing type of AI-enabled technology is an Intelligent Tutoring System (ITS).27 In an \\nearly success, scientists were able to build accurate models of how human experts solve \\nmathematical problems. The resulting model was incorporated into a system that would observe \\nstudent problem solving as they worked on mathematical problems on a computer. Researchers'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 22, 'page_label': '23', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='mathematical problems. The resulting model was incorporated into a system that would observe \\nstudent problem solving as they worked on mathematical problems on a computer. Researchers \\nwho studied human tutors found that feedback on specific steps (and not just right or wrong \\nsolutions) is a likely key to why tutoring is so effective.28 For example, when a student diverged \\nfrom the expert model, the system gave feedback to help the student get back on track.29 \\nImportantly, this feedback went beyond right or wrong, and instead, the model was able to \\nprovide feedback on specific steps of a solution process. A significant advancement of AI, \\ntherefore, can be its ability to provide adaptivity at the step-by-step level and its ability to do so \\nat scale with modest cost. \\nAs a research and development (R&D) field emerged to advance ITS, the work has gone beyond \\nmathematics problems to additional important issues beyond step-by-step problem solving. In'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 22, 'page_label': '23', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='As a research and development (R&D) field emerged to advance ITS, the work has gone beyond \\nmathematics problems to additional important issues beyond step-by-step problem solving. In \\nthe early work, some limitations can be observed. The kinds of problems that an ITS could \\nsupport were logical or mathematical, and they were closed tasks, with clear expectations for \\nwhat a solution and solution process should look like. Also, the “approximation of reality” in \\nearly AI models related to cognition and not to other elements of human learning, for example, \\nsocial or motivational aspects. Over time, these early limitations have been addressed in two \\nways: by expanding the AI models and by involving humans in the loop, a perspective that is also \\nimportant now. Today, for example, if an ITS specializes in feedback as a student practices, a \\nhuman teacher could still be responsible for motivating student engagement and self-regulation'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 22, 'page_label': '23', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='important now. Today, for example, if an ITS specializes in feedback as a student practices, a \\nhuman teacher could still be responsible for motivating student engagement and self-regulation \\nalong with other aspects of instruction. In other contemporary examples, the computer ITS \\nmight focus on problem solving practice, while teachers work with students in small groups. \\nFurther, students can be in the loop with AI, as is the case with “open learner models”—a type of \\nAI-enabled system that provides information to support student self-monitoring and \\nreflection.30 \\n \\n26 Dieterle, E., Dede, C. & Walker, M. (2022). The cyclical ethical effects of using artificial intelligence in education. AI & \\nSociety. https://link.springer.com/article/10.1007/s00146-022-01497-w \\n27 Mousavinasab, E., Zarifsanaiey, N., R. Niakan Kalhori, S., Rakhshan, M., Keikha, L., & Ghazi Saeedi, M. (2021). Intelligent'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 22, 'page_label': '23', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Society. https://link.springer.com/article/10.1007/s00146-022-01497-w \\n27 Mousavinasab, E., Zarifsanaiey, N., R. Niakan Kalhori, S., Rakhshan, M., Keikha, L., & Ghazi Saeedi, M. (2021). Intelligent \\ntutoring systems: A systematic review of characteristics, applications, and evaluation methods. Interactive Learning \\nEnvironments, 29(1), 142–163. https://psycnet.apa.org/doi/10.1080/10494820.2018.1558257 \\n28 Van Lehn, K. (2011) The relative effectiveness of human tutoring, intelligent tutoring systems, and other tutoring \\nsystems. Educational Psychologist, 46(4), 197-221. https://doi.org/10.1080/00461520.2011.611369 \\n29 Ritter, S., Anderson, J.R., Koedinger, K.R. & Corbett, A. (2007). Cognitive Tutor: Applied research in mathematics \\neducation. Psychonomic Bulletin & Review, 14, 249–255/ https://doi.org/10.3758/BF03194060 \\n30 Winne, P.H. (2021). Open learner models working in symbiosis with self-regulating learners: A research agenda.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 22, 'page_label': '23', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='30 Winne, P.H. (2021). Open learner models working in symbiosis with self-regulating learners: A research agenda. \\nInternational Journal of Artificial Intelligence in Education, 31(3), 446-459. https://doi.org/10.1007/s40593-020-00212-4'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 23, 'page_label': '24', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='20 \\nAlthough R&D along the lines of an ITS should not limit the view of what’s possible, such an \\nexample is useful because so much research and evaluation has been done on the ITS approach. \\nResearchers have looked across all the available high-quality studies in a meta-analysis and \\nconcluded that ITS approaches are effective.31 Right now, many school systems are looking at \\nhigh-intensity human tutoring to help students with unfinished learning. Human tutoring is very \\nexpensive, and it is hard to find enough high-quality human tutors. With regard to large-scale \\nneeds, if it is possible for an ITS to supplement what human tutors do, it might be possible to \\nextend beyond the amount of tutoring that people can provide to students.  \\nImportant Directions for Expanding AI-Based Adaptivity \\nAdaptivity is sometimes referred to as “personalization.” Although this is a convenient term, \\nmany observers have noted how imprecise it is.32 For some educators, personalization means'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 23, 'page_label': '24', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Adaptivity is sometimes referred to as “personalization.” Although this is a convenient term, \\nmany observers have noted how imprecise it is.32 For some educators, personalization means \\ngiving learners “voice and choice,” and for others it means that a learning management system \\nrecommends an individual “playlist” of activities to each student. Hidden in that imprecision is \\nthe reality that many edtech products that personalize do so in limited ways. Adjusting the \\ndifficulty and the order of lesson materials are among the two most common ways that edtech \\nproducts adapt. And yet, any teacher knows there is more to supporting learning than adjusting \\nthe difficulty and sequence of materials. For example, a good teacher can find ways to engage a \\nstudent by connecting to their own past experiences and can shape explanations until they really \\nconnect in an “aha!” moment for that student. When we say, “meet the learner where they are,”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 23, 'page_label': '24', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='student by connecting to their own past experiences and can shape explanations until they really \\nconnect in an “aha!” moment for that student. When we say, “meet the learner where they are,” \\nhuman teachers bring a much more complete picture of each learner than most available edtech. \\nThe teacher is also not likely to “over personalize” (by performing like an algorithm that only \\npresents material for which the learner has expressed interest), thereby limiting the student’s \\nexposure to new topics. The nature of “teachable moments” that a human teacher can grasp is \\nbroader than the teachable moments today’s AI models grasp. \\nIn our listening sessions, we heard many ways in which the core models in an AI system must be \\nexpanded. We discuss these below. \\n1. From deficit-based to asset-oriented. Listening session attendees noted that the rhetoric \\naround adaptivity has often been deficit-based; technology tries to pinpoint what a'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 23, 'page_label': '24', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"1. From deficit-based to asset-oriented. Listening session attendees noted that the rhetoric \\naround adaptivity has often been deficit-based; technology tries to pinpoint what a \\nstudent is lacking and then provides instruction to fill that specific gap. Teachers also \\norient to students' strengths; they find competencies or “assets” a student has and use \\nthose to build up the students’ knowledge. AI models cannot be fully equitable while \\nfailing to recognize or build upon each student’s sources of competency. AI models that \\nare more asset-oriented would be an advance.  \\n2. From individual cognition to including social and other aspects of learning. The \\nexisting adaptivity rhetoric has also tended to focus on individualized learning and \\nmostly on cognitive elements of learning, with motivational and other elements only \\nbrought in to support the cognitive learning goals. Attendees observe that their vision for\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 23, 'page_label': '24', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='mostly on cognitive elements of learning, with motivational and other elements only \\nbrought in to support the cognitive learning goals. Attendees observe that their vision for \\nlearning is broader than cognition. Social learning is important, for example, especially \\n \\n31 Kulik, J.A., & Fletcher, J.D. (2016). Effectiveness of intelligent tutoring systems: A meta-analytic review. Review of \\nEducational Research, 86(1), 42–78; Ma, W., Adescope, O.O, Nesbit, J.C. & Liu, Q. (2014). Intelligent tutoring systems and \\nlearning outcomes: A meta-analysis. Journal of Educational Psychology, 106(4), 901–918. http://dx.doi.org/10.1037/a0037123 \\n32 Plass, J.L., & Pawar, S. (2020). Toward a taxonomy of adaptivity for learning. Journal of Research on Technology in \\nEducation, 52(3), 275–300. https://doi.org/10.1080/15391523.2020.1719943;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 24, 'page_label': '25', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='21 \\nfor students to learn to reason, explain, and justify. For students who are learning English, \\ncustomized and adaptive support for improving language skills while learning curricular \\ncontent is clearly important. Developing self-regulation skills is also important. A modern \\nvision of learning is not individualistic; it recognizes that students learn in groups and \\ncommunities too.  \\n3. From neurotypical to neurodiverse learners. AI models could help in including \\nneurodiverse learners (students who access, process, and interact with the world in less \\ncommon ways than “neurotypical” students) who could benefit from different learning \\npaths and from forms of display and input that fit their strengths. Constituents want AI \\nmodels that can support learning for neurodiverse learners and learners with disabilities. \\nThus, they want AI models that can work with multiple paths to learning and multiple'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 24, 'page_label': '25', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='models that can support learning for neurodiverse learners and learners with disabilities. \\nThus, they want AI models that can work with multiple paths to learning and multiple \\nmodalities of interaction. Such models should be tested for efficacy, to guard against the \\npossibility that some students could be assigned a “personalized” but inadequate learning \\nresource. In addition, some systems for neurodiverse students are presently \\nunderutilized, so designs that support intended use will also be important. \\n4. From fixed tasks to active, open, and creative tasks. As mentioned above, AI models are \\nhistorically better at closed tasks like solving a math problem or logical tasks like playing \\na game. In terms of life-wide and lifelong opportunities, we value learning how to \\nsucceed at open-ended and creative tasks that require extended engagement from the \\nlearner, and these are often not purely mathematical or logical. We want students to learn'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 24, 'page_label': '25', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"succeed at open-ended and creative tasks that require extended engagement from the \\nlearner, and these are often not purely mathematical or logical. We want students to learn \\nto invent and create innovative approaches. We want AI models that enable progress on \\nopen, creative tasks. \\n5. From correct answers to additional goals. At the heart of many adaptivity approaches \\nnow on the market, the model inside the technology counts students' wrong answers and \\ndecides whether to speed up, slow down, or offer a different type of learning support. Yet, \\nright and wrong answers are not the only learning goals. We want students to learn how \\nto self-regulate when they experience difficulties in learning, for example, such as being \\nable to persist in working on a difficult problem or knowing how and when to ask for \\nhelp. We want learners to become skilled in teamwork and in leading teams. As students \\ngrow, we want them to develop more agency and to be able to act on their own to\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 24, 'page_label': '25', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='help. We want learners to become skilled in teamwork and in leading teams. As students \\ngrow, we want them to develop more agency and to be able to act on their own to \\nadvance toward their own learning goals.  \\nListing every dimension of expansion that we heard in our listening sessions is beyond the scope \\nof this report. Some additional dimensions are presented in the following sections on Teaching, \\nAssessment, and Research. For example, in Research, we discuss all the ways in which AI systems \\nhave trouble with context—context that humans readily grasp and consider.  \\nOverall, constituents in the listening sessions realized we need an ambitious outlook on learning \\nto respond to the future today’s learners face. Constituents were concerned about ways in which \\nAI might narrow learning. For example, if the incorporation of AI into education slowed \\nattention to students’ skills on creative, open-ended tasks and their ability to lead and collaborate'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 24, 'page_label': '25', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='AI might narrow learning. For example, if the incorporation of AI into education slowed \\nattention to students’ skills on creative, open-ended tasks and their ability to lead and collaborate \\nin teams, then school districts may be less able to realize their students’ progress in relation to a \\nPortrait of a Graduate who excels in communication and other skills valued in communities and \\ncareers.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 25, 'page_label': '26', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='22 \\nConstituents reminded us that as we conceptualize what we want AI in edtech to accomplish, we \\nmust start and constantly revisit a human-centered vision of learning. \\nA Duality: Learning With and About AI \\nAs AI is brought into schools, two broad perspectives about AI in education arise: (1) AI in support \\nof student learning; and (2) support for learning about AI and related technologies. So far, we’ve \\ndiscussed AI systems and tools to support student learning and mastery of subjects like \\nmathematics and writing. Yet, it is also important that students learn about AI, critically examine \\nits presence in education and society, and determine its role and value in their own lives and \\ncareers. We discuss risks across each section in this report. Here, it is important for students to \\nbecome more aware of and savvy to the risks of AI—including risks of bias and surveillance—as \\nthey appear in all elements of their lives. In the recent past, schools have supported students’'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 25, 'page_label': '26', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='become more aware of and savvy to the risks of AI—including risks of bias and surveillance—as \\nthey appear in all elements of their lives. In the recent past, schools have supported students’ \\nunderstanding of cybersecurity, for example. AI will bring new risks, and students need to learn \\nabout them. \\nWe are encouraged by efforts we’ve seen underway that would give students opportunities to \\nlearn about how AI works while also giving them opportunities to discuss relevant topics like \\nprivacy and security.33 Other learning goals are noted in the K-12 Computer Science Framework. \\nWe’ve seen that students can begin learning about AI in elementary, middle, and high school. \\nThey can use AI to design simulations and products that they find exciting. And we’ve seen that \\nstudents want to talk about the ethics of products they experience in their everyday lives and \\nhave much to say about the kinds of products they’d like to see or not see in school. (And later, in'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 25, 'page_label': '26', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='students want to talk about the ethics of products they experience in their everyday lives and \\nhave much to say about the kinds of products they’d like to see or not see in school. (And later, in \\nthe Research section, we note the desire for co-design processes that involve students in creating \\nthe next generation of AI-enabled edtech). Overall, it’s important to balance attention to using AI \\nto support learning and giving students opportunities to learn about AI. \\nA Challenge: Systems Thinking About AI in Education \\nAs AI expands into the educational system, our listening session attendees reminded us that it \\nwill be entering parts or locations of the system that are presently dysfunctional. AI is certainly \\nnot a fix for broken systems, and instead, must be used with even more care when the systems’ \\ncontext is unstable or uncertain.  \\n \\n33 Forsyth, S., Dalton, B., Foster, E.H., Walsh, B., Smilack, J., & Yeh, T. (2021, May). Imagine a more ethical AI: Using stories'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 25, 'page_label': '26', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"context is unstable or uncertain.  \\n \\n33 Forsyth, S., Dalton, B., Foster, E.H., Walsh, B., Smilack, J., & Yeh, T. (2021, May). Imagine a more ethical AI: Using stories \\nto develop teens' awareness and understanding of artificial intelligence and its societal impacts. In 2021 Conference on \\nResearch in Equitable and Sustained Participation in Engineering, Computing, and Technology (RESPECT). IEEE. \\nhttps://doi.org/10.1109/RESPECT51740.2021.9620549; Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., & Breazeal, C. \\n(2022). Integrating ethics and career futures with technical learning to promote AI literacy for middle school students: An \\nexploratory study. International Journal of Artificial Intelligence in Education, 1–35. https://doi.org/10.1007/s40593-022-\\n00293-3\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 26, 'page_label': '27', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"23 \\n“First and foremost, they are getting deployed in educational contexts \\nthat are already fragmented and broken and unequal. Technology \\ndoesn't discriminate—we do. So, as we think about the application of \\nthese new systems, we have to really think about the contextual \\napplication of AI.”  \\n—Dr. Nicole Turner \\nAs discussed previously, because AI systems and tools do not fully align with goals for learning, \\nwe have to design educational settings to situate AI in the right place, where educators and other \\nadults can make effective use of these tools for teaching and learning. Within the ITS example, \\nwe saw that AI could make learning by practicing math problems more effective, and a whole \\ncurricular approach might include roles for teachers that emphasize mathematical practices like \\nargumentation and modeling. Further, small-group work is likely to remain important: Students \\nmight work in small groups to use mathematics to predict or justify as they work on responding\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 26, 'page_label': '27', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='argumentation and modeling. Further, small-group work is likely to remain important: Students \\nmight work in small groups to use mathematics to predict or justify as they work on responding \\nto a realistic challenge. At the present, one “right place” for people, and not AI, is understanding \\nhow learning can be culturally responsive and culturally sustaining, as AI is not even close to \\nbeing ready to connect learning to the unique strengths in a student’s community and family. \\nOpen Questions About AI for Learning \\nWith advances occurring in the foundations for AI, opportunities to use AI in support of learning \\nare rapidly expanding. As we explore these opportunities, the open questions below deserve \\nongoing attention: \\n● To what extent is AI enabling adaptation to students’ strengths and not just deficits? Is AI \\nenabling improved support for learners with disabilities and English language learners? \\n● How are youth voices involved in choosing and using AI for learning?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 26, 'page_label': '27', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='enabling improved support for learners with disabilities and English language learners? \\n● How are youth voices involved in choosing and using AI for learning? \\n● Is AI leading to narrower student activities (e.g., procedural math problems), or the fuller \\nrange of activities highlighted in the National Educational Technology Plan (NETP), \\nwhich emphasizes features such as personalized learning, project-based learning, learning \\nfrom visualizations, simulations, and virtual reality, as well as learning across school, \\ncommunity, and familial settings? \\n● Is AI supporting the whole learner, including social dimensions of learning such as \\nenabling students to be active participants in small group and collaborative learning? For \\nexample, does AI contribute to aspects of student collaboration we value like shared \\nattention, mutual engagement, peer help, self-regulation, and building on each other’s \\ncontributions?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 26, 'page_label': '27', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='example, does AI contribute to aspects of student collaboration we value like shared \\nattention, mutual engagement, peer help, self-regulation, and building on each other’s \\ncontributions? \\n● When AI is used, are students’ privacy and data protected? Are students and their \\nguardians informed about what happens with their data? \\n● How strong are the processes or systems for monitoring student use of AI for barriers, \\nbias, or other undesirable consequences of AI use by learners? How are emergent issues \\naddressed? \\n● Is high-quality research or evaluations about the impacts of using the AI system for \\nstudent learning available? Do we know not only whether the system works but for whom \\nand under what conditions?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 27, 'page_label': '28', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='24 \\nKey Recommendation: Seek AI Models Aligned to a Vision for Learning \\nWe’ve called attention to how advances in AI are important to adaptivity but also to ways in \\nwhich adaptivity is limited by the model’s inherent quality. We noted that a prior wave of edtech \\nused the term “personalized” in differing ways, and it was often important to clarify what \\npersonalization meant for a particular product or service. Thus, our key recommendation is to \\ntease out the strengths and limitations of AI models inside forthcoming edtech products and to \\nfocus on AI models that align closely to desired visions of learning. AI is now advancing rapidly, \\nand we should differentiate between products that have simple AI-like features inside and \\nproducts that have more sophisticated AI models.  \\nLooking at what’s happening in research and development, we can see significant effort and push \\ntoward overcoming these limitations. We noted that decision makers need to be careful about'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 27, 'page_label': '28', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Looking at what’s happening in research and development, we can see significant effort and push \\ntoward overcoming these limitations. We noted that decision makers need to be careful about \\nselecting AI models that might narrow their vision for learning, as general artificial intelligence \\ndoes not exist. And because AI models will always be narrower than real world experience, we \\nneed to proceed with systems thinking in which humans are in the loop, with the strengths and \\nweaknesses of the specific educational system considered. We hold that the full system for \\nlearning is broader than its AI component.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 28, 'page_label': '29', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='25 \\nTeaching \\nTeachers have long envisioned many things that technology could make possible for teachers, \\ntheir classrooms, and their students but not the changes wrought by the recent pandemic. Today, \\nnearly all teachers have experienced uses of technologies for instruction that no one anticipated. \\nSome of those experiences were positive, and others were not. All of the experiences provide an \\nimportant context as we think further about teaching and technology. \\nThere is a critical need to focus on addressing the challenges teachers experience. It must \\nbecome easier for teachers to do the amazing work they always do. We must also remember why \\npeople choose the teaching profession and ensure they can do the work that matters. This \\nsection discusses examples of AI supporting teachers and teaching including these concepts: AI \\nassistants to reduce routine teaching burdens; AI that provides teachers with recommendations'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 28, 'page_label': '29', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='section discusses examples of AI supporting teachers and teaching including these concepts: AI \\nassistants to reduce routine teaching burdens; AI that provides teachers with recommendations \\nfor their students’ needs and extends their work with students; and AI that helps teachers to \\nreflect, plan, and improve their practice. \\n“One opportunity I see with AI is being able to reduce the amount of \\nattention I have to give to administrative things and increase the amount \\nof attention I can give to my students with their learning needs in the \\nclassroom. So that\\'s the first one that I\\'d say that I\\'m super excited about \\nthe possibility of AI to support me as a teacher.\"  \\n—Vidula Plante \\nAlways Center Educators in Instructional Loops \\nTo succeed with AI as an enhancement to learning and teaching, we need to always center \\neducators (ACE). Practically speaking, practicing “ACE in AI” means keeping a humanistic view of'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 28, 'page_label': '29', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='To succeed with AI as an enhancement to learning and teaching, we need to always center \\neducators (ACE). Practically speaking, practicing “ACE in AI” means keeping a humanistic view of \\nteaching front and center. ACE leads the Department to confidently respond “no” when asked \\n“will AI replace teachers?” ACE is not just about making teachers’ jobs easier but also making it \\npossible to do what most teachers want to do. That includes, for example, understanding their \\nstudents more deeply and having more time to respond in creative ways to teachable moments. \\nTo bring more precision to how and where we should center educators, we return to our \\nadvocacy for human in the loop AI and ask, what are the loops in which teachers should be \\ncentered? Figure 5 suggests three key loops (inspired by research on adaptivity loops34): \\n  \\n \\n34 Aleven, V., McLaughlin, E.A., Glenn, R.A., & Koedinger, K.R. (2016). Instruction based on adaptive learning technologies.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 28, 'page_label': '29', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='34 Aleven, V., McLaughlin, E.A., Glenn, R.A., & Koedinger, K.R. (2016). Instruction based on adaptive learning technologies. \\nIn Mayer, R.E. & Alexander, P.A., Handbook of research on learning and instruction, 522-560. ISBN: 113883176X'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 29, 'page_label': '30', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='26 \\n \\n1. The loop in which teachers make moment-to-moment decisions as they do the \\nimmediate work of teaching.  \\n2. The loop in which teachers prepare for, plan, and reflect on teaching, which includes \\nprofessional development. \\n3. The loop in which teachers participate in decisions about the design of AI-enabled \\ntechnologies, participate in selecting the technologies, and shape the evaluation of \\ntechnologies—thus setting a context for not only their own classroom but those of fellow \\nteachers as well.  \\nFigure 5: Three ways to center educators as we conceptualize human in the loop AI  \\n \\n \\nPlease note that in the next section, on Formative Assessment, we also discuss teachers’ important \\nrole in feedback loops that support students and enable school improvement. That section also \\nincludes a discussion of the concepts of “bias” and “fairness,” which are important to teachers. \\nInsight: Using AI to Improve Teaching Jobs'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 29, 'page_label': '30', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='includes a discussion of the concepts of “bias” and “fairness,” which are important to teachers. \\nInsight: Using AI to Improve Teaching Jobs \\nThe job of teaching is notoriously complex, with teachers making thousands of decisions each \\nday. Teachers participate in classroom processes, in interactions with students beyond \\nclassrooms, in work with fellow teachers, and in administrative functions. They also are part of \\ntheir communities and thus are expected to interact with families and caregivers.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 30, 'page_label': '31', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='27 \\nIf the teacher is able to efficiently predict and understand the range of \\nother answers given by students in the class, it becomes possible to think \\ncreatively about the novel answer and figure how and why the student \\nmight have generated it.35 \\nWe think about how much easier some everyday tasks have become. We can request and receive \\nalerts and notifications about events. Selecting music that we want to hear used to be a multistep \\nprocess (even with digital music), and now we can speak the name of a song we want to hear, and \\nit plays. Likewise, mapping a journey used to require a cumbersome study of maps, but now cell \\nphones let us choose among several transportation options to reach a destination. Why can’t \\nteachers be supported to notice changing student needs and provided with supports to enact a \\ntechnology-rich lesson plan? Why can’t they more easily plan their students’ learning journeys?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 30, 'page_label': '31', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='teachers be supported to notice changing student needs and provided with supports to enact a \\ntechnology-rich lesson plan? Why can’t they more easily plan their students’ learning journeys? \\nWhen things change in a classroom, as they always do, why don’t the tools of the classroom make \\nit easier for teachers to adapt to student strengths and needs on the fly? \\nFigure 6: Teachers work about 50 hours a week, spending less than half the time in direct \\ninteraction with students. \\n \\n \\nA report by McKinsey36 first suggested that AI’s initial benefit could be to improve teaching jobs \\nby reducing low-level burdens in administrative or clerical work (Figure 6). The report also \\nsuggests that recovered time from AI-enabled technology should be rededicated toward more \\n \\n35 Hammerness, K., Darling-Hammond, L., & Bransford, J. (2005). Preparing teachers for a changing world: What teachers should \\nlearn and be able to do. Jossey-Bass. ISBN: 0787996343'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 30, 'page_label': '31', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='35 Hammerness, K., Darling-Hammond, L., & Bransford, J. (2005). Preparing teachers for a changing world: What teachers should \\nlearn and be able to do. Jossey-Bass. ISBN: 0787996343 \\n36 Bryant, J., Heitz,C., Sanghvi, S., & Wagle, D. (2020, January 14). How artificial intelligence will impact K-12 teachers. \\nMcKinsey. https://www.mckinsey.com/industries/education/our-insights/how-artificial-intelligence-will-impact-k-12-\\nteachers'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 31, 'page_label': '32', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='28 \\neffective instruction—particularly, outcomes such as reducing the average 11 hours of weekly \\npreparation down to only six. We highlight these opportunities and two others below. \\n1. Handling low-level details to ease teaching burdens and increase focus on students. A \\ngood teacher must master all levels of details, big and small. When working with a \\nparticular student, the teacher may wish to later send that student a helpful learning \\nresource. How will they remember to send it? A voice assistant or other forms of an AI \\nassistant could make it easier to stay organized by categorizing simple voice notes for \\nteachers to follow up on after a classroom session ends. We are beginning to see AI-\\nenabled voice assistants in the market, and they could do many simple tasks so that the \\nteachers can stay focused on students. These tasks can include record-keeping, starting \\nand stopping activities, controlling displays, speakers, and other technologies in the'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 31, 'page_label': '32', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"teachers can stay focused on students. These tasks can include record-keeping, starting \\nand stopping activities, controlling displays, speakers, and other technologies in the \\nclassroom, and providing reminders. Many workers may eventually use assistants to \\nmake their jobs easier, and teachers are the most deserving of efforts to ease their jobs \\nnow.  \\n2. Extending beyond the teacher's availability with their students but continuing to \\ndeliver on the teacher’s intent. Teachers almost always want to do more with each \\nstudent than they can, given the limited number of hours before the next school day. A \\nteacher may wish to sit with the student as they practice 10 more math problems, giving \\nthem ongoing support and feedback. If the teacher can sit with the student for only three \\nproblems, perhaps they could delegate to an AI-enabled learning system to help with the \\nrest. Teachers cannot be at their best if on call at all hours to help with homework, but\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 31, 'page_label': '32', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='problems, perhaps they could delegate to an AI-enabled learning system to help with the \\nrest. Teachers cannot be at their best if on call at all hours to help with homework, but \\nperhaps they can indicate what types of supports, hints, and feedback they want students \\nto receive while studying after school hours. An AI assistant can ensure that students have \\nthat support wherever and whenever they do homework or practice skills on their own. \\nTeachers may wish to provide more extensive personal notes to families/caregivers, and \\nperhaps an AI assistant could help with drafts based on students’ recent classroom work. \\nThen, the teacher could review the AI-generated comments and quickly edit where \\nneeded before returning it to the student for another draft. AI tools might also help \\nteachers with language translation so they can work with all parents and caregivers of \\ntheir students. AI tools might also help teachers with awareness. For example, in the next'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 31, 'page_label': '32', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='teachers with language translation so they can work with all parents and caregivers of \\ntheir students. AI tools might also help teachers with awareness. For example, in the next \\nsection, Formative Assessment, we note that teachers can’t always know what’s going on for \\neach student and in each small group of students; emerging products might signal to the \\nteacher when a student or teacher may need some more personal attention. \\n3. Making teacher professional development more productive and fruitful. Emerging \\nproducts already enable a teacher to record her classroom and allow an AI algorithm to \\nsuggest highlights of the classroom discussion worth reviewing with a professional \\ndevelopment coach.37 AI can compute metrics, such as whether students have been \\ntalking more or less, which are difficult for a teacher to calculate during a lesson.38 For \\n \\n37 Chen, G., Clarke, S., & Resnick, L.B. (2015). Classroom Discourse Analyzer (CDA): A discourse analytic tool for teachers.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 31, 'page_label': '32', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"37 Chen, G., Clarke, S., & Resnick, L.B. (2015). Classroom Discourse Analyzer (CDA): A discourse analytic tool for teachers. \\nTechnology, Instruction, Cognition and Learning, 10(2), 85-105 \\n38 Jensen, E., Dale, M., Donnelly, P.J., Stone, C., Kelly, S., Godley, A. & D'Mello, S.K. (2020). Toward automated feedback on \\nteacher discourse to enhance teacher learning. In Proceedings of the 2020 CHI Conference on Human Factors in \\nComputing Systems (CHI '20). https://doi.org/10.1145/3313831.3376418\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 32, 'page_label': '33', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='29 \\nteachers who want to increase student engagement, these metrics can be a valuable tool. \\nClassroom simulation tools are also emerging and can enable teachers to practice their \\nskills in realistic situations.39 Simulators can include examples of teaching from a real \\nclassroom while changing the faces and voices of the participants so that teaching \\nsituations can be shared and discussed among teachers without revealing identities.  \\nNote the emphasis above on what listening-session panelist Sarah Hampton said about the \\nhuman touch. Teachers will feel that AI is helping them teach with a focus on their human \\nconnection to their students when the necessary (but less meaningful) burdens of teaching are \\nlessened. In Figure 7, below, see concerns that teachers raised about AI during listening sessions. \\nFigure 7: Concerns raised during the listening session about teaching with AI \\n \\nPreparing and Supporting Teachers in Planning and Reflecting'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 32, 'page_label': '33', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Figure 7: Concerns raised during the listening session about teaching with AI \\n \\nPreparing and Supporting Teachers in Planning and Reflecting \\nACE also means preparing teachers to take advantage of possibilities like those listed above and \\nmore. In the Research section, we highlight how pre-service education still tends to \\ncompartmentalize and inadequately address the topic of technology. That section suggests a \\nneed to invest in research about how to deeply integrate technology in pre-service teacher \\ntraining programs. In-service teachers, too, will need professional development to take \\nadvantage of opportunities that AI can provide, like those presented in the Teaching section. \\nProfessional development will need to be balanced not only to discuss opportunities but also to \\ninform teachers of new risks, while providing them with tools to avoid the pitfalls of AI.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 32, 'page_label': '33', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Professional development will need to be balanced not only to discuss opportunities but also to \\ninform teachers of new risks, while providing them with tools to avoid the pitfalls of AI.  \\n \\n39 Ersozlu, Z., Ledger, S., Ersozlu, A., Mayne, F., & Wildy, H. (2021). Mixed-reality learning environments in teacher \\neducation: An analysis of TeachLivETM Research. SAGE Open, 11(3). https://doi.org/10.1177/21582440211032155.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 33, 'page_label': '34', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='30 \\n“Humans are well suited to discern the outcomes…because we are the \\nones that have the capacity for moral reflection and empathy. So, in other \\nwords, I want the AI to help me really quickly and easily see what my \\nstudent needs in their learning journey.”  \\n—Sarah Hampton \\nBy nature, teaching requires significant time in planning as well to account for the breadth of \\nneeds across their rosters—especially for inclusive learning environments and students with IEPs \\nand 504 plans. AI could help teachers with recommendations that are tuned to their situation and \\ntheir ways of practicing teaching and support with adapting found materials to fit their exact \\nclassroom needs. For students with an IEP, AI could help with finding components to add to \\nlesson plans to fully address standards and expectations and to meet each student’s unique \\nrequirements. Even beyond finding components, AI might help adapt standardized resources to'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 33, 'page_label': '34', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='lesson plans to fully address standards and expectations and to meet each student’s unique \\nrequirements. Even beyond finding components, AI might help adapt standardized resources to \\nbetter fit specific needs—for example, providing a voice assistant that allows a student with a \\nvisual difficulty to hear material and respond to it or permitting a group of students to present \\ntheir project using American Sign Language (ASL) which could be audibly voiced for other \\nstudents using an AI ASL-to-Spoken-English translation capability. Indeed, coordinating IEPs is \\ntime-consuming work that might benefit from supportive automation and customized \\ninteractivity that can be provided by AI. \\nReflection is important too. In the bustle of a classroom, it is sometimes difficult to fully \\nunderstand what a student is expressing or what situations lead to certain positive or negative \\nbehaviors. Again, context is paramount. In the moment, teachers may not be aware of external'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 33, 'page_label': '34', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='understand what a student is expressing or what situations lead to certain positive or negative \\nbehaviors. Again, context is paramount. In the moment, teachers may not be aware of external \\nevents that could shape their understanding of how students are showing up in their classrooms. \\nTools that notice patterns and suggest ways to share information might help students and \\nteachers communicate more fully about strengths and needs. \\nDesigning, Selecting, and Evaluating AI Tools \\nThe broadest loop teachers should be part of is the loop that determines what classroom tools do \\nand which tools are available. Today, teachers already play a role in designing and selecting \\ntechnologies. Teachers can weigh in on usability and feasibility. Teachers examine evidence of \\nefficacy and share their findings with other school leaders. Teachers already share insights on \\nwhat is needed to implement technology well.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 33, 'page_label': '34', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='efficacy and share their findings with other school leaders. Teachers already share insights on \\nwhat is needed to implement technology well.  \\nWhile these concerns will continue, AI will raise new concerns too. For example, the following \\nFormative Assessment section raises concerns about bias and fairness that can lead to algorithmic \\ndiscrimination. Those concerns go beyond data privacy and security; they raise attention to how \\ntechnologies may unfairly direct or limit some students’ opportunities to learn. A key takeaway \\nhere is that teachers will need time and support so they can stay abreast of both the well-known \\nand the newer issues that are arising and so they can fully participate in design, selection, and \\nevaluation processes that mitigate risks. \\nChallenge: Balancing Human and Computer Decision-Making \\nOne major new challenge with AI-enabled tools for teachers is that AI can enable autonomous'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 33, 'page_label': '34', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='evaluation processes that mitigate risks. \\nChallenge: Balancing Human and Computer Decision-Making \\nOne major new challenge with AI-enabled tools for teachers is that AI can enable autonomous \\nactivity by a computer, and thus when a teacher delegates work to an AI-enabled tool, it may'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 34, 'page_label': '35', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='31 \\ncarry on with that work somewhat independently. Professor Inge Molenaar40 has wondered \\nabout the challenges of control in a hybrid teaching scenario: When should a teacher be in \\ncontrol? What can be delegated to a computational system? How can a teacher monitor the AI \\nsystem and override its decisions or take back control as necessary? \\nFigure 8: The tension between human and AI decision making: Who is in control? \\n \\nFigure 8 expresses the tension around control. To the left, the teacher is fully in control, and \\nthere is no use of AI in the classroom. To the right, the technology is fully in control with no \\nteacher involved—a scenario which is rarely desirable. The middle ground is not one \\ndimensional and involves many choices. Molenaar analyzed products and suggests some \\npossibilities: \\n● The technology only offers information and recommendations to the teacher. \\n● The teacher delegates specific types of tasks to the technology, for example, giving'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 34, 'page_label': '35', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='possibilities: \\n● The technology only offers information and recommendations to the teacher. \\n● The teacher delegates specific types of tasks to the technology, for example, giving \\nfeedback on a particular math assignment or sending out reminders to students before an \\nassignment is due. \\n● The teacher delegates more broadly to the technology, with clear protocols for alerts, for \\nmonitoring, and for when the teacher takes back control. \\nThese and other choices need to be debated openly. For example, we may want to define \\ninstructional decisions that have different kinds of consequences for a student and be very \\ncareful about delegating control over highly consequential decisions (for example, placement in \\na next course of study or disciplinary referrals). For human in the loop to become more fully \\nrealized, AI technologies must allow teacher monitoring, have protocols to signal a teacher when'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 34, 'page_label': '35', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='a next course of study or disciplinary referrals). For human in the loop to become more fully \\nrealized, AI technologies must allow teacher monitoring, have protocols to signal a teacher when \\ntheir judgment is needed, and allow for classroom, school, or district overrides when they \\ndisagree with an instructional choice for their students. We cannot forget that if a technology \\nallows a teacher choice—which it should—it will take significant time for a teacher to think \\nthrough and set up all the options, requiring greater time initially.  \\nChallenge: Making Teaching Jobs Easier While Avoiding Surveillance \\nWe also recognize that the very technologies that make jobs easier might also introduce new \\npossibilities for surveillance (Figure 9). In a familiar example, when we enable a voice assistant in \\nthe kitchen, it might help us with simple household tasks like setting a cooking timer. And yet the'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 34, 'page_label': '35', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='the kitchen, it might help us with simple household tasks like setting a cooking timer. And yet the \\nsame voice assistant might hear things that we intended to be private. This kind of dilemma will \\n \\n40 Molenaar, I. (2022). Towards hybrid human-AI learning technologies. European Journal of Education, 00, 1–14. \\nhttps://doi.org/10.1111/ejed.12527'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 35, 'page_label': '36', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='32 \\noccur in classrooms and for teachers. When they enable an AI-assistant to capture data about \\nwhat they say, what teaching resources they search for, or other behaviors, the data could be \\nused to personalize resources and recommendations for the teacher. Yet the same data might \\nalso be used to monitor the teacher, and that monitoring might have consequences for the \\nteacher. Achieving trustworthy AI that makes teachers’ jobs better will be nearly impossible if \\nteachers experience increased surveillance. \\nA related tension is that asking teachers to be “in the loop” could create more work for teachers if \\nnot done well, and thus, being in the loop might be in tension with making teaching jobs easier. \\nAlso related is the tension between not trusting AI enough (to obtain assistance) or trusting it too \\nmuch (and incurring surveillance or loss of privacy). For example, researchers have documented'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 35, 'page_label': '36', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Also related is the tension between not trusting AI enough (to obtain assistance) or trusting it too \\nmuch (and incurring surveillance or loss of privacy). For example, researchers have documented \\nthat people will follow instructions from a robot during a simulated fire emergency even when \\n(a) they are told the robot is broken and (b) the advice is obviously wrong.41 We anticipate \\nteachers will need training and support to understand how and when they will need to exercise \\nhuman judgement. \\nFigure 9: Highly customized assistance vs. increased teacher surveillance \\n \\nChallenge: Responding to Students’ Strengths While Protecting Their \\nPrivacy \\nEducators seek to tackle inequities in learning, no matter how they manifest locally (e.g. in access \\nto educational opportunities, resources, or supports). In culturally responsive42 and culturally \\nsustaining43 approaches, educators design materials to build on the “assets”—individual,'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 35, 'page_label': '36', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='to educational opportunities, resources, or supports). In culturally responsive42 and culturally \\nsustaining43 approaches, educators design materials to build on the “assets”—individual, \\ncommunity, and cultural strengths that students bring to learning. Along with considering assets, \\nof course, educators must meet students where they are, including both strengths and needs. AI \\ncould assist in this process by helping teachers with customizing curricular resources, for \\nexample. But to do so, the data inputted in an AI-enabled system would have to provide more \\ninformation about the students. This information could be, but need not be, demographic \\ndetails. It could also be information about students’ preferences, outside interests, relationships, \\n \\n41 Wagner, A.R., Borenstein, J. & Howard, A. (September 2018). Overtrust in the robotics age. Communications of the ACM, \\n61(9),22-24. https://doi.org/10.1145/3241365'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 35, 'page_label': '36', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='41 Wagner, A.R., Borenstein, J. & Howard, A. (September 2018). Overtrust in the robotics age. Communications of the ACM, \\n61(9),22-24. https://doi.org/10.1145/3241365 \\n42 Gay, G. (2018). Culturally responsive teaching: Theory, research, and practice. Teachers College Press. ISBN: 978-0807758762 \\n43 Paris, D., & Alim, H.S. (Eds.). (2017). Culturally sustaining pedagogies: Teaching and learning for justice in a changing \\nworld. Teachers College Press. ISBN: 978-0807758342'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 36, 'page_label': '37', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='33 \\nor experiences.44 What happens to this data, how it is deleted, and who sees it is of huge concern \\nto educators. As educators contemplate using AI-enabled technologies to assist in tackling \\neducational inequities, they must consider whether the information about students shared with \\nor stored in an AI-enabled system is subject to federal or state privacy laws, such as FERPA. \\nFurther, educators must consider whether interactions between students and AI systems create \\nrecords that must be protected by law, such as when a chatbot or automated tutor generates \\nconversational or written guidance to a student. Decisions made by AI technologies, along with \\nexplanations of those decisions that are generated by algorithms may also be records that must \\nbe protected by law. Therein, a third tension emerges, between more fully representing students \\nand protecting their privacy (Figure 10). \\nFigure 10: Responding to students’ strengths while fully protecting student privacy'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 36, 'page_label': '37', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='and protecting their privacy (Figure 10). \\nFigure 10: Responding to students’ strengths while fully protecting student privacy \\nFurther, representation would be just a start toward a solution. As discussed earlier in this report, \\nAI can introduce algorithmic discrimination through bias in the data, code, or models within AI-\\nenhanced edtech. Engineers develop the pattern detection in AI models using existing data, and \\nthe data they use may not be representative or may contain associations that run counter to \\npolicy goals. Further, engineers shape the automations that AI implements when it recognizes \\npatterns, and the automations may not meet the needs of each student group with a diverse \\npopulation. The developers of AI are typically less diverse than the populations they serve, and \\nas a consequence, they may not anticipate the ways in which pattern detection and automation \\nmay harm a community, group, or individual.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 36, 'page_label': '37', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='as a consequence, they may not anticipate the ways in which pattern detection and automation \\nmay harm a community, group, or individual. \\nAI could help teachers to customize and personalize materials for their students, leveraging the \\nteacher’s understanding of student needs and strengths. It is time consuming to customize \\ncurricular resources, and teachers are already exploring how AI chatbots can help them design \\nadditional resources for their students. An elementary school teacher could gain powerful \\nsupports for changing the visuals in a storybook to engage their students or for adapting \\nlanguage that poorly fits local manners of speaking or even for modifying plots to incorporate \\nother dimensions of a teacher’s lesson. In the Learning section, we noted that AI could help \\nidentify learner strengths. For example, a mathematics teacher may not be aware of ways in \\nwhich a student is making great sense of graphs and tables about motions when they are in'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 36, 'page_label': '37', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='identify learner strengths. For example, a mathematics teacher may not be aware of ways in \\nwhich a student is making great sense of graphs and tables about motions when they are in \\nanother teacher’s physics classroom and might not realize that using similar graphs about \\n \\n44 Zacamy, J. & Roschelle, J. (2022). Navigating the tensions: How could equity-relevant research also be agile, open, and \\nscalable? Digital Promise. http://hdl.handle.net/20.500.12265/159; Baker, R.S., Esbenshade, L., Vitale, J., & Karumbaiah, S. \\n(2022). Using demographic data as predictor variables: A questionable choice. https://doi.org/10.35542/osf.io/y4wvj'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 37, 'page_label': '38', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='34 \\nmotion could help with their linear function lesson. AI might help teachers when they seek to \\nreflect student strengths by creating or adapting instructional resources. \\nYet, the broad equity challenges of avoiding algorithmic discrimination while increasing \\ncommunity and cultural responsiveness must be approached within the four foundations we \\nearlier outlined: human in the loop, equity, safety and effectiveness, and evaluation of AI models. \\nWe cannot expect AI models to respect cultural responsiveness. The Department is particularly \\nconcerned that equity is something that engaged educators and other responsive adults are in the \\nbest position to address and something that is never solely addressable as a computational \\nproblem. \\nQuestions Worth Asking About AI for Teaching \\nAs leaders in both pre-service and post-service teacher education contemplate how AI can \\nimprove teaching (along with policymakers, developers, and researchers), we urge all in the'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 37, 'page_label': '38', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='As leaders in both pre-service and post-service teacher education contemplate how AI can \\nimprove teaching (along with policymakers, developers, and researchers), we urge all in the \\necosystem to spend more time asking these questions: \\n• Is AI improving the quality of an educator’s day-to-day work? Are teachers experiencing \\nless burden and more ability to focus and effectively teach their students? \\n• As AI reduces one type of teaching burden, are we preventing new responsibilities or \\nadditional workloads being shifted and assigned to teachers in a manner that negates the \\npotential benefits of AI? \\n• Is classroom AI use providing teachers with more detailed insights into their students and \\ntheir strengths while protecting their privacy?  \\n• Do teachers have oversight of AI systems used with their learners? Are they exercising \\ncontrol in the use of AI-enabled tools and systems appropriately or inappropriately \\nyielding decision-making to these systems and tools?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 37, 'page_label': '38', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='control in the use of AI-enabled tools and systems appropriately or inappropriately \\nyielding decision-making to these systems and tools? \\n• When AI systems are being used to support teachers or to enhance instruction, are the \\nprotections against surveillance adequate? \\n• To what extent are teachers able to exercise voice and decision-making to improve \\nequity, reduce bias, and increase cultural responsiveness in the use of AI-enabled tools \\nand systems? \\nKey Recommendation: Inspectable, Explainable, Overridable AI \\nIn the Introduction, we discuss the notion that when AI is incorporated into a system, the core of \\nthe AI is a model. In the Learning section, we discuss that we need to be careful that models align \\nto the learning we envision (e.g., that they aren’t too narrow). Now, based on the needs of \\nteachers (as well as students and their families/caregivers), we add another layer to our criteria'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 37, 'page_label': '38', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='to the learning we envision (e.g., that they aren’t too narrow). Now, based on the needs of \\nteachers (as well as students and their families/caregivers), we add another layer to our criteria \\nfor good AI models: the need for explainability.45 Some AI models can recognize patterns in the \\nworld and do the right action, but they cannot explain why (e.g., how they arrived at the \\n \\n45 Khosravi, H., Shum, S.B., Chen, G, Conati, C., Tsai,Y-S., Kay, J., Knight, S., Martinez-Maldonado, R., Sadiq, S., Gašević, D. \\n(2022). Explainable artificial intelligence in education. Computers and Education: Artificial Intelligence, 3. \\nhttps://doi.org/10.1016/j.caeai.2022.100074'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 38, 'page_label': '39', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='35 \\nconnection between the pattern and the action). This lack of explainability will not suffice for \\nteaching; teachers will need to know how an AI model analyzed the work of one of their students \\nand why the AI model recommended a particular tutorial, resource, or next step to the student.  \\nThus, explainability of an AI system’s decision is key to a teacher’s ability to judge that \\nautomated decision. Such explainability helps teachers to develop appropriate levels of trust and \\ndistrust in AI, particularly to know where the AI model tends to make poor decisions. \\nExplainability is also key to a teacher’s ability to monitor when an AI system may be unfairly \\nacting on the wrong information (and thus may be biased. We discuss bias and fairness more in \\nthe Assessment section next). \\nSurrounding the idea of explainability is the need for teachers to be able to inspect what an AI \\nmodel is doing. For example, what kinds of instructional recommendations are being made and'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 38, 'page_label': '39', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Surrounding the idea of explainability is the need for teachers to be able to inspect what an AI \\nmodel is doing. For example, what kinds of instructional recommendations are being made and \\nto which students? Which students are being assigned remedial work in a never ended loop? \\nWhich are making progress? Dashboards in current products present some of this information, \\nbut with AI, teachers may want to further explore which decisions are being made and for whom \\nand know of the student-specific factors that an AI model had available (and possibly which \\nfactors were influential) when reaching a particular decision. For example, some of today’s \\nadaptive classroom products use limited recommendation models that only consider student \\nsuccess on the last three mathematics problems and do not consider other variables that a \\nteacher would know to consider, such as whether a student has an IEP Plan or other needs.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 38, 'page_label': '39', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='success on the last three mathematics problems and do not consider other variables that a \\nteacher would know to consider, such as whether a student has an IEP Plan or other needs. \\nOur call for attending to equity considerations as we evaluate AI models requires information \\nabout how discriminatory bias may arise in particular AI systems and what developers have done \\nto address it. This can only be achieved with transparency for how the tools use datasets to \\nachieve outcomes and what data they have available or that a teacher could include in her \\njudgement but are not available to the system (IEP status is offered as an example above).  \\nTeachers will also need the ability to view and make their own judgement about automated \\ndecisions, such as decisions about which set of mathematics problems a student should work on \\nnext. They need to be able to intervene and override decisions when they disagree with the logic'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 38, 'page_label': '39', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='decisions, such as decisions about which set of mathematics problems a student should work on \\nnext. They need to be able to intervene and override decisions when they disagree with the logic \\nbehind an instructional recommendation.46 Teachers need protection against adverse \\nramifications when they assert human judgement over an AI system’s decision. \\n \\n46 Ruiz, P. & Fusco, J. (2022). Teachers partnering with artificial intelligence: Augmentation and automation. Digital Promise. \\nhttps://digitalpromise.org/2022/07/06/teachers-partnering-with-artificial-intelligence-augmentation-and-automation/'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 39, 'page_label': '40', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='36 \\n“These systems sometimes are seen as a black box kind of a situation \\nwhere predictions are made based on lots of data. But what we need is to \\nhave a clear view—to clearly show how those recommendations or those \\ninteractions are made and what evidence is used or what data is used to \\nbe able to make those recommendations so teachers and everyone \\ninvolved know about why that kind of system is providing that type of \\ninformation. So, having open learning environments or inspectable \\nlearner models or applications where the stakeholders can understand \\nhow these systems make decisions or recommendations is going to be an \\nimportant aspect in the future of teaching and learning.”  \\n—Diego Zapata-Rivera'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 40, 'page_label': '41', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='37 \\nFormative Assessment \\nFormative assessment is traditionally a key use of edtech because feedback loops are vital to \\nimproving teaching and learning.47 As we have emphasized throughout this report, a top priority \\nwith AI is to keep humans in the loop and in control, which includes focusing on the people \\nengaged with formative assessments: students, teachers, school leaders, families/caregivers, and \\nothers who support learners. In the definition below, please note the overlap between definitions \\nof AI and formative assessment; both have to do with detecting patterns and choosing a future \\ncourse of action (that adapts to learner strengths and needs). \\nAssessment refers to all those activities undertaken by teachers, and by \\nthe students in assessing themselves, which provide information to be \\nused as feedback to modify the teaching and learning activities in which \\nthey are engaged. Such assessment becomes “formative assessment”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 40, 'page_label': '41', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='used as feedback to modify the teaching and learning activities in which \\nthey are engaged. Such assessment becomes “formative assessment” \\nwhen the evidence is actually used to adapt the teaching to meet the \\nneeds.48 \\nBuilding on Best Practices \\nA number of dimensions hold potential for shaping the future of formative assessments, and \\nmany have ready extensions to the field of AI-enabled systems and tools. For example, the 2017 \\nNETP discussed how technology can lead to improved formative assessments along seven \\ndimensions, listed below: \\n1. Enabling Enhanced Question Types: \\nto give students more ways to show what they know and can do. \\n2. Measurement of Complex Competencies:  \\nto better elicit growth in important skills that go beyond typical subject matter standards, \\nfor example, in measuring practices, social skills like teamwork, self-regulation, and \\nwork-relevant skills (e.g., making presentations or leading teams). \\n3. Providing Real-Time Feedback:'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 40, 'page_label': '41', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='for example, in measuring practices, social skills like teamwork, self-regulation, and \\nwork-relevant skills (e.g., making presentations or leading teams). \\n3. Providing Real-Time Feedback:  \\nto maintain and increase student engagement and to support effective learning, \\nproviding timely and helpful responses and suggestions to each learner. \\n4. Increasing Accessibility:  \\nto include neurodiverse learners and to engage learners’ best communication capabilities \\nas they share what they know and can do. \\n \\n47 Shute, V.J. (2008). Focus on formative feedback. Review of Educational Research, 78(1), 153–189. \\nhttps://doi.org/10.3102/0034654307313795 \\n48 Black, P. & Wiliam, D. (1998). Inside the black box: Raising standards through classroom assessment. Phi Delta Kappan, \\n92(1), 81-90. https://kappanonline.org/inside-the-black-box-raising-standards-through-classroom-assessment/'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 41, 'page_label': '42', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='38 \\n5. Adapting to Learner Ability and Knowledge:  \\nto make assessments more precise and efficient. \\n6. Embedded Assessment in the Learning Process:  \\nto emphasize an assessment’s role in improving teaching and learning (this report does \\nnot focus on assessment for accountability purposes). \\n7. Assess for Ongoing Learning: \\nto reveal progress over time and not just predetermined milestones. \\nAI models and AI-enabled systems may have potential to strengthen formative assessments. In \\none example, a question type that invites students to draw a graph or create a model can be \\nanalyzed with AI algorithms,49 and similar student models might be grouped for the teacher to \\ninterpret. Enhanced formative assessment may enable teachers to better respond to students’ \\nunderstanding of a concept like “rate of change” in a complex, real-world situation. AI can also \\ngive learners feedback on complex skills, such as learning American Sign Language50 or speaking'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 41, 'page_label': '42', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='understanding of a concept like “rate of change” in a complex, real-world situation. AI can also \\ngive learners feedback on complex skills, such as learning American Sign Language50 or speaking \\na foreign language51 and in other practice situations where no person is available to provide \\nimmediate feedback. \\nGenerally, an AI assistant may be able to reduce the load for teachers related to grading simpler \\naspects of student responses, allowing the teacher to focus their specialized judgment on \\nimportant qualities of a whole essay or a complex project. We also may be able to better provide \\nfeedback with accessibility. For example, an AI-enabled learning technology may be able to \\ninteract verbally with a student about their response to an essay prompt, asking questions that \\nguide the student to clarify their argument without requiring the student to read a screen or type \\nat a keyboard. In the examples shared earlier in the Learning section, we also see that AI can be'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 41, 'page_label': '42', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='guide the student to clarify their argument without requiring the student to read a screen or type \\nat a keyboard. In the examples shared earlier in the Learning section, we also see that AI can be \\nembedded in the learning process, providing feedback to students as they work to solve a \\nproblem, rather than only later after the student has reached a wrong answer. When formative \\nassessment is more embedded, it can better support learning, and timely feedback is critical.52  \\nAlthough there are many points of connection like these between AI and formative assessments, \\nour listening sessions also revealed attendees’ desire to tackle some existing shortcomings in the \\nfield of formative assessment; namely, the time-consuming and sometime onerous nature of \\ntaking tests, quizzes, or other assessments and the lack of perceived value in the feedback loop by \\nteachers and students.  \\nImplications for Teaching and Learning'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 41, 'page_label': '42', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='taking tests, quizzes, or other assessments and the lack of perceived value in the feedback loop by \\nteachers and students.  \\nImplications for Teaching and Learning  \\nReal-time instructional feedback can be beneficial when it helps learners and teachers to \\nimprove. But common experience too often leaves students and teachers with unpleasant \\nfeelings toward assessment and thus poses a provocative conflict between the potential benefits \\n \\n49 Zhai, X., He, P., Krajcik, J. (2022). Applying machine learning to automatically assess scientific models. Journal of Research \\nin Science Teaching. https://doi.org/10.1002/tea.21773 \\n50 Shao, Q., Sniffen, A., Blanchet, J., Hillis, M.E., Shi, X., Haris, T.K., & Balkcom, D. (2020). Teaching american sign language \\nin mixed reality. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 4(4), 1-27. \\nhttps://doi.org/10.1145/3432211'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 41, 'page_label': '42', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='in mixed reality. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 4(4), 1-27. \\nhttps://doi.org/10.1145/3432211 \\n51 Godwin-Jones, R. (2021). Big data and language learning: Opportunities and challenges. \\u2028Language Learning & Technology, \\n25(1), 4–19. http://hdl.handle.net/10125/44747 \\n52 Wiggins, G. (2015). Seven keys to effective feedback. ACSD. https://www.ascd.org/el/articles/seven-keys-to-effective-\\nfeedback'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 42, 'page_label': '43', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='39 \\nof data collected through formative assessments and the practical implications of administering \\nadditional assessments in classrooms and schools. \\nSome AI-enabled systems and tools seek to address this potential conflict. For example, one AI-\\nenabled reading tutor listens to students as they read aloud and provides on-the-spot feedback to \\nimprove their reading.53 Students reportedly enjoyed reading aloud, and the approach was \\neffective. Researchers have also embedded formative assessments in games so that students can \\nshow how well they understand Newtonian physics as they play increasingly difficult levels of a \\ngame.54 If a student can more easily ask for and receive help when they feel frustrated or \\nconfused, reducing those feelings can feel encouraging. Student feelings of safety, confidence, \\nand trust in the feedback generated by these AI-enabled systems and tools are essential to'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 42, 'page_label': '43', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='confused, reducing those feelings can feel encouraging. Student feelings of safety, confidence, \\nand trust in the feedback generated by these AI-enabled systems and tools are essential to \\nshowcase their learning. That focus on learning growth and gains is optimal (absent negative \\nconsequences or a high-stakes environment).55 \\nAI-enhanced formative assessments may have the potential to save teachers’ time (e.g., time \\nspent on grading), allowing the instructor to spend more time engaged in helping students. AI-\\nenhanced assessments may also benefit teachers if they provide detailed insights about student \\nstrengths or needs that may not be visible and if they support instructional adaptation or \\nimprovement by suggesting a small set of evidence-based recommendations for helping students \\nmaster content. Such assessments may also be helpful outside of the classroom if it can provide \\nfeedback when the teacher is not available, for example, in completing homework or practicing a'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 42, 'page_label': '43', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='master content. Such assessments may also be helpful outside of the classroom if it can provide \\nfeedback when the teacher is not available, for example, in completing homework or practicing a \\nconcept during study hall. As we discussed in the Teaching section, an essential aspect of \\ndeploying AI-based formative assessment must be centering teachers in system design. \\nInsight: AI Can Enhance Feedback Loops \\nThe term “formative assessment” does not singularly mean a test or a measurement. Assessment \\nbecomes formative when it results in useful reflections and changes to the course of teaching, \\nlearning, or both.56 The term “feedback loops” emphasizes that measurement is only part of the \\nprocess. Feedback loops that lead to instructional improvement—including adaptations in \\nteaching and learning—yield the strongest outcomes for students.  \\nWe also use “feedback loops” as a plural term because there are many types and levels of loops'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 42, 'page_label': '43', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='teaching and learning—yield the strongest outcomes for students.  \\nWe also use “feedback loops” as a plural term because there are many types and levels of loops \\nthat are important. Students can benefit from feedback when they work individually, as a \\nmember of a small group, or in a classroom discussion. Feedback loops are valuable “in the \\nmoment”—for example, as a student practices a skill. Further, feedback loops are valuable when \\nthey cover larger spans of effort and reflections, such as at the end of presenting a project or \\nterm paper. In addition, feedback loops can assist teachers, for example, helping them notice \\n \\n53 Mostow, J., Aist, G., Burkhead, P., Corbett, A., Cuneo, A., Eitelman, S., Huang, C., Junker, B., Sklar, M.B., & Tobin, B. \\n(2003). Evaluation of an automated reading tutor that listens: Comparison to human tutoring and classroom instruction. \\nJournal of Educational Computing Research, 29(1), 61–117. https://doi.org/10.2190/06AX-QW99-EQ5G-RDCF'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 42, 'page_label': '43', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"Journal of Educational Computing Research, 29(1), 61–117. https://doi.org/10.2190/06AX-QW99-EQ5G-RDCF \\n54 Shute, V.J., Ventura, M., & Kim, Y.J. (2013). Assessment and learning of qualitative physics in Newton's Playground. The \\nJournal of Educational Research, 106(6), 423–430. https://doi.org/10.1080/00220671.2013.832970 \\n55 Shute, V J. (2008). Focus on formative feedback. Review of Educational Research, 78(1), 153–189. \\nhttps://doi.org/10.3102/0034654307313795 \\n56 Black, P., & Wiliam, D. (2009). Developing the theory of formative assessment. Educational Assessment, Evaluation and \\nAccountability, 21(1), 5-31. https://doi.org/10.1007/s11092-008-9068-5\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 43, 'page_label': '44', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='40 \\ntheir own patterns of responding to students’ ideas. Moreover, feedback loops are critical to the \\ncontinuous improvement of products and the implementation of programs.  \\nDue to the importance of feedback loops, formative assessment could be a leading area for \\nschools’ explorations of powerful uses of AI in teaching and learning. Educators can build upon \\nalignments between their long-standing visions for formative assessment and the emerging \\ncapabilities that AI holds. Further, the professional assessment community brings a toolkit for \\nasking and answering questions about topics like bias and fairness. The psychometric toolkit of \\nmethods is a strong start toward the questions that must be asked and answered because it \\nalready contains ways to measure bias and fairness and, more generally, to benchmark the \\nquality of formative assessments. But as our discussion reveals, AI can only make feedback loops'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 43, 'page_label': '44', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='already contains ways to measure bias and fairness and, more generally, to benchmark the \\nquality of formative assessments. But as our discussion reveals, AI can only make feedback loops \\nbetter if we keep a firm eye on the weaknesses of AI and how AI introduces new concerns. \\nAn Example: Automated Essay Scoring \\nOne instructive example is Automated Essay Scoring (AES). To become strong writers, which is a \\nvaluable life skill, students need regular and specific feedback. However, reviewing and \\nproviding feedback on essays is very time consuming for humans. Hence, Ellis Page provided a \\nfirst vision for computer programs that could review and provide feedback on student essays in 196657, \\nand much effort has gone into AES technologies in the intervening 56 years. Many research \\nreview articles are available to summarize the progress, which has been impressive.58 Further, \\nsome of today’s applications of AES technologies will be familiar to readers, such as Grammarly,'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 43, 'page_label': '44', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='review articles are available to summarize the progress, which has been impressive.58 Further, \\nsome of today’s applications of AES technologies will be familiar to readers, such as Grammarly, \\nTurnitin, and the various essay analysis engines used by publishers and assessment companies. \\nAlso note that while the traditional AES functionality emphasizes scoring or rating essays, newer \\nAI-enabled products focus more on providing students with constructive criticism and \\ndeveloping their skills as writers. Writing is a life skill that is important to the pursuit of college \\nand career ambitions, and developing writers require comprehensive feedback. If developers \\ncould inexpensively augment human feedback to developing writers with AI feedback, it’s \\npossible that support for learning to write could become more equitable. \\nAnd yet, AES is an instructive example because researchers have analyzed limitations, too.59 AES'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 43, 'page_label': '44', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='possible that support for learning to write could become more equitable. \\nAnd yet, AES is an instructive example because researchers have analyzed limitations, too.59 AES \\ntechnologies in AI can analyze some features of student essays but can also be misled by the \\nlength of an essay, by a student who places appropriate keywords in sentences that don’t make \\nsense, and other flaws that a human reader would easily notice. In a telling quote, one team that \\nreviewed the state of the art wrote this: \\nThe authors further note that while human and AI judgements of essays may correlate, people \\nand computers are not noticing the same things in student writing. Due to these limitations, we \\nmust continue to emphasize a human in the loop foundation for AI-enhanced formative \\nassessment. AI may support but not replace high-quality, human-led processes and practices of \\nformative assessment in schools.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 43, 'page_label': '44', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='assessment. AI may support but not replace high-quality, human-led processes and practices of \\nformative assessment in schools. \\n \\n57 Page, E.B. (1966). The imminence of grading essays by computer. Phi Delta Kappan, 47(5), 238–243 \\n58 Ke, Z., & Ng, V. (2019). Automated essay scoring: A survey of the state of the art. In Proceedings of the Twenty-Eighth \\nInternational Joint Conference on Artificial Intelligence, 6300–6308. https://doi.org/10.24963/ijcai.2019/879 \\n59 Doewes, A. & Pechenizkiy, M. (2021). On the limitations of human-computer agreement in automated essay scoring. In \\nProceedings of the 14th International Conference on Educational Data Mining (EDM21). \\nhttps://educationaldatamining.org/EDM2021/virtual/static/pdf/EDM21_paper_243.pdf'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 44, 'page_label': '45', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='41 \\n \\n“Nevertheless, the time when AES systems will be able to operate on a \\npar with human judges, with similar levels of connoisseurship for such \\nfeatures as meaning, emotion, originality, creativity, fluency, sense of \\naudience and so on, arguably remains a long way off.” \\n—Gardner, O’Leary, and Yuan60  \\nKey Opportunities for AI in Formative Assessment \\nBased on the listening sessions we held, we see three key areas of opportunity in supporting \\nformative assessment using AI systems and models.  \\nFirst, we recommend a strong focus on measuring what matters61 and particularly those things \\nthat have not been easily measured before and that many constituents would like to include in \\nfeedback loops. The example above, AES, was chosen because writing remains a valuable \\nacademic, workplace, and life skill. Looking at community goals through the lens of their visions \\nfor their high school graduates, we see that families/caregivers, students, and community leaders'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 44, 'page_label': '45', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='academic, workplace, and life skill. Looking at community goals through the lens of their visions \\nfor their high school graduates, we see that families/caregivers, students, and community leaders \\nwant to nurture graduates who solve problems adaptively, who communicate and collaborate \\nwell, who persevere and self-regulate when they experience challenges. “What matters” today \\nreaches beyond a sole focus on the core academic content measured by large-scale summative \\nassessments, to support students and teachers with actionable feedback that nurtures the broader \\nskills students need to succeed and thrive. Further, within core academic content, AI may help us \\nto provide feedback on the more realistic and complex aspects of doing math, for example, or \\ninvestigating scientific phenomena, understanding history, or discussing literature.  \\nSecond, we’d like to see a strong focus on improving help-seeking and help-giving.62 Asking for'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 44, 'page_label': '45', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='investigating scientific phenomena, understanding history, or discussing literature.  \\nSecond, we’d like to see a strong focus on improving help-seeking and help-giving.62 Asking for \\nand giving help is crucial to learning63 and practicing a growth-mindset and central to the notion \\nof human feedback loops. Students may not always know when they need help. In one example, \\ncomputer algorithms can detect a student who is “wheel spinning” (working hard on mastering \\ncontent but not making progress).64 A student who is working hard may not feel like they need \\nhelp, and the teacher may not be aware that the student is struggling if he or she appears to be \\n“on task.” AI may also be helpful by highlighting for students and teachers what forms of \\nassistance have been most useful to the student in the recent past so that an educator can expand \\naccess to specific assistance that works for that individual student. Finally, educators may learn'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 44, 'page_label': '45', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='assistance have been most useful to the student in the recent past so that an educator can expand \\naccess to specific assistance that works for that individual student. Finally, educators may learn \\nthings from AI-enabled systems and tools that give feedback and hints during the completion of \\n \\n60 Gardner, J., O\\'Leary, M. & Yuan, L. (2021). Artificial intelligence in educational assessment: \"Breakthrough? Or \\nbuncombe and ballyhoo?\" Journal of Computer Assisted Learning, 37(5), 1207–1216. https://doi.org/10.1111/jcal.12577 \\n61 Merrill, S. (2020). In schools, are we measuring what matters? Edutopia. https://www.edutopia.org/article/schools-are-we-\\nmeasuring-what-matters \\n62 Roll, I., Aleven, V., McLaren, B.M., Koedinger, K.R. (2011). Improving students’ help-seeking skills using metacognitive \\nfeedback in an intelligent tutoring system, Learning and Instruction, 21(2), 267–280. \\nhttps://doi.org/10.1016/j.learninstruc.2010.07.004.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 44, 'page_label': '45', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='feedback in an intelligent tutoring system, Learning and Instruction, 21(2), 267–280. \\nhttps://doi.org/10.1016/j.learninstruc.2010.07.004. \\n63 Webb, N.M., & Farivar, S. (1994). Promoting helping behavior in cooperative small groups in middle school \\nmathematics. American Educational Research Journal, 31(2), 369–395. https://doi.org/10.3102/00028312031002369 \\n64 Kai, S., Almeda, M.V., Baker, R. S., Heffernan, C., & Heffernan, N. (2018). Decision tree modeling of wheel-spinning and \\nproductive persistence in skill builders. Journal of Educational Data Mining, 10(1), 36–71. \\nhttps://doi.org/10.5281/zenodo.3344810'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 45, 'page_label': '46', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='42 \\nhomework, utilizing that feedback to later reinforce concepts in direct instruction and \\nstrengthen the one-on-one support provided to students.65 AI-enabled systems and tools can \\nprovide teachers with additional information about the students’ recent work, so their instructor \\nhas a greater contextual sense as they begin to provide help. \\nThird, we advocate for teachers and students to be strongly involved in designing feedback \\nloops as developers produce AI-enhanced formative assessments so they can directly voice what \\nwould make assessments less onerous and more convenient and valuable to them.66 Earlier in the \\nTeaching section, we emphasized how important it is to involve teachers in designing, selecting, \\nand evaluating AI-enhanced technologies. Students need to be centered, too. They are \\nexperiencing AI in their everyday lives, and they have strong opinions on what is valuable and'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 45, 'page_label': '46', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='and evaluating AI-enhanced technologies. Students need to be centered, too. They are \\nexperiencing AI in their everyday lives, and they have strong opinions on what is valuable and \\nsafe. There are local and cultural variations in how people provide and receive feedback, so \\nadjusting feedback to align with community norms is important. \\nKey Recommendation: Harness Assessment Expertise to Reduce Bias \\nBias and fairness are important issues in assessment design and administration,67 and they hold \\nrelevance for the area of AI-enabled assessment. In traditional assessment, a test item might be \\nbiased if unnecessary details are included that differentially advantage some students (e.g., a \\nstory-based item that references a sport that only boys play regularly may be less helpful to \\ngirls). As discussed earlier, with AI, we now must worry about algorithmic discrimination which \\ncan arise due to the manner in which AI algorithms are developed and improved from large'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 45, 'page_label': '46', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='girls). As discussed earlier, with AI, we now must worry about algorithmic discrimination which \\ncan arise due to the manner in which AI algorithms are developed and improved from large \\ndatasets of parameters and values that may not represent all cohorts of learners. \\nAlgorithmic discrimination is not just about the measurement side of formative assessment; it is \\nalso about the feedback loop and the instructional interventions and supports that may be \\nundertaken in response to data collected by formative assessments. There is a question both \\nabout access to such interventions and the quality or appropriateness of such interventions or \\nsupports. When an algorithm suggests hints, next steps, or resources to a student, we have to \\ncheck whether the help-giving is unfair because one group systematically does not get useful \\nhelp which is discriminatory. Fairness goes beyond bias as well. In AI-enabled formative'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 45, 'page_label': '46', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='check whether the help-giving is unfair because one group systematically does not get useful \\nhelp which is discriminatory. Fairness goes beyond bias as well. In AI-enabled formative \\nassessment, both the opportunity to learn through feedback loops, as well as the quality of \\nlearning in and outside of such loops, should be addressed. Issues of bias and fairness have arisen \\nin traditional assessments, and the field of psychometrics has already developed valuable tools to \\nchallenge and address these issues.68 Assessment as a field may have a head start on tackling bias \\nand fairness for AI in education. And yet the issues expand with AI, so the work is not done. \\nStrong and deliberate attention to bias and fairness is needed as future formative assessments are \\ndeveloped. \\n \\n65 Walker, E., Rummel, N. & Koedinger, K.R. (2015). Adaptive intelligent support to improve peer tutoring in algebra.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 45, 'page_label': '46', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='developed. \\n \\n65 Walker, E., Rummel, N. & Koedinger, K.R. (2015). Adaptive intelligent support to improve peer tutoring in algebra. \\nInternational Journal of Artificial Intelligence in Education, 24, 33–61 https://doi.org/10.1007/s40593-013-0001-9 \\n66 Swiecki, Z., Khosravi, H., Chen, G., Martinez-Maldonado, R., Lodge, J.M., Milligan, S., Selwyn, B. & Gašević,D. (2022). \\nAssessment in the age of artificial intelligence. Computers and Education: Artificial Intelligence, 3. k \\nhttps://doi.org/10.1016/j.caeai.2022.100075 \\n67 Reynolds, C.R., & Suzuki, L.A. (2012). Bias in psychological assessment: An empirical review and recommendations. \\nHandbook of Psychology, Second Edition. https://doi.org/10.1002/9781118133880.hop210004 \\n68 Kaplan, R.M., & Saccuzzo, D.P. (2017). Psychological testing: Principles, applications, and issues. Cengage Learning.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 46, 'page_label': '47', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='43 \\nRelated Questions \\nAs indicated, formative assessment is an area in which AI is expanding along a continuum that \\ncan be guided by visions already in place, such as the 2017 NETP. It is an area in which AI is \\npoised to grow, especially with capabilities that power more feedback loops in student learning. \\nAs this growth takes place, we suggest ongoing attention to the following questions: \\n● Is formative assessment bringing benefits to the student learning experience and to the \\nefficacy of classroom instruction?  \\n● Are humans being centered in AI-enabled formative assessment and feedback loops? \\n● Are we providing empowering professional development to teachers so they can leverage \\nfeedback loops and safeguard against concerns? \\n● To what extent are the developers and implementers of AI-enabled systems and tools \\ntackling new sources of algorithmic bias and continuing to make assessment fairer?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 46, 'page_label': '47', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='● To what extent are the developers and implementers of AI-enabled systems and tools \\ntackling new sources of algorithmic bias and continuing to make assessment fairer? \\n● Are governance policies regarding who owns, controls, and can view or use AI-enabled \\nformative assessment data appropriate and adequate? \\n● Do we have sufficient guardrails against misuse of formative assessment data or \\nautomatically generated interpretations of student achievement and learning, such as on \\ndashboards?  \\n● Is trust in an AI-enabled assessment system, feedback loops, and data generated by such \\nassessments growing or diminishing?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 47, 'page_label': '48', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='44 \\nResearch and Development \\nPolicy relies upon research-based knowledge; likewise, improving practice depends on feedback \\nloops that analyze empirical evidence. Consequently, the 2010 NETP specified a series of “grand \\nchallenges” which were “R&D problems that might be funded and coordinated at a national \\nlevel.” One 2010 NETP grand challenge was to create personalized learning systems that \\ncontinuously improve as they are used: \\n“Design and validate an integrated system that provides real-time access \\nto learning experiences tuned to the levels of difficulty and assistance \\nthat optimize learning for all learners and that incorporates self-\\nimproving features that enable it to become increasingly effective \\nthrough interaction with learners.”69 \\nSince 2010, much R&D has addressed this challenge. Conferences about learning analytics, \\neducational data mining, and learning at scale have blossomed. Developers have created'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 47, 'page_label': '48', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Since 2010, much R&D has addressed this challenge. Conferences about learning analytics, \\neducational data mining, and learning at scale have blossomed. Developers have created \\nplatforms that use algorithms and the analysis of big data to tune learning experiences. The \\nchallenge has not been fully achieved, and further work on this challenge is still relevant today.  \\nInsight: Research Can Strengthen the Role of Context in AI \\nDespite the relevance of 2010’s grand challenges, it has become apparent that the R&D \\ncommunity is now looking to expand their attention. The 2010 challenges were stated as \\ntechnical problems. Today’s researchers want to more deeply investigate context, and today’s \\ntech companies want to develop platforms that are responsive to the learners’ characteristics and \\nsituations more broadly—not just in terms of narrow cognitive attributes. We see a push to \\ntransform R&D to address context sensitivity. We look forward to new meanings of “adaptive”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 47, 'page_label': '48', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='situations more broadly—not just in terms of narrow cognitive attributes. We see a push to \\ntransform R&D to address context sensitivity. We look forward to new meanings of “adaptive” \\nthat broaden outward from what the term has meant in the past decade. For example, “adaptive” \\nshould not always be a synonym of “individualized” because people are social learners. \\nResearchers therefore are broadening “adaptivity” to include support for what students do as \\nthey learn in groups, a form of learning that is prevalent in schools across the U.S. \\nThe focus on context is not an accident. Context is a traditional challenge in AI.70 Thus, \\nresearchers and developers are wise to prioritizing context. Unless we invest more in AI that is \\ncontext-sensitive, it is quite likely that AI will break and fail to achieve educational goals. \\nAgreeing to prioritize context won’t be easy. As illustrated above in Figure 12, there will be a'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 47, 'page_label': '48', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='context-sensitive, it is quite likely that AI will break and fail to achieve educational goals. \\nAgreeing to prioritize context won’t be easy. As illustrated above in Figure 12, there will be a \\ntension between depth of context and pace of technological advances in AI R&D. On the one \\nhand, AI is sometimes presented as a race to be the first to advance new techniques or scale new \\napplications—innovation is sometimes portrayed as rapidly going to scale with a minimally \\nviable product, failing fast, and only after failure, dealing with context. On the other hand, \\nresearchers and developers see that achieving good innovations with AI in education will clearly \\n \\n69 U.S. Department of Education, Office of Educational Technology. (2010). Transforming American Education: Learning \\nPowered by Technology. U.S. Department of Education. p. 78 \\n70 Boden, M.A. (2018). Artificial intelligence: A very short introduction. Oxford. ISBN: 978-0199602919'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 48, 'page_label': '49', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='45 \\nrequire bringing more context into the process early and often. For example, researchers \\nhighlight that humans must be continually adjusting the goals for technology and have noted \\nthat when we set forth goals, we often don’t yet fully understand context; and as we learn about \\ncontext, the goals must change.71 This suggests that context must be prioritized early and \\nhabitually in R&D; we don’t want to win a race to the wrong finish line. \\nFigure 12: The tension between depth of context and pace of technological advances in AI \\n \\nFurther, intensifying focus on context in this work will change the nature of the R&D. There \\nwon’t be just one type of change in R&D because context has multiple meanings. Attendees in \\nour listening sessions described four types of context necessary for the future. \\nWe list these four types of context below and then expand on each one in its own section. These'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 48, 'page_label': '49', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='our listening sessions described four types of context necessary for the future. \\nWe list these four types of context below and then expand on each one in its own section. These \\nfour types emerged as topics of provocations to think differently about R&D but certainly do not \\nexhaust the important ways of investigating context. \\n1. Focus on the Long Tail: How could we use big data and AI to pay more attention to the \\n“long tail” of edtech use—going beyond a few “most typical” ways of using emerging \\ntechnology and instead solving for digital equity and inclusion? \\n2. Partnership in Design-Based Research: How can we change who is involved and \\ninfluential in designing the future of AI in education to more centrally include students, \\nteachers, and other educational constituents?  \\n3. Connect with Public Policy: How can work on AI in education build on general advances \\nin AI ethics, safety, and regulation and contribute additional advances specific to \\neducational policy?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 48, 'page_label': '49', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='3. Connect with Public Policy: How can work on AI in education build on general advances \\nin AI ethics, safety, and regulation and contribute additional advances specific to \\neducational policy?  \\n4. Rethink Teacher Professional Development: How can we solve for new systems of \\nteacher professional development (both pre-service and in-service) that align to the \\nincreasingly core role of technology in the teaching profession? \\n \\n71 Russell, S. (2019). Human compatible: Artificial intelligence and the problem of control. Penguin. ISBN: 9780525558637'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 49, 'page_label': '50', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"46 \\n“We can't necessarily always apply traditional research methodologies to \\nthis topic because educational technology changes so quickly.”  \\n—Kristina Ishmael, Office of Educational Technology \\nAttention to the Long Tail of Learner Variability \\nAt the core of R&D of AI in education, innovators will be building models that fit available data. \\nThe increasing scale and prevalence of technologies means that the data is coming from and \\nincluding a wide range of different contexts and varied ways that people in those contexts engage \\nin teaching and learning. Researchers in our listening sessions drew attention to the promise of \\nAI for addressing “context” by reference to the long tail of learner variability. \\nFigure 13: The long tail of learner variability\\n \\nAs depicted in Figure 13, learners vary in their strengths and needs. The most frequently \\noccurring mix of strength and needs (also known as “teaching to the middle”) is depicted\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 49, 'page_label': '50', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='As depicted in Figure 13, learners vary in their strengths and needs. The most frequently \\noccurring mix of strength and needs (also known as “teaching to the middle”) is depicted \\nleftmost, with less frequently occurring mixes spreading to the right. Rising upward, the figure \\ndepicts the number of learners who benefit from a particular learning design, pathway, or \\napproach. We argue that AI can bring opportunities to address a wider spectrum of strengths and \\nneeds but only if developers and innovators focus on the long tail and not only “teaching to the \\nmiddle.”  \\nFor the sake of argument, the figure indicates three zones. In a first zone, curricular resources are \\nmostly standardized, with perhaps a dimension or two of adaptivity. For example, many existing \\nproducts adapt based on the correctness of student answers and may also provide options to read \\nor hear text in a second language. However, the core of the instructional approach is highly'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 49, 'page_label': '50', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='products adapt based on the correctness of student answers and may also provide options to read \\nor hear text in a second language. However, the core of the instructional approach is highly \\nstandardized. In a second zone, there is greater balance between how much standardization and \\nhow much adaptivity students can access. Universal Design for Learning (UDL) is one set of \\nrecommendations for providing learning opportunities in multiple formats and for'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 50, 'page_label': '51', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='47 \\naccommodating different learning progressions.72 UDL can enable accommodating more ways in \\nwhich learners vary, and as teachers know, there are many more important ways to adapt to \\nstudents than found in today’s edtech products.  \\nStudents are neurodiverse. They bring different assets from their experiences at home, in their \\ncommunities, and in their cultures. They have different interests and motivations. And they \\nlearn in varied settings—classrooms and schools differ, and at-home students learn in informal \\nsettings in ways that could complement school learning. These are all important dimensions of \\n“context.” Zone 3 indicates highly adaptive learning, where standardization is less successful and \\nwhere we need to discover a wider variety of approaches to engage learners and sustain powerful \\nlearning. Researchers in our listening sessions noted the promise of Zone 3 because AI’s ability to'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 50, 'page_label': '51', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"where we need to discover a wider variety of approaches to engage learners and sustain powerful \\nlearning. Researchers in our listening sessions noted the promise of Zone 3 because AI’s ability to \\nrecognize patterns in data can extend beyond the most common patterns and because AI's ability \\nto generate customized content can extend beyond what people can reasonably generate on their \\nown. \\nNotice that although the Zone 1 bar appears to be the tallest, and thus tends to attract initial \\nattention, there are more students in Zones 2 and 3, the regions where AI can provide more help. \\nThus, it’s important to ask where AI researchers and developers are directing their attention. \\nWhen we say a model “fits,” are we saying it fits the most common and typical uses by teachers \\nand learners? This sort of R&D is easier to do. However, machine learning and AI also can tailor a \\nmodel to the less common and more culturally specific contexts, too. Therefore, how can\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 50, 'page_label': '51', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='and learners? This sort of R&D is easier to do. However, machine learning and AI also can tailor a \\nmodel to the less common and more culturally specific contexts, too. Therefore, how can \\nconstituents cultivate interdisciplinary expertise to direct attention among researchers and \\ndevelopers to focus on the long tail? If we do, the quality of what we do for those represented in \\nthat tail can be more adaptive and more context-sensitive. And to be most effective, it will \\nrequire the integration of contextual, content, and technical expertise. \\nWithin the long-tail challenge, the community is wondering how we can get to research insights \\nthat are both general and specific enough. When research produces very general abstractions \\nabout learning, it often doesn’t give developers enough guidance on exactly how to adjust their \\nlearning environments. Conversely, when research produces a specific adaptive algorithm that'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 50, 'page_label': '51', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='about learning, it often doesn’t give developers enough guidance on exactly how to adjust their \\nlearning environments. Conversely, when research produces a specific adaptive algorithm that \\nworks on one educational platform, it often remains hard to apply to additional platforms; \\nresearch can be too detailed as well. The research community is also thinking about new \\npartnerships that could bring more data and more diverse perspectives to the table, the topic of \\nthe next section.  \\nFocusing on the long tail of learner variability is particularly important to addressing a long-\\nstanding key research question: “Do new AI-enhanced approaches work to improve learning, and for \\nwhom and under what conditions?” \\nPartnership in Design-Based Research \\nOf course, teachers must be included in rethinking their own professional development. This \\nthought leads to another priority aspect of context: partnership in design-based research. With'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 50, 'page_label': '51', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Of course, teachers must be included in rethinking their own professional development. This \\nthought leads to another priority aspect of context: partnership in design-based research. With \\nregard to inclusive design, attendees in our listening sessions brought up a variety of co-design73 \\n \\n72 Rose, D. (2000). Universal design for learning. Journal of Special Education Technology, 15(4), 47-51. \\nhttps://doi.org/10.1177/016264340001500407 \\n73 Roschelle, J., Penuel, W., & Shechtman, N. (2006). Co-design of innovations with teachers: definition and dynamics. In \\nProceedings of the 7th International Conference on Learning Sciences, Bloomington, IN. https://doi.dx.org/10.22318/icls2006.606'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 51, 'page_label': '52', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='48 \\nand other participatory processes and goals that can be used in R&D.74 By co-design, they mean \\nsharing power with non-researchers and non-developers through all the phases of design and \\ndevelopment, which would result in more influence by teachers, students, and other constituents \\nin the shape of AI-enabled edtech. The shift toward co-design was palpable throughout our \\nlistening sessions, but as researchers and developers have not standardized on one particular co-\\ndesign method, we share some representative examples. \\n● Youth can powerfully participate in design when researcher methods include participant \\nco-design. Such research can investigate how to improve edtech while educating students. \\nA listening session attendee asked about developing students’ awareness of what data are \\nbeing collected and how data are being used by developers. \\n● There is a near future need to go beyond representation so that co-designed solutions'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 51, 'page_label': '52', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='being collected and how data are being used by developers. \\n● There is a near future need to go beyond representation so that co-designed solutions \\nconsider more generous contexts for broader possibilities, according to attendees. \\n● The shift of power dynamics is another research-worthy interest of the panel and \\nattendees to understand the balance between a teacher’s agency and a machine’s \\nsuggestions. \\n● Likewise, such longitudinal research will require both the infrastructure and institutional \\nsupport to fund necessary experimentation and requisite failures to elicit positive results \\nand safe innovation. \\n● There is a desire for rapid cycle evaluations with inclusive feedback loops that return to \\nthe educators themselves as essential relative to traditional research approaches. \\n● Many researchers also mentioned a focus on explainable AI as essential to enable \\nparticipation in the design and evaluation of emerging AI approaches in education.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 51, 'page_label': '52', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='● Many researchers also mentioned a focus on explainable AI as essential to enable \\nparticipation in the design and evaluation of emerging AI approaches in education. \\nThe conversations raised this question: how can co-design provide an empowering form of \\nparticipation in design and thus achieve digital inclusion goals? Such digital inclusion can span \\nmany layers of design, including diverse representation in design of policies around data, design \\nof adaptivity, and other user experiences in AI systems, design of plans for cultivating AI literacy \\nfor users of new platforms, and lastly, the design of plans to evaluate systems. \\nRe-thinking Teacher Professional Development \\nWith regard to teachers as professionals, both researchers and other educators attending our \\nlistening sessions were highly concerned about the disconnect between how teachers are \\nprepared versus how they are expected to work with emerging technology. When we discuss'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 51, 'page_label': '52', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='listening sessions were highly concerned about the disconnect between how teachers are \\nprepared versus how they are expected to work with emerging technology. When we discuss \\nlearning, teachers are central actors, and thus the contexts in which they are prepared is centrally \\nimportant to their ability to do great work in current and emerging technological environments.  \\nTeacher professional development, professional learning, and leadership (PD or PL) for \\nemerging technologies was seen as an area needing intense re-thinking, and research could lead \\nthe way. Today, few who prepare to become a teacher in an established pre-service program \\nlearn about the effective use of educational technology in schools and classrooms; those who do \\n \\n74 Center for Integrative Research in Computing and Learning Sciences (CIRCLS). (2022, Feb.). From Broadening to \\nEmpowering: Reflecting on the CIRCLS’21 Convening. https://circls.org/circls21report'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 52, 'page_label': '53', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='49 \\nhave the opportunity to investigate technology rarely think about the structures that shape its \\nuse in the classroom and in educational leadership. Consequently, a troubling dichotomy arises \\nbetween a small set of investigators who specifically consider educational technology in their \\nresearch on teaching and a broader group of educators who see educational technology as a \\ngeneric instructional resource. The challenge is high because teacher professional development \\nwill remain highly varied by local contexts. Yet insufficient attention to teachers as leaders in the \\nuse and further development of effective educational technology is widespread in teacher \\nprofessional development research. \\nOne response can be in terms of investigating how to nurture greater AI literacy for all teachers. \\nAI literacy is not only important to protect educators and students from possible dangers but also \\nvaluable to support teachers to harness the good and do so in innovative ways. A panelist'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 52, 'page_label': '53', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='AI literacy is not only important to protect educators and students from possible dangers but also \\nvaluable to support teachers to harness the good and do so in innovative ways. A panelist \\nreminded the group that this work implies how we prepare educators with a baseline AI literacy \\nand understanding. More transparency and authentic dialogue can foster trust, which was \\nmentioned by a researcher as a chief concern for all teachers and students. \\nThis is not to suggest that AI literacy is a complete or even a simple fix. Researchers want to ask \\nfundamental questions about what it means for teachers to be professionals, especially as \\nemerging technologies gain ground in schools and classrooms—our teachers’ professional \\nworkplaces. Researchers want to broadly reconceptualize teacher professionalism and to stop \\ntreating technology as an add-on element of professional development. \\nConnecting with Public Policy'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 52, 'page_label': '53', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='workplaces. Researchers want to broadly reconceptualize teacher professionalism and to stop \\ntreating technology as an add-on element of professional development. \\nConnecting with Public Policy \\nDefining human-centered AI for education requires the embrace of a human-centered principle \\nand foundation for developing and formulating policies that govern the application and use of \\nAI more generally throughout society. For example, power dynamics that arise between \\ncompanies and consumers in society around issues like data ownership will also arise in the \\neducation-specific ecosystem. Further, the public discourse in which people are discussing ethics, \\nbias, responsibility, and many other necessary concepts will be happening simultaneously in \\npublic policy and in educational ecosystems.  \\nOne clear implication in our listening sessions was that efforts to improve AI literacy in \\neducation could be important and helpful to society more generally. For example, one panelist'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 52, 'page_label': '53', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='One clear implication in our listening sessions was that efforts to improve AI literacy in \\neducation could be important and helpful to society more generally. For example, one panelist \\nsaid that an overarching goal of improving AI literacy is necessary if they are to contribute to \\nhow those technologies are designed. Another researcher was interested in how edtech can \\nprovide environments where students can experience having difficult discussions across \\nperspectives, an issue which is endemic to present society. A third researcher noted the \\ninsufficiencies of prior efforts to contend with algorithmic bias, ethics, and inclusion due to a \\nclassroom’s complex social dynamics. \\nResearchers want to take a lead in going beyond checkbox approaches to take these issues \\nseriously. And they also acknowledge that engaging with policy is often a new form of context \\nfor edtech and AI researchers, many of whom don’t have long experiences in policy arenas.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 52, 'page_label': '53', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='seriously. And they also acknowledge that engaging with policy is often a new form of context \\nfor edtech and AI researchers, many of whom don’t have long experiences in policy arenas. \\nLikewise, developers often do have experience with some policy issues, such as data privacy and \\nsecurity, but are now needing to become part of new conversations about ethics, bias,'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 53, 'page_label': '54', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='50 \\ntransparency, and more, a problem that the EdSAFE AI Alliance is addressing through multi-\\nsector working groups and policy advocacy.75  \\nKey Recommendation: Focus R&D on Addressing Context \\nAttendees who have participated in listening sessions leading up to this report were exceptionally \\nclear that their view of future R&D involved a shift from narrow technical questions to richer \\ncontextual questions. This expansive shift toward context, as detailed below, is the foundational \\norientation that the listening session attendees saw as being necessary to advancing R&D. \\nAttendees included these as dimensions of context: \\n• learner variability, e.g., in disabilities, languages spoken, and other relevant \\ncharacteristics; \\n• interactions with peers, teachers, and others in the learning settings; \\n• relationships across home, school, and community settings, including cultural assets; \\n• instructional resources available while learning; \\n• teacher preparation; and'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 53, 'page_label': '54', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='• relationships across home, school, and community settings, including cultural assets; \\n• instructional resources available while learning; \\n• teacher preparation; and \\n• policies and systems that structure teaching and learning. \\n \\nTo more fully represent the context of teaching and learning, including these and other \\ndimensions of text, researchers will have to work in partnership with others to understand which \\naspects of context are most relevant to teaching and learning and how they can be usefully \\nincorporated into AI models. \\nOngoing Questions for Researchers \\nAs mentioned earlier, people are good at context; AI—not so much. R&D investment in context-\\nrich edtech thus could serve multiple national interests because finding ways to do a better job \\nwith context would be a fundamental advancement in AI. Indeed, questions like these \\nreverberate across all applications of AI in society, and education is a centrally good context for \\ninvestigating them:'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 53, 'page_label': '54', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='reverberate across all applications of AI in society, and education is a centrally good context for \\ninvestigating them: \\n● Are AI systems moving beyond the tall portions of the “long tail” to adapt to a greater \\nrange of conditions, factors, and variations in how people learn?  \\n● To what extent are AI technologies enhancing rather than replacing human control and \\njudgment of student learning? \\n● How will users understand the legal and ethical implications of sharing data with AI \\nenabled technologies and how to mitigate privacy risks? \\n● To what extent does technology account for the complex social dynamics of how people \\nwork and learn together, or is technology leading humans to narrow or oversimplify? \\n● How can we more clearly define what we mean by a context-sensitive technology in \\nterms that are both concrete and broad enough? How can we measure it? \\n \\n75 Nentrup, E. (2022). How Policymakers Can Support Educators and Technology Vendors Towards SAFE AI. EdSAFE AI'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 53, 'page_label': '54', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='terms that are both concrete and broad enough? How can we measure it? \\n \\n75 Nentrup, E. (2022). How Policymakers Can Support Educators and Technology Vendors Towards SAFE AI. EdSAFE AI \\nAlliance. https://www.edsafeai.org/post/how-policymakers-can-support-aied'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 54, 'page_label': '55', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='51 \\n● To what extent are technical indicators and human observations of bias or unfairness \\nworking together with human observations? How can concerns about ethics and equity in \\nAI technologies become actionable both in R&D, and later, when AI is widely used? \\n● Are we learning for whom and under what conditions AI systems produce desired \\nbenefits and impacts and avoid undesirable discrimination, bias, or negative outcomes?  \\nDesired National R&D Objectives \\nAttendees sought immediate progress on some key R&D issues, such as these: \\n• Clarifying and achieving a consensus on the terms that go beyond data privacy and data \\nsecurity, including ideas like human-centered, value-sensitive, responsible, ethical, and \\nsafe so constituents can advocate for their needs meaningfully and consistently \\n• Creating and studying effective programs for AI literacy for students, teachers, and \\neducational constituents in general, including literacy with regard to the ethics and equity'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 54, 'page_label': '55', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='• Creating and studying effective programs for AI literacy for students, teachers, and \\neducational constituents in general, including literacy with regard to the ethics and equity \\nissues specific to AI in educational settings \\n• Advancing research and development to increase fairness, accountability, transparency, \\nand safety in AI systems used in educational settings \\n• Defining participatory or co-designed research processes that include educators in the \\ndevelopment and conduct of research related to the development, use, and efficacy of AI-\\nenabled systems and tools  \\n• Highlighting and advancing R&D efforts that empower the participation and voices of \\nyouth regarding research, data, and design of AI applications for teaching and learning \\nLonger term desires for a national R&D program include some of the following objectives: \\n• Funding sustainable partnerships that uncover what context means and how it can be \\naddressed over longer periods of time'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 54, 'page_label': '55', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='• Funding sustainable partnerships that uncover what context means and how it can be \\naddressed over longer periods of time \\n• Better connecting goals for “broadening participation” (for example, in STEM learning \\npathways) to strategies for addressing learner variability and diversity \\n• Prioritizing research to revitalize support for instructors in light of the increasingly \\ntechnological nature of K-12, higher education, and workplace learning settings \\n• Creating infrastructure and new ways of working together beyond individual field-\\ninitiated grants so that R&D with big data and leveraging emerging AI capabilities \\nbecomes safer and more productive'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 55, 'page_label': '56', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='52 \\nRecommendations  \\nEarlier, we asked two guiding questions: \\n1. What is our collective vision of a desirable and achievable educational system that \\nleverages automation while protecting and centering human agency? \\n2. On what timeline will we be ready with necessary guidelines and guardrails along with \\nconvincing evidence of positive impacts, so that we can ethically and equitably \\nimplement this vision widely? \\nAnswers to the first question are provided throughout the Learning, Teaching, Assessment, and \\nResearch sections. This section turns to a call to action to education leaders and to \\nrecommendations. Core to the Department’s perspective is that education will need leadership \\nspecific to our sector. Leadership should recognize and build on prior accomplishments in \\nedtech (such as strong prior work on student privacy and school data security) as well as broad \\nframeworks for safe AI (such as the Blueprint for an AI Bill of Rights). Leadership must also reach'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 55, 'page_label': '56', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='edtech (such as strong prior work on student privacy and school data security) as well as broad \\nframeworks for safe AI (such as the Blueprint for an AI Bill of Rights). Leadership must also reach \\nbeyond these accomplishments and frameworks to address emerging opportunities and risks \\nthat are specific to novel capabilities and uses of AI in education.  \\nInsight: Aligning AI to Policy Objectives \\nIndividual sections of this policy report provided insights in each of four areas—learning, \\nteaching, assessment, and research. These insights, synthesized from extensive stakeholder \\nconsultation and listening sessions, show that the advances in AI can bring opportunities to \\nadvance the Department’s policy objectives: \\n● In support of our objective of attracting and retaining teachers, our nation could focus on \\nAI assistants that make teaching jobs better and provide teachers with the information \\nthey need to work closely and empathically with students. An emphasis on teachers in the'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 55, 'page_label': '56', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='AI assistants that make teaching jobs better and provide teachers with the information \\nthey need to work closely and empathically with students. An emphasis on teachers in the \\nloop could ensure that AI-enabled classroom technologies keep teachers in the know, in \\ntouch with their students, and in control of important instructional decisions. Keeping the \\nteacher in the loop is important to managing risks, as well. \\n● In support of equitable learning, especially for those most affected by the pandemic, AI \\ncould shift edtech from a current deficit-based model to a strengths-based alternative. In \\naddition to finding student weaknesses and assigning fixes, edtech could make \\nrecommendations based on strengths that students bring to learning and how adapting to \\nthe whole student—a cognitive, social, and self-regulating person—could enable more \\npowerful learning. Adapting to the whole student should include supporting students'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 55, 'page_label': '56', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='the whole student—a cognitive, social, and self-regulating person—could enable more \\npowerful learning. Adapting to the whole student should include supporting students \\nwith disabilities as well as English learners. With regard to equity, we must remain highly \\nattuned to the challenges of bias (which are inherent to how AI systems are developed) \\nand take firm action to ensure fairness. \\n● With regard to growth trajectories to successful careers, AI-enabled assessments could \\nprovide students and teachers with formative guidance on a wider range of valuable \\nskills, focusing on providing information that enhances learning. Aligned with the \\nhuman-centric view, we should take a systems view of assessments where students, \\nteachers, and others remain at the center of instructional decision making.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 56, 'page_label': '57', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='53 \\n● With regard to equity, as research advances and brings more context into AI, we will be \\nbetter able to use AI to support goals that require customization of learning resources, \\nsuch as enabling teachers to more easily transform materials to support neurodiverse \\nlearners and increase responsiveness to local communities and cultures.  \\nGoing forward, educational leaders need to bring these and their own policy priorities to the \\ntable at every discussion about AI, driving the conversation around human priorities and not \\nonly their excitement about what new technology might do. Fundamentally, AI seeks to \\nautomate processes that achieve goals, and yet, AI should never set goals. The goals must come \\nfrom educators’ vision of teaching and learning and educators’ understanding of students’ \\nstrengths and needs. \\nCalling Education Leaders to Action \\nWe summarize seven recommendations for policy action. These recommendations are for'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 56, 'page_label': '57', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='strengths and needs. \\nCalling Education Leaders to Action \\nWe summarize seven recommendations for policy action. These recommendations are for \\neducation leaders. In the introduction, we note the necessity of involving education constituents \\nin determining policies for AI. We also observed throughout our listening sessions that people \\ncoming from many different roles in education all have passion, knowledge, and insights to \\ncontribute. In our view, all types of constituents can be education leaders. We are reluctant to \\nsuggest any constituent role is more important to advance any of the recommendations, but we \\ncall out specific needs for action within some of the recommendations where it is warranted. \\nRecommendation #1: Emphasize Humans in the Loop \\nWe start with a central recommendation throughout this report. This recommendation was a \\nclear constituent favorite. Indeed, across more than 700 attendees in our listening sessions, the'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 56, 'page_label': '57', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='We start with a central recommendation throughout this report. This recommendation was a \\nclear constituent favorite. Indeed, across more than 700 attendees in our listening sessions, the \\npredominant discussion tackled how constituents can achieve a consensus vision for AI-enabled \\nedtech where humans are firmly at the center. The Blueprint for an AI Bill of Rights similarly calls \\nfor “access to timely human consideration and remedy by a fallback and escalation process if an \\nautomated system fails, it produces an error, or you would like to appeal or contest its impacts…” \\nBuilding on this consensus, we call upon all constituents to adopt “humans in the loop” as a key \\ncriterion for educational use of AI.  \\nWe envision a technology-enhanced future more like an electric bike and less like robot \\nvacuums. On an electric bike, the human is fully aware and fully in control, but their burden is \\nless, and their effort is multiplied by a complementary technological enhancement. Robot'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 56, 'page_label': '57', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='vacuums. On an electric bike, the human is fully aware and fully in control, but their burden is \\nless, and their effort is multiplied by a complementary technological enhancement. Robot \\nvacuums do their job, freeing the human from involvement or oversight.  \\nAlthough teachers should not be the only humans involved in loops, Figure 5 provided examples \\nof three types of teacher loops that are central to education and can be used to illustrate what \\n“human in the loop” means. Here, we use the example of an AI chatbot to elaborate on the \\nmeaning of the loops. First, as students become involved in extended interactions with AI \\nchatbots, teachers will need to educate students about safe AI use, monitor their use, and provide \\nhuman recourse when things go astray. Second, teachers are beginning to use chatbots to plan \\npersonalized instruction for their students; they will need to be involved in loops with other'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 56, 'page_label': '57', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='human recourse when things go astray. Second, teachers are beginning to use chatbots to plan \\npersonalized instruction for their students; they will need to be involved in loops with other \\nteachers to understand effective prompts, to know how to analyze AI-generated lesson plans for \\nflaws, and to avoid the human tendency to overly trust AI systems and underapply human \\njudgement. Third, teachers need to be involved in the design and evaluation of AI systems before \\nthey are used in classrooms and when needs for improvement are observed. In one example, to \\ndesign AI-generated homework support for students, teachers’ in-depth understanding of the'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 57, 'page_label': '58', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='54 \\ncognitive, motivational, and social supports their students need will provide much-needed \\nguidance as a homework-support chatbot is designed.  \\nIn framing AI in education, this report advances a key recommendation of “human in the loop” \\nAI because the phrase readily communicates a criterion that everyone can use as they determine \\nwhich AI-enabled systems and tools are appropriate for use in teaching and learning. In a rather \\ntechnical field, human in the loop is an approachable and humanistic criterion. Rather than \\nsuggesting that AI-enabled systems and tools should replace teachers, this term instead solidifies \\nthe central role of educators as instructors and instructional decision makers, while reinforcing \\nthe responsibility of teachers to exercise judgement and control over the use of AI in education. \\nIt resonates with the important idea of feedback loops, which are highly important to how'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 57, 'page_label': '58', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='the responsibility of teachers to exercise judgement and control over the use of AI in education. \\nIt resonates with the important idea of feedback loops, which are highly important to how \\npeople teach and learn. It also aligns with the ideas of inspectable, explainable, severable, and \\noverridable AI.  \\nThe Department agrees with listening session participants who argued that teachers should not \\nbe the only humans in the loop and calls upon parents, families, students, policy makers, and \\nsystem leaders to likewise examine the “loops” for which they are responsible, critically analyze \\nthe increasing role of AI in those loops, and determine what they need to do to retain support for \\nthe primacy of human judgement in educational systems. \\nRecommendation #2: Align AI Models to a Shared Vision for Education \\n“All models are wrong, but some are useful.”  \\n —George Box, Statistician \\nAs we have discussed across every section of this report, AI technologies are grounded in models,'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 57, 'page_label': '58', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"“All models are wrong, but some are useful.”  \\n —George Box, Statistician \\nAs we have discussed across every section of this report, AI technologies are grounded in models, \\nand these models are inevitably incomplete in some way. It is up to humans to name educational \\ngoals and measure the degree to which models fit and are useful—or don’t fit and might be \\nharmful. Such an assessment of how well certain tools serve educational priorities may seem \\nobvious, but the romance of technology can lead to a “let’s see what the tech can do'' attitude, \\nwhich can weaken the focus on goals and cause us to adopt models that fit our priorities poorly.  \\nHere we call upon educational policy and decision makers at the local, state, and federal level to \\nuse their power to align priorities, educational strategies, and technology adoption decisions to \\nplace the educational needs of students ahead of the excitement about emerging AI capabilities.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 57, 'page_label': '58', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='use their power to align priorities, educational strategies, and technology adoption decisions to \\nplace the educational needs of students ahead of the excitement about emerging AI capabilities. \\nWe want to strengthen their attention to existing state, district, and school-level policies that \\nguide edtech adoption and use, such as the four levels of evidence in ESSA, the privacy \\nrequirements of FERPA, and enhanced policies to come. Local education leaders know best what \\ntheir urgent educational priorities are. Every conversation about AI (or any emerging \\ntechnology) should start with the educational needs and priorities of students front and center \\nand conclude with a discussion about the evaluation of effectiveness re-centered on those needs \\nand priorities. Equity, of course, is one of those priorities that requires constant attention, \\nespecially given the worrisome consequences of potentially biased AI models.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 57, 'page_label': '58', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='and priorities. Equity, of course, is one of those priorities that requires constant attention, \\nespecially given the worrisome consequences of potentially biased AI models.  \\nWe especially call upon leaders to avoid romancing the magic of AI or only focusing on \\npromising applications or outcomes, but instead to interrogate with a critical eye how AI-enabled \\nsystems and tools function in the educational environment. We ask leaders to distrust broad \\nclaims and ask six types of questions, listed below. Throughout this report, we elaborated on'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 58, 'page_label': '59', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='55 \\nwhich characteristics of AI model use in education are most important to evaluate for alignment \\nto intended educational goals. To aid leaders, we summarize our insights about AI models and \\ntheir use in educational tools and systems in Figure 14.  \\nFigure 14: Recommendation for desired qualities of AI tools and systems in education \\n \\nIn this figure, we center teaching and learning in all considerations about the suitability of an AI \\nmodel for an educational use. Humans remain in the loop of defining, refining, and using AI \\nmodels. We highlight the six desirable characteristics of AI models for education (elaborating \\nfrom principles in the Blueprint for an AI Bill of Rights to fit the specifics of educational systems): \\n1. Alignment of the AI Model to Educators’ Vision for Learning: When choosing to use AI \\nin educational systems, decision makers prioritize educational goals, the fit to all we know'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 58, 'page_label': '59', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='1. Alignment of the AI Model to Educators’ Vision for Learning: When choosing to use AI \\nin educational systems, decision makers prioritize educational goals, the fit to all we know \\nabout how people learn, and alignment to evidence-based best practices in education. \\n2. Data Privacy: Ensuring security and privacy of student, teacher, and other human data in \\nAI systems is essential. \\n3. Notice and Explanation: Educators can inspect edtech to determine whether and how AI \\nis being incorporated within edtech systems. Educators’ push for AI models can explain \\nthe basis for detecting patterns and/or for making recommendations, and people retain \\ncontrol over these suggestions. \\n4. Algorithmic Discrimination Protections: Developers and implementers of AI in \\neducation take strong steps to minimizing bias and promoting fairness in AI models.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 59, 'page_label': '60', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='56 \\n5. Safe and Effective Systems: The use of AI models in education is based on evidence of \\nefficacy (using standards already established in education for this purpose) and work for \\ndiverse learners and in varied educational settings. \\n6. Human Alternatives, Consideration and Feedback: AI models that support transparent, \\naccountable, and responsible use of AI in education by involving humans in the loop to \\nensure that educational values and principles are prioritized. \\nAlthough we first address our recommendation to interrogate how educational systems use AI \\nmodels to educational leaders who adopt technologies, other leaders also have integral roles to \\nplay. Teachers and students, as well as their families/caregivers, contribute significantly to \\nadoption decisions also. And leaders and parents must support educators when they question or \\noverride an AI model based on their professional wisdom. Developers of technologies need to be'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 59, 'page_label': '60', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='adoption decisions also. And leaders and parents must support educators when they question or \\noverride an AI model based on their professional wisdom. Developers of technologies need to be \\nforthcoming about the models they use, and we may need policymakers to create requirements \\nfor disclosure so that the marketplace can function on the basis of information about AI models \\nand not only by the claims of their benefits. \\nWe also emphasize the need for a government role. AI models are made by people and are only \\nan approximation to reality. Thus, we need policies that require transparency about the AI \\nmodels that are embedded in educational systems, as well as models that are inspectable, \\nexplainable, and overridable. Our listening sessions featured constituent calls for government \\ndoing more to hold developers accountable for disclosing the types of AI models they employ in \\nlarge-scale products and the safeguards included in their systems. Government leaders can make'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 59, 'page_label': '60', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='doing more to hold developers accountable for disclosing the types of AI models they employ in \\nlarge-scale products and the safeguards included in their systems. Government leaders can make \\na positive contribution to market conditions that enable building trust as AI systems are \\nprocured and implemented in education. We discuss these guidelines more in recommendation \\n#4, which is about building trust. \\nRecommendation #3: Design Using Modern Learning Principles \\nWe call for the R&D sector to ensure that product designs are based on best and most current \\nprinciples of teaching and learning. The first decade of adaptivity in edtech drew upon many \\nimportant principles, for example, around how to sequence learning experiences and how to \\ngive students feedback. And yet the underlying conception was often deficit-based. The system \\nfocused on what was wrong with the student and chose pre-existing learning resources that'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 59, 'page_label': '60', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='give students feedback. And yet the underlying conception was often deficit-based. The system \\nfocused on what was wrong with the student and chose pre-existing learning resources that \\nmight fix that weakness. Going forward, we must harness AI’s ability to sense and build upon \\nlearner strengths. Likewise, the past decade of approaches was individualistic, and yet we know \\nthat humans are fundamentally social and that learning is powerfully social. Going forward, we \\nmust build on AI capabilities that connect with principles of collaborative and social learning and \\nwhich respect the student not just for their cognition but also for the whole human skill set. \\nGoing forward, we also must seek to create AI systems that are culturally responsive and \\nculturally sustaining, leveraging the growth of published techniques for doing so. Further, most \\nearly AI systems had few specific supports for students with disabilities and English learners.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 59, 'page_label': '60', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='culturally sustaining, leveraging the growth of published techniques for doing so. Further, most \\nearly AI systems had few specific supports for students with disabilities and English learners. \\nGoing forward, we must ensure that AI-enabled learning resources are intentionally inclusive of \\nthese students. The field has yet to develop edtech that builds upon each student’s ability to \\nmake choices and to self-regulate in increasingly complex environments. We have to develop \\nedtech that expands students’ abilities to learn in creative modes and to expand their ability to \\ndiscuss, write, present, and lead. \\nWe also call upon educators to reject uses of AI that are based solely on machine learning from \\ndata—without triangulation based on learning theory and knowledge from practice. Achieving'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 60, 'page_label': '61', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='57 \\neffective and equitable educational systems requires more than processing “big data,” and \\nalthough we want to harness insights from data, human interpretation of data remains highly \\nimportant. We reject a technological determinism in which patterns in data, on their own, tell us \\nwhat to do. Applications of AI in education must be grounded in established, modern learning \\nprinciples, the wisdom of educational practitioners, and should leverage the expertise in the \\neducational assessment community around detecting bias and improving fairness.  \\nRecommendation #4: Prioritize Strengthening Trust \\nTechnology can only help us to achieve educational objectives when we trust it. Yet, our listening \\nsessions revealed the ways in which distrust of edtech and AI is commonplace. Constituents \\ndistrust emerging technologies for multiple reasons. They may have experienced privacy \\nviolations. The user experience may be more burdensome than anticipated. Promised increases'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 60, 'page_label': '61', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='distrust emerging technologies for multiple reasons. They may have experienced privacy \\nviolations. The user experience may be more burdensome than anticipated. Promised increases \\nin student learning may not be backed by efficacy research. They may have experienced \\nunanticipated consequences. Unexpected costs may arise. Constituents may distrust complexity. \\nTrust needs to incorporate safety, usability, and efficacy. \\nThe Department firmly takes the stance that constituents want AI that supports teachers and \\nrejects AI visions that replace teachers. And yet, teachers, students, and their families/caregivers \\nneed support to build appropriate levels of trust in systems that affect their work. In the broader \\necosystem, trustworthy AI is recognized as a multidimensional problem (including the \\ndimensions of Figure 14, above). If every step forward does not include strong elements of trust \\nbuilding, we worry that distrust will distract from innovation serving the public good that AI'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 60, 'page_label': '61', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='dimensions of Figure 14, above). If every step forward does not include strong elements of trust \\nbuilding, we worry that distrust will distract from innovation serving the public good that AI \\ncould help realize. \\nWe expect that associations and societies have a key role in strengthening trust. Some important \\nassociations like the State Educational Technology Directors Association and the Consortium for \\nSchool Network work with edtech leaders, and parallel organizations like EDUCAUSE work with \\npostsecondary leaders. Other associations and societies work with teachers, education leaders, \\nand education staff developers. Industry networks, like the EdSAFE AI Alliance, can bring \\ntogether industry leaders to work together to foster trust. Additional societies bring researchers \\ntogether. These societies and associations have the reach necessary to bring all parts of the \\neducational ecosystem into discussions about trust and also the ability to represent the views of'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 60, 'page_label': '61', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='together. These societies and associations have the reach necessary to bring all parts of the \\neducational ecosystem into discussions about trust and also the ability to represent the views of \\ntheir constituents in cross-cutting policy discussions. \\nRecommendation #5: Inform and Involve Educators \\nOur listening sessions also asked for more specific direction on the question of what education \\nleaders should do (see Figure 15). The most frequent responses fit three clusters: the need for \\nguidelines and guardrails, strengthening the role of teachers, and re-focusing research and \\ndevelopment. These are activities that constituents are asking for and that could expand trust. \\nThe recommendations that follow respond to these requests.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 61, 'page_label': '62', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='58 \\nFigure 15: Listening session attendees prioritized involving practitioners, research, and \\nevaluation and the need for guidelines and guardrails. \\n \\nIn particular, one concern that repeatedly arose in our listening sessions was the potential for AI \\nto result in less respect for educators or less value for their skills. Across the nation, we are now \\nresponding to decreasing interest in entering or remaining in the teaching profession. Now is the \\ntime to show the respect and value we hold for educators by informing and involving them in \\nevery step of the process of designing, developing, testing, improving, adopting, and managing \\nAI-enabled edtech. This includes involving educators in reviewing existing AI-enabled systems, \\ntools, and data use in schools, designing new applications of AI based on teacher input, carrying \\nout pilot evaluations of proposed new instructional tools, collaborating with developers to'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 61, 'page_label': '62', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='tools, and data use in schools, designing new applications of AI based on teacher input, carrying \\nout pilot evaluations of proposed new instructional tools, collaborating with developers to \\nincrease the trustworthiness of the deployed system, and raising issues about risks and \\nunexpected consequences as the system is implemented. \\nWe have already seen educators rise to the challenge of creating overall guidelines, designing \\nspecific uses of available AI-enabled systems and tools, and ferreting out concerns. And yet, the \\ninfluence of educators in the future of AI-enabled products cannot be assumed; instead, \\nconstituents need policies that put muscle behind it. Could we create a national corps of leading \\neducators representing every state and region to provide leadership? Could we commit to \\ndeveloping necessary professional development supports? Can we find ways to compensate \\neducators so they can be at the forefront of designing the future of education? Our policies'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 61, 'page_label': '62', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='developing necessary professional development supports? Can we find ways to compensate \\neducators so they can be at the forefront of designing the future of education? Our policies \\nshould enable educators to be closely involved in design of AI-enabled educational systems. \\nAlthough we know that the responsibility for informing and involving educators must be \\ndistributed at all levels of national and school governance, the Office of Educational Technology'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 62, 'page_label': '63', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='59 \\ncan play a key role in informing and involving educators through its reports, events, outreach, \\nand in a future NETP. Although examples above refer to K-12 teachers, higher education \\ninstructors must also be included. We also call on the edtech industry to involve educators \\nthroughout their design and development processes. For example, AI-enabled teaching assistants \\nare only likely to help teachers do their job if teachers are thoroughly involved as the assistants \\nare designed. We call upon institutions that prepare teachers to integrate technology more \\nsystematically into their programs; for example, the use of technology in teaching and learning \\nshould be a core theme across teacher preparation programs, not an issue that arises only in one \\ncourse. \\nRecommendation #6: Focus R&D on Addressing Context and \\nEnhancing Trust and Safety \\nResearch that focuses on how AI-enabled systems can adapt to context (including variability'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 62, 'page_label': '63', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='course. \\nRecommendation #6: Focus R&D on Addressing Context and \\nEnhancing Trust and Safety \\nResearch that focuses on how AI-enabled systems can adapt to context (including variability \\namong learners) in instructional approaches and across educational settings is essential to \\nanswering the question of, “Do specific applications of AI work in education, and if so, for whom \\nand under what conditions?” The italicized phrase points to variability among learners and \\ndiversity in the settings for learning. We call upon innovators in R&D to focus their efforts to \\nadvance AI on the long tail of learning variability, where large populations of students would \\nbenefit from customization of learning. We also call on R&D to lead by establishing how trust \\ncan be strengthened in AI-enabled systems, building on the Blueprint’s call for safe and effective \\nsystems yet also including education-specific requirements, such as how teachers can be'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 62, 'page_label': '63', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='can be strengthened in AI-enabled systems, building on the Blueprint’s call for safe and effective \\nsystems yet also including education-specific requirements, such as how teachers can be \\nmeaningfully involved in design phases, not only in implementation and evaluation. \\nAlthough many products today are adaptive, some adapt on just one or a few dimensions of \\nvariability, such as student’s accuracy in problem solving. As teachers know, there are many \\nmore important ways to adapt to students’ strengths and needs. Students are neurodiverse and \\nmay have specific disabilities. They bring different assets from their experiences at home, in \\ncommunities, and in their cultures. They have different interests and motivations. They are in \\ndifferent places in their journeys to master the English language. And they learn in varied \\nsettings. Classrooms and schools are different, and at home, students learn in informal settings in'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 62, 'page_label': '63', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='different places in their journeys to master the English language. And they learn in varied \\nsettings. Classrooms and schools are different, and at home, students learn in informal settings in \\nways that could complement school learning. We recommend attention to “context” as a means \\nfor expressing the multiple dimensions that must be considered when elaborating the phrase \\n“for whom and under what conditions.” We also acknowledge the role of researchers in \\nconducting evaluations, which must now consider not only efficacy but must also explore where \\nharm may arise and the system problems that can occur through weak trust or over-trust in AI \\nsystems. \\nR&D must take the lead in making AI models more context-sensitive and ensuring that they are \\neffective, safe, and trustworthy for use with varied learners in diverse settings. Although AI has \\ncapabilities to find patterns beyond the limited number of variables that people normally think'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 62, 'page_label': '63', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='effective, safe, and trustworthy for use with varied learners in diverse settings. Although AI has \\ncapabilities to find patterns beyond the limited number of variables that people normally think \\nabout, AI is not particularly good at understanding and working with context in the ways people \\ndo. Over time, we’ve seen learning sciences grow to be less about individualistic cognitive \\nprinciples and more encompassing first of social learning and then of the many dimensions of \\ncontext that matter in learning. Our use of AI needs to follow this trajectory toward context to \\nsupport educational applications. \\nTo achieve human-centric vision, listening session attendees argued that teams will need time \\nand freedom to explore how best to manage the tension between the pace of technological'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 63, 'page_label': '64', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='60 \\nadvancement and the need for broader contextual insights—for trust and for safety. They will \\nneed time and freedom to pioneer new processes that better involve teachers and students as co-\\ndesigners, with attention to balancing power dynamics. And they will need to shift attention \\nfrom older ways of framing priorities (such as achievement gaps) to new ways of prioritizing \\ndigital equity. We call on R&D funders to focus resources on the long tail of learner variability, \\nthe need for AI-enabled systems that better incorporate context, and time required to get \\ncontextual considerations right. We call upon researchers and developers to prioritize challenges \\nof context, trust, and safety in their work to advance AI.  \\nRecommendation #7: Develop Education-Specific Guidelines and \\nGuardrails \\nOur final recommendation is central to policymakers. A feature of the American educational \\nsystem is the emphasis on local decision making. With technology growing in complexity at such'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 63, 'page_label': '64', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Guardrails \\nOur final recommendation is central to policymakers. A feature of the American educational \\nsystem is the emphasis on local decision making. With technology growing in complexity at such \\na rapid pace, it is becoming difficult for local leaders to make informed decisions about the \\ndeployment of artificial intelligence. As we have discussed, the issues are not only data privacy \\nand security but extend to new topics such as bias, transparency, and accountability. It will be \\nharder to evaluate promising edtech platforms that rely on AI systems against this evolving, \\ncomplex set of criteria.  \\nRegulations related to key student and family data privacy laws like the Family Educational \\nRights & Privacy Act (FERPA), the Children’s Internet Privacy Act (CIPA), and the Children’s \\nOnline Privacy Protection Act (COPPA) warrant review and further consideration in light of new \\nand emerging technologies in schools. Laws such as the Individuals with Disabilities Education'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 63, 'page_label': '64', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Online Privacy Protection Act (COPPA) warrant review and further consideration in light of new \\nand emerging technologies in schools. Laws such as the Individuals with Disabilities Education \\nAct (IDEA) may likewise be considered as new situations arise in the use of AI-enabled learning \\ntechnologies. As discussed throughout this document, the Blueprint for an AI Bill of Rights is an \\nimportant framework throughout this work.  \\nThe Department encourages parallel work by constituents in all levels of the educational system. \\nIn addition to the key federal laws cited immediately above, many states have also passed privacy \\nlaws that govern the use of educational technology and edtech platforms in classrooms. Further \\nconstituents can expect general frameworks for responsible AI in parallel sectors like health, \\nsafety, and consumer products to be informative but not sufficient for education’s specific needs.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 63, 'page_label': '64', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='constituents can expect general frameworks for responsible AI in parallel sectors like health, \\nsafety, and consumer products to be informative but not sufficient for education’s specific needs. \\nLeaders at every level need awareness of how this work reaches beyond implications for privacy \\nand security (e.g., to include awareness of potential bias and unfairness), and they need \\npreparation to effectively confront the next level of issues.  \\nNext Steps \\nWe are heartened to see intensifying discussions throughout the educational ecosystem about \\nthe role of AI. We see progress that we can build upon occurring, as constituents discuss these \\nthree types of questions: What are the most significant opportunities and risks? How can we \\nachieve trustworthy educational AI? How can we understand the models at the heart of \\napplications of AI and ensure they have the qualities that align to educational aspirations?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 63, 'page_label': '64', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='achieve trustworthy educational AI? How can we understand the models at the heart of \\napplications of AI and ensure they have the qualities that align to educational aspirations?  \\nThe Department developed this report with awareness of contributions arising from many types \\nof organizations and collectives. Internationally, we recognize parallel efforts to consider AI in \\nthe European Union, at the United Nations, and indeed throughout the world. We are aware of \\nprogress being led by organizations such as UNESCO, the EdSAFE AI Alliance, and research'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 64, 'page_label': '65', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='61 \\norganizations in many countries. We plan to continue cross-agency work, for example, by \\ncontinuing to coordinate with the Office of Science and Technology Policy and other Federal \\nagencies as agencies implement next steps guided by the Blueprint for an AI Bill of Rights. We see a \\nbroad and fertile context for necessary next steps:  \\n● Working within this context and with others, the Department will consider specific \\npolicies and regulations so that educators can realize the opportunities of AI in edtech \\nwhile minimizing risks. For example, the Department is developing a set of AI usage \\nscenarios to strengthen the process of evaluating and enhancing policies and regulations. \\nThe principles and practices in the Blueprint for an AI Bill of Rights will be used to ensure \\nthe scenarios mitigate important risks and harms.  \\n● Working with constituents (including education leaders; teachers, faculty, support staff,'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 64, 'page_label': '65', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='the scenarios mitigate important risks and harms.  \\n● Working with constituents (including education leaders; teachers, faculty, support staff, \\nand other educators; researchers; policymakers; funders; technology developers; \\ncommunity members and organizations; and above all, learners and their \\nfamilies/caregivers), we will develop additional resources and events to increase \\nunderstanding of AI and to involve those who will be most affected by these new \\ntechnologies.  \\n● Working across sectors, such as education, innovation, research, and policy, we will revise \\nand update the NETP to guide all constituents toward safe, equitable, and effective AI in \\neducation in the United States, in alignment with our overall educational priorities.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 65, 'page_label': '66', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='62 \\nCommon Acronyms and \\nAbbreviations \\n⚫ AES: Automated Essay Scoring \\n⚫ AI: Artificial Intelligence \\n⚫ CIPA: Children’s Internet Protection Act \\n⚫ COPPA: Children’s Online Privacy Protection Act \\n⚫ Edtech: Educational Technology \\n⚫ ESEA: Elementary and Secondary Education Act \\n⚫ ESSA: Every Student Succeeds Act \\n⚫ FERPA: Family Educational Rights and Privacy Act \\n⚫ IA: Intelligence Augmentation \\n⚫ IDEA: Individuals with Disabilities Education Act \\n⚫ IEP: Individualized Education Program \\n⚫ ITS: Intelligent Tutoring Systems \\n⚫ NETP: National Education Technology Plan \\n⚫ R&D: Research & Development'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 66, 'page_label': '67', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='63 \\nAcknowledgements \\nProject Team \\nArtificial Intelligence and the Future of Teaching and Learning was developed under the leadership \\nand guidance of Roberto J. Rodríguez, Assistant Secretary for the Office of Planning, Evaluation, \\nand Policy Development, Kristina Ishmael, Deputy Director of the Office of Educational \\nTechnology, and Bernadette Adams, Senior Policy Advisor for the Office of Educational \\nTechnology at the U.S. Department of Education.  \\nSupport for the creation of this document was provided by Digital Promise, led by Jeremy \\nRoschelle with Carly Chillmon, Judi Fusco, Gabrielle Lue, Eric Nentrup, My Nguyen, Pati \\nRuiz, and Zohal Shah. Special thanks to Center for Integrative Research in Computing and \\nLearning Sciences postdocs Michael Chang and Aditi Mallavarapu. \\nListening Session Panelists and Hosts\\nHal Abelson \\nRyan Baker \\nNancye Blair Black \\nMarcelo Aaron Bonilla \\nWorsley \\nMichael Chang \\nCarly Chillmon \\nSherice Clarke \\nTammy Clegg \\nSidney d’Mello \\nJudi Fusco'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 66, 'page_label': '67', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Hal Abelson \\nRyan Baker \\nNancye Blair Black \\nMarcelo Aaron Bonilla \\nWorsley \\nMichael Chang \\nCarly Chillmon \\nSherice Clarke \\nTammy Clegg \\nSidney d’Mello \\nJudi Fusco \\nDragan Gasevic \\nKip Glazer \\nJanice Gobert \\nSarah Hampton \\nKristina Ishmael \\nJim Larimore \\nNicol Turner Lee \\nSherry Loftin \\nGabrielle Lue \\nAditi Mallavarapu \\nOle Molvig \\nPeter Norvig \\nThomas Philip \\nVidula Plante \\nJeremy Roschelle \\nPati Ruiz \\nAlina Von Davier \\nErin Walker \\nDiego Zapata \\nWe also thank 1,075 people who registered for Listening Sessions and 700 who attended.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 67, 'page_label': '68', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='64 \\nReferences \\nAkgun, S., Greenhow, C. (2022). Artificial intelligence in education: Addressing ethical \\nchallenges in K-12 settings. AI Ethics, 2, 431–440. https://doi.org/10.1007/s43681-021-\\n00096-7 \\nAleven, V., McLaughlin, E. A., Glenn, R. A., & Koedinger, K. R. (2016). Instruction based on \\nadaptive learning technologies. In Mayer, R.E. & Alexander, P.A., Handbook of research on \\nlearning and instruction, 522-560. ISBN: 113883176X \\nBaker, R.S., Esbenshade, L., Vitale, J., & Karumbaiah, S. (2022). Using demographic data as \\npredictor variables: A questionable choice. https://doi.org/10.35542/osf.io/y4wvj \\nBlack, P. & Wiliam, D. (1998). Inside the black box: Raising standards through classroom \\nassessment. Phi Delta Kappan, 92(1), 81-90. https://kappanonline.org/inside-the-black-\\nbox-raising-standards-through-classroom-assessment/ \\nBlack, P., & Wiliam, D. (2009). Developing the theory of formative assessment. Educational'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 67, 'page_label': '68', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='box-raising-standards-through-classroom-assessment/ \\nBlack, P., & Wiliam, D. (2009). Developing the theory of formative assessment. Educational \\nAssessment, Evaluation and Accountability, 21(1), 5-31. https://doi.org/10.1007/s11092-008-\\n9068-5 \\nBoden, M.A. (2018). Artificial intelligence: A very short introduction. Oxford. ISBN: 978-0199602919 \\nBryant, J., Heitz,C., Sanghvi, S., & Wagle, D. (2020, January 14). How artificial intelligence will \\nimpact K-12 teachers. McKinsey. https://www.mckinsey.com/industries/education/our-\\ninsights/how-artificial-intelligence-will-impact-k-12-teachers \\nCelik, I., Dindar, M., Muukkonen, H. & Järvelä, S. (2022). The promises and challenges of \\nartificial intelligence for teachers: A systematic review of research. TechTrends, 66, 616–\\n630. https://doi.org/10.1007/s11528-022-00715-y \\nCenter for Integrative Research in Computing and Learning Sciences (CIRCLS). (2022, Feb.). \\nFrom Broadening to empowering: Reflecting on the CIRCLS’21 Convening.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 67, 'page_label': '68', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Center for Integrative Research in Computing and Learning Sciences (CIRCLS). (2022, Feb.). \\nFrom Broadening to empowering: Reflecting on the CIRCLS’21 Convening. \\nhttps://circls.org/circls21report \\nChen, C., Park, H.W. & Breazeal, C. (2020). Teaching and learning with children: Impact of \\nreciprocal peer learning with a social robot on children’s learning and emotive \\nengagement. Computers & Education, 150, https://doi.org/10.1016/j.compedu.2020.103836 \\nChen, G., Clarke, S., & Resnick, L.B. (2015). Classroom Discourse Analyzer (CDA): A discourse \\nanalytic tool for teachers. Technology, Instruction, Cognition and Learning, 10(2), 85-105 \\nDieterle, E., Dede, C. & Walker, M. (2022). The cyclical ethical effects of using artificial \\nintelligence in education. AI & Society. https://link.springer.com/article/10.1007/s00146-\\n022-01497-w \\nDoewes, A. & Pechenizkiy, M. (2021). On the limitations of human-computer agreement in'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 67, 'page_label': '68', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='intelligence in education. AI & Society. https://link.springer.com/article/10.1007/s00146-\\n022-01497-w \\nDoewes, A. & Pechenizkiy, M. (2021). On the limitations of human-computer agreement in \\nautomated essay scoring. In Proceedings of the 14th International Conference on Educational \\nData Mining (EDM21). \\nhttps://educationaldatamining.org/EDM2021/virtual/static/pdf/EDM21_paper_243.pdf \\nEnglebart, D.C. (October 1962). Augmenting human intellect: A conceptual framework. SRI Summary \\nReport AFOSR-3223. https://www.dougengelbart.org/pubs/augment-3906.html \\nErsozlu, Z., Ledger, S., Ersozlu, A., Mayne, F., & Wildy, H. (2021). Mixed-reality learning \\nenvironments in teacher education: An analysis of TeachLivETM Research. SAGE Open, \\n11(3). https://doi.org/10.1177/21582440211032155. \\nEuropean Commission, Directorate-General for Education, Youth, Sport and Culture. \\n(2022). Ethical guidelines on the use of artificial intelligence (AI) and data in teaching and'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 67, 'page_label': '68', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"European Commission, Directorate-General for Education, Youth, Sport and Culture. \\n(2022). Ethical guidelines on the use of artificial intelligence (AI) and data in teaching and \\nlearning for educators. Publications Office of the European \\nUnion. https://data.europa.eu/doi/10.2766/153756 \\nForsyth, S., Dalton, B., Foster, E.H., Walsh, B., Smilack, J., & Yeh, T. (2021, May). Imagine a more \\nethical AI: Using stories to develop teens' awareness and understanding of artificial \\nintelligence and its societal impacts. In 2021 Conference on Research in Equitable and \\nSustained Participation in Engineering, Computing, and Technology (RESPECT). IEEE. \\nhttps://doi.org/10.1109/RESPECT51740.2021.9620549 \\nFriedman, L., Blair Black, N., Walker, E., & Roschelle, J. (November 8, 2021) Safe AI in education \\nneeds you. Association of Computing Machinery BLOG@ACM, \\nhttps://cacm.acm.org/blogs/blog-cacm/256657-safe-ai-in-education-needs-you/fulltext\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 68, 'page_label': '69', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='65 \\nGardner, J., O\\'Leary, M. & Yuan, L. (2021). Artificial intelligence in educational assessment: \\n\"Breakthrough? Or buncombe and ballyhoo?\" Journal of Computer Assisted Learning, 37(5), \\n1207–1216. https://doi.org/10.1111/jcal.12577 \\nGartner (n.d.) Gartner glossary: Augmented intelligence. Gartner. \\nhttps://www.gartner.com/en/information-technology/glossary/augmented-intelligence \\nGay, G. (2018). Culturally responsive teaching: Theory, research, and practice. Teachers College Press. \\nISBN: 978-0807758762 \\nGodwin-Jones, R. (2021). Big data and language learning: Opportunities and challenges. \\u2028\\nLanguage Learning & Technology, 25(1), 4–19. http://hdl.handle.net/10125/44747 \\nHammerness, K., Darling-Hammond, L., & Bransford, J. (2005). Preparing teachers for a changing \\nworld: What teachers should learn and be able to do. Jossey-Bass. ISBN: 0787996343 \\nHolmes, W. & Porayska-Pomsta, K. (Eds.) (2022). The ethics of artificial intelligence in education. \\nRoutledge. ISBN 978-0367349721'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 68, 'page_label': '69', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"Holmes, W. & Porayska-Pomsta, K. (Eds.) (2022). The ethics of artificial intelligence in education. \\nRoutledge. ISBN 978-0367349721 \\nHolstein, K., McLaren, B.M., & Aleven, V. (2019). Co-designing a real-time classroom \\norchestration tool to support teacher–AI complementarity. Journal of Learning Analytics, \\n6(2). https://doi.org/10.18608/jla.2019.62.3 \\nIEEE-USA Board of Directors. (February 10, 2017). Artificial intelligence research, development and \\nregulation. IEEE http://globalpolicy.ieee.org/wp-content/uploads/2017/10/IEEE17003.pdf \\nJensen, E., Dale, M., Donnelly, P.J., Stone, C., Kelly, S., Godley, A. & D'Mello, S.K. (2020). Toward \\nautomated feedback on teacher discourse to enhance teacher learning. In Proceedings of \\nthe 2020 CHI Conference on Human Factors in Computing Systems (CHI '20). \\nhttps://doi.org/10.1145/3313831.3376418 \\nKai, S., Almeda, M.V., Baker, R. S., Heffernan, C., & Heffernan, N. (2018). Decision tree modeling\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 68, 'page_label': '69', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='https://doi.org/10.1145/3313831.3376418 \\nKai, S., Almeda, M.V., Baker, R. S., Heffernan, C., & Heffernan, N. (2018). Decision tree modeling \\nof wheel-spinning and productive persistence in skill builders. Journal of Educational Data \\nMining, 10(1), 36–71. https://doi.org/10.5281/zenodo.3344810 \\nKaplan, R.M., & Saccuzzo, D.P. (2017). Psychological testing: Principles, applications, and issues. \\nCengage Learning. \\nKe, Z., & Ng, V. (2019). Automated essay scoring: A survey of the state of the art. In Proceedings of \\nthe Twenty-Eighth International Joint Conference on Artificial Intelligence, 6300–6308. \\nhttps://doi.org/10.24963/ijcai.2019/879 \\nKhosravi, H., Shum, S.B., Chen, G, Conati, C., Tsai,Y-S., Kay, J., Knight, S., Martinez-Maldonado, \\nR., Sadiq, S., Gašević, D. (2022). Explainable artificial intelligence in education. \\nComputers and Education: Artificial Intelligence, 3. \\nhttps://doi.org/10.1016/j.caeai.2022.100074'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 68, 'page_label': '69', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='R., Sadiq, S., Gašević, D. (2022). Explainable artificial intelligence in education. \\nComputers and Education: Artificial Intelligence, 3. \\nhttps://doi.org/10.1016/j.caeai.2022.100074 \\nKulik, J.A., & Fletcher, J.D. (2016). Effectiveness of intelligent tutoring systems: A meta-analytic \\nreview. Review of Educational Research, 86(1), 42–78 \\nMa, W., Adescope, O.O, Nesbit, J.C. & Liu, Q. (2014). Intelligent tutoring systems and learning \\noutcomes: A meta-analysis. Journal of Educational Psychology, 106(4), 901–918. \\nhttp://dx.doi.org/10.1037/a0037123 \\nMaslej, N., Fattorini, L., Brynjolfsson E., Etchemendy, J., Ligett, K., Lyons, T., Manyika, J., Ngo, \\nH., Niebles, J.C., Parli, V., Shoham, Y., Wald, R., Clark, J. and Perrault, R., (2023). The AI \\nindex 2023 annual report. Stanford University: AI Index Steering Committee, Institute for \\nHuman-Centered AI.  \\nMerrill, S. (2020). In schools, are we measuring what matters? Edutopia.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 68, 'page_label': '69', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='index 2023 annual report. Stanford University: AI Index Steering Committee, Institute for \\nHuman-Centered AI.  \\nMerrill, S. (2020). In schools, are we measuring what matters? Edutopia. \\nhttps://www.edutopia.org/article/schools-are-we-measuring-what-matters \\nMolenaar, I. (2022). Towards hybrid human-AI learning technologies. European Journal of \\nEducation, 00, 1–14. https://doi.org/10.1111/ejed.12527 \\nMostow, J., Aist, G., Burkhead, P., Corbett, A., Cuneo, A., Eitelman, S., Huang, C., Junker, B., \\nSklar, M.B., & Tobin, B. (2003). Evaluation of an automated reading tutor that listens: \\nComparison to human tutoring and classroom instruction. Journal of Educational \\nComputing Research, 29(1), 61–117. https://doi.org/10.2190/06AX-QW99-EQ5G-RDCF \\nMousavinasab, E., Zarifsanaiey, N., R. Niakan Kalhori, S., Rakhshan, M., Keikha, L., & Ghazi \\nSaeedi, M. (2021). Intelligent tutoring systems: A systematic review of characteristics,'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 68, 'page_label': '69', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Mousavinasab, E., Zarifsanaiey, N., R. Niakan Kalhori, S., Rakhshan, M., Keikha, L., & Ghazi \\nSaeedi, M. (2021). Intelligent tutoring systems: A systematic review of characteristics, \\napplications, and evaluation methods. Interactive Learning Environments, 29(1), 142–163. \\nhttps://psycnet.apa.org/doi/10.1080/10494820.2018.1558257 \\nNational Academies of Sciences, Engineering, and Medicine. 2018. How people learn II: Learners, \\ncontexts, and cultures. The National Academies Press. https://doi.org/10.17226/24783'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 69, 'page_label': '70', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='66 \\nNational Research Council. 2000. How people learn: Brain, mind, experience, and school. The \\nNational Academies Press. https://doi.org/10.17226/9853 \\nNentrup, E. (2022). How Policymakers Can Support Educators and Technology Vendors Towards SAFE \\nAI. EdSAFE AI Alliance. https://www.edsafeai.org/post/how-policymakers-can-support-\\naied \\nPage, E.B. (1966). The imminence of grading essays by computer. Phi Delta Kappan, 47(5), 238–\\n243 \\nParis, D., & Alim, H.S. (Eds.). (2017). Culturally sustaining pedagogies: Teaching and learning for \\njustice in a changing world. Teachers College Press. ISBN: 978-0807758342 \\nPlass, J.L., & Pawar, S. (2020). Toward a taxonomy of adaptivity for learning. Journal of Research \\non Technology in Education, 52(3), 275–300. https://doi.org/10.1080/15391523.2020.1719943  \\nRegona, Massimo & Yigitcanlar, Tan & Xia, Bo & Li, R.Y.M. (2022). Opportunities and adoption \\nchallenges of AI in the construction industry: A PRISMA review. Journal of Open'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 69, 'page_label': '70', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Regona, Massimo & Yigitcanlar, Tan & Xia, Bo & Li, R.Y.M. (2022). Opportunities and adoption \\nchallenges of AI in the construction industry: A PRISMA review. Journal of Open \\nInnovation Technology Market and Complexity, 8(45). https://doi.org/10.3390/joitmc8010045 \\nReynolds, C.R., & Suzuki, L.A. (2012). Bias in psychological assessment: An empirical review and \\nrecommendations. Handbook of Psychology, Second Edition. \\nhttps://doi.org/10.1002/9781118133880.hop210004 \\nRitter, S., Anderson, J.R., Koedinger, K.R. & Corbett, A. (2007). Cognitive Tutor: Applied \\nresearch in mathematics education. Psychonomic Bulletin & Review, 14, 249–255/ \\nhttps://doi.org/10.3758/BF03194060 \\nRoll, I., Aleven, V., McLaren, B.M., Koedinger, K.R. (2011). Improving students’ help-seeking \\nskills using metacognitive feedback in an intelligent tutoring system, Learning and \\nInstruction, 21(2), 267–280. https://doi.org/10.1016/j.learninstruc.2010.07.004.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 69, 'page_label': '70', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='skills using metacognitive feedback in an intelligent tutoring system, Learning and \\nInstruction, 21(2), 267–280. https://doi.org/10.1016/j.learninstruc.2010.07.004. \\nRoschelle, J., Dimitriadis, Y. & Hoppe, U. (2013). Classroom orchestration: Synthesis. Computers \\n& Education, 69, 512-526. https://doi.org/10.1016/j.compedu.2013.04.010 \\nRoschelle, J., Feng, M., Murphy, R. & Mason, C.A. (2016). Online mathematics homework \\nincreases student achievement. AERA Open, 2(4), 1-12. DOI: 10.1177/2332858416673968 \\nRoschelle, J., Penuel, W., & Shechtman, N. (2006). Co-design of innovations with teachers: \\ndefinition and dynamics. In Proceedings of the 7th International Conference on Learning \\nSciences, Bloomington, IN. https://doi.dx.org/10.22318/icls2006.606 \\nRose, D. (2000). Universal design for learning. Journal of Special Education Technology, 15(4), 47-51. \\nhttps://doi.org/10.1177/016264340001500407'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 69, 'page_label': '70', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Rose, D. (2000). Universal design for learning. Journal of Special Education Technology, 15(4), 47-51. \\nhttps://doi.org/10.1177/016264340001500407 \\nRuiz, P. & Fusco, J. (2022). Teachers partnering with artificial intelligence: Augmentation and \\nautomation. Digital Promise. https://digitalpromise.org/2022/07/06/teachers-partnering-\\nwith-artificial-intelligence-augmentation-and-automation/ \\nRussell, S. (2019). Human compatible: Artificial intelligence and the problem of control. Viking. ISBN \\n978-0-525-55861-3. \\nShao, Q., Sniffen, A., Blanchet, J., Hillis, M.E., Shi, X., Haris, T.K., & Balkcom, D. (2020). \\nTeaching american sign language in mixed reality. Proceedings of the ACM on Interactive, \\nMobile, Wearable and Ubiquitous Technologies, 4(4), 1-27. https://doi.org/10.1145/3432211 \\nSharples, M. & Pérez y Pérez, R. (2022). Story machines: How computers have become creative writers. \\nRoutledge. ISBN 9780367751951'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 69, 'page_label': '70', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content=\"Sharples, M. & Pérez y Pérez, R. (2022). Story machines: How computers have become creative writers. \\nRoutledge. ISBN 9780367751951 \\nShemshack, A., Spector, J.M. (2020) A systematic literature review of personalized learning \\nterms. Smart Learning Environments, 7(33). https://doi.org/10.1186/s40561-020-00140-9 \\nShute, V J. (2008). Focus on formative feedback. Review of Educational Research, 78(1), 153–189. \\nhttps://doi.org/10.3102/0034654307313795 \\nShute, V. J., Ventura, M., & Kim, Y. J. (2013). Assessment and learning of qualitative physics in \\nNewton's Playground. The Journal of Educational Research, 106(6), 423-430. \\nhttps://doi.org/10.1080/00220671.2013.832970 \\nSwiecki, Z., Khosravi, H., Chen, G., Martinez-Maldonado, R., Lodge, J.M., Milligan, S., Selwyn, B. \\n& Gašević,D. (2022). Assessment in the age of artificial intelligence. Computers and \\nEducation: Artificial Intelligence, 3. https://doi.org/10.1016/j.caeai.2022.100075\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 69, 'page_label': '70', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='& Gašević,D. (2022). Assessment in the age of artificial intelligence. Computers and \\nEducation: Artificial Intelligence, 3. https://doi.org/10.1016/j.caeai.2022.100075 \\nThe White House (February 17, 2023). Executive order on further advancing racial equity and support \\nfor underserved communities through the federal government. \\nhttps://www.whitehouse.gov/briefing-room/presidential-actions/2023/02/16/executive-\\norder-on-further-advancing-racial-equity'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 70, 'page_label': '71', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='67 \\nThe White House (September 8, 2022). Readout of White House listening session on tech platform \\naccountability. https://www.whitehouse.gov/briefing-room/statements-\\nreleases/2022/09/08/readout-of-white-house-listening-session-on-tech-platform-\\naccountability/ \\nU.S. Department of Education, Office of Educational Technology (2022). Advancing digital equity \\nfor all: Community-based recommendations for developing effective digital equity plans to close the \\ndigital divide and enable technology-empowered learning. US Department of Education. \\nU.S. Department of Education, Office of Educational Technology. (2010). Transforming American \\nEducation: Learning Powered by Technology. U.S. Department of Education. p. 78 \\nVan Lehn, K. (2011) The relative effectiveness of human tutoring, intelligent tutoring systems, \\nand other tutoring systems. Educational Psychologist, 46(4), 197-221. \\nhttps://doi.org/10.1080/00461520.2011.611369'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 70, 'page_label': '71', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='and other tutoring systems. Educational Psychologist, 46(4), 197-221. \\nhttps://doi.org/10.1080/00461520.2011.611369 \\nWagner, A.R., Borenstein, J. & Howard, A. (September 2018). Overtrust in the robotics age. \\nCommunications of the ACM, 61(9), 22-24. https://doi.org/10.1145/3241365 \\nWalker, E., Rummel, N. & Koedinger, K.R. (2015). Adaptive intelligent support to improve peer \\ntutoring in algebra. International Journal of Artificial Intelligence in Education, 24, 33–61 \\nhttps://doi.org/10.1007/s40593-013-0001-9 \\nWalton Family Foundation (March 1, 2023). Teachers and students embrace ChatGPT for education. \\nhttps://www.waltonfamilyfoundation.org/learning/teachers-and-students-embrace-\\nchatgpt-for-education \\nWebb, N.M., & Farivar, S. (1994). Promoting helping behavior in cooperative small groups in \\nmiddle school mathematics. American Educational Research Journal, 31(2), 369–395. \\nhttps://doi.org/10.3102/00028312031002369'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 70, 'page_label': '71', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='middle school mathematics. American Educational Research Journal, 31(2), 369–395. \\nhttps://doi.org/10.3102/00028312031002369 \\nWhite House Office of Science and Technology Policy (October 2022), Blueprint for an AI bill of \\nrights: Making automated systems work for the American people. The White House Office of \\nScience and Technology Policy. https://www.whitehouse.gov/ostp/ai-bill-of-rights/  \\nWiggins, G. (2015). Seven keys to effective feedback. ACSD. https://www.ascd.org/el/articles/seven-\\nkeys-to-effective-feedback \\nWinne, P.H. (2021). Open learner models working in symbiosis with self-regulating learners: A \\nresearch agenda. International Journal of Artificial Intelligence in Education, 31(3), 446-459. \\nhttps://doi.org/10.1007/s40593-020-00212-4 \\nZacamy, J. & Roschelle, J. (2022). Navigating the tensions: How could equity-relevant research also be \\nagile, open, and scalable? Digital Promise. http://hdl.handle.net/20.500.12265/159'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-05-02T18:36:15+00:00', 'author': 'U.S. Department of Education', 'moddate': '2023-05-22T15:08:44-04:00', 'title': 'Artificial Intelligence and the Future of Teaching and Learning (PDF)', 'source': '..\\\\data\\\\pdf\\\\ai-report.pdf', 'total_pages': 71, 'page': 70, 'page_label': '71', 'source_file': 'ai-report.pdf', 'file_type': 'pdf'}, page_content='Zacamy, J. & Roschelle, J. (2022). Navigating the tensions: How could equity-relevant research also be \\nagile, open, and scalable? Digital Promise. http://hdl.handle.net/20.500.12265/159 \\nZhai, X., He, P., Krajcik, J. (2022). Applying machine learning to automatically assess scientific \\nmodels. Journal of Research in Science Teaching. https://doi.org/10.1002/tea.21773 \\nZhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., & Breazeal, C. (2022). Integrating ethics and \\ncareer futures with technical learning to promote AI literacy for middle school students: \\nAn exploratory study. International Journal of Artificial Intelligence in Education, 1–35. \\nhttps://doi.org/10.1007/s40593-022-00293-3'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 0, 'page_label': '1', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='Attention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser ∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 0, 'page_label': '1', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='entirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.0 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature.\\n1 Introduction\\nRecurrent neural networks, long short-term memory [12] and gated recurrent [7] neural networks\\nin particular, have been ﬁrmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 29, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 0, 'page_label': '1', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='transduction problems such as language modeling and machine translation [ 29, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [31, 21, 13].\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 0, 'page_label': '1', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='efﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 1, 'page_label': '2', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='Recurrent models typically factor computation along the symbol positions of the input and output\\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\\nstates ht, as a function of the previous hidden state ht−1 and the input for position t. This inherently\\nsequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsigniﬁcant improvements in computational efﬁciency through factorization tricks [18] and conditional\\ncomputation [26], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 1, 'page_label': '2', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='Attention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [2, 16]. In all but a few cases [22], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for signiﬁcantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2 Background\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[20], ByteNet [15] and ConvS2S [8], all of which use convolutional neural networks as basic building'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 1, 'page_label': '2', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='The goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[20], ByteNet [15] and ConvS2S [8], all of which use convolutional neural networks as basic building\\nblock, computing hidden representations in parallel for all input and output positions. In these models,\\nthe number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difﬁcult to learn dependencies between distant positions [ 11]. In the Transformer this is\\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribed in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 1, 'page_label': '2', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='described in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 22, 23, 19].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [28].\\nTo the best of our knowledge, however, the Transformer is the ﬁrst transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 1, 'page_label': '2', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [14, 15] and [8].\\n3 Model Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 29].\\nHere, the encoder maps an input sequence of symbol representations (x1,...,x n) to a sequence\\nof continuous representations z = (z1,...,z n). Given z, the decoder then generates an output\\nsequence (y1,...,y m) of symbols one element at a time. At each step the model is auto-regressive\\n[9], consuming the previously generated symbols as additional input when generating the next.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1 Encoder and Decoder Stacks'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 1, 'page_label': '2', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1 Encoder and Decoder Stacks\\nEncoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. The ﬁrst is a multi-head self-attention mechanism, and the second is a simple, position-\\n2'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 2, 'page_label': '3', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='Figure 1: The Transformer - model architecture.\\nwise fully connected feed-forward network. We employ a residual connection [10] around each of\\nthe two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\\nLayerNorm(x+ Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.\\nDecoder: The decoder is also composed of a stack of N = 6identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 2, 'page_label': '3', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='around each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\\npredictions for position ican depend only on the known outputs at positions less than i.\\n3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1 Scaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\n3'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 3, 'page_label': '4', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='Scaled Dot-Product Attention\\n Multi-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nquery with all keys, divide each by √dk, and apply a softmax function to obtain the weights on the\\nvalues.\\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\\ninto a matrix Q. The keys and values are also packed together into matrices Kand V. We compute\\nthe matrix of outputs as:\\nAttention(Q,K,V ) = softmax(QKT\\n√dk\\n)V (1)\\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\\nof 1√dk\\n. Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 3, 'page_label': '4', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='of 1√dk\\n. Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\\nmuch faster and more space-efﬁcient in practice, since it can be implemented using highly optimized\\nmatrix multiplication code.\\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\\ndot product attention without scaling for larger values of dk [3]. We suspect that for large values of\\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\\nextremely small gradients 4. To counteract this effect, we scale the dot products by 1√dk\\n.\\n3.2.2 Multi-Head Attention\\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,\\nwe found it beneﬁcial to linearly project the queries, keys and values htimes with different, learned'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 3, 'page_label': '4', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='we found it beneﬁcial to linearly project the queries, keys and values htimes with different, learned\\nlinear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of\\nqueries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\\noutput values. These are concatenated and once again projected, resulting in the ﬁnal values, as\\ndepicted in Figure 2.\\nMulti-head attention allows the model to jointly attend to information from different representation\\nsubspaces at different positions. With a single attention head, averaging inhibits this.\\n4To illustrate why the dot products get large, assume that the components of q and k are independent random\\nvariables with mean 0 and variance 1. Then their dot product, q · k = ∑dk\\ni=1 qiki, has mean 0 and variance dk.\\n4'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 4, 'page_label': '5', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='MultiHead(Q,K,V ) = Concat(head1,..., headh)WO\\nwhere headi = Attention(QWQ\\ni ,KW K\\ni ,VW V\\ni )\\nWhere the projections are parameter matricesWQ\\ni ∈Rdmodel×dk , WK\\ni ∈Rdmodel×dk , WV\\ni ∈Rdmodel×dv\\nand WO ∈Rhdv×dmodel .\\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\\ndk = dv = dmodel/h= 64. Due to the reduced dimension of each head, the total computational cost\\nis similar to that of single-head attention with full dimensionality.\\n3.2.3 Applications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[31, 2, 8].'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 4, 'page_label': '5', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='position in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[31, 2, 8].\\n• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\\nand queries come from the same place, in this case, the output of the previous layer in the\\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder.\\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward\\ninformation ﬂow in the decoder to preserve the auto-regressive property. We implement this\\ninside of scaled dot-product attention by masking out (setting to −∞) all values in the input\\nof the softmax which correspond to illegal connections. See Figure 2.\\n3.3 Position-wise Feed-Forward Networks'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 4, 'page_label': '5', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='of the softmax which correspond to illegal connections. See Figure 2.\\n3.3 Position-wise Feed-Forward Networks\\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\\nconnected feed-forward network, which is applied to each position separately and identically. This\\nconsists of two linear transformations with a ReLU activation in between.\\nFFN(x) = max(0,xW1 + b1)W2 + b2 (2)\\nWhile the linear transformations are the same across different positions, they use different parameters\\nfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.\\nThe dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality\\ndff = 2048.\\n3.4 Embeddings and Softmax\\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input\\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 4, 'page_label': '5', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='Similarly to other sequence transduction models, we use learned embeddings to convert the input\\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\\nmation and softmax function to convert the decoder output to predicted next-token probabilities. In\\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\\nlinear transformation, similar to [24]. In the embedding layers, we multiply those weights by √dmodel.\\n3.5 Positional Encoding\\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\\norder of the sequence, we must inject some information about the relative or absolute position of the\\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\\n5'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 5, 'page_label': '6', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\\nfor different layer types. nis the sequence length, dis the representation dimension, kis the kernel\\nsize of convolutions and rthe size of the neighborhood in restricted self-attention.\\nLayer Type Complexity per Layer Sequential Maximum Path Length\\nOperations\\nSelf-Attention O(n2 ·d) O(1) O(1)\\nRecurrent O(n·d2) O(n) O(n)\\nConvolutional O(k·n·d2) O(1) O(logk(n))\\nSelf-Attention (restricted) O(r·n·d) O(1) O(n/r)\\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\\nas the embeddings, so that the two can be summed. There are many choices of positional encodings,\\nlearned and ﬁxed [8].\\nIn this work, we use sine and cosine functions of different frequencies:\\nPE(pos,2i) = sin(pos/100002i/dmodel )\\nPE(pos,2i+1) = cos(pos/100002i/dmodel )\\nwhere posis the position and iis the dimension. That is, each dimension of the positional encoding'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 5, 'page_label': '6', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='PE(pos,2i) = sin(pos/100002i/dmodel )\\nPE(pos,2i+1) = cos(pos/100002i/dmodel )\\nwhere posis the position and iis the dimension. That is, each dimension of the positional encoding\\ncorresponds to a sinusoid. The wavelengths form a geometric progression from 2πto 10000 ·2π. We\\nchose this function because we hypothesized it would allow the model to easily learn to attend by\\nrelative positions, since for any ﬁxed offset k, PEpos+k can be represented as a linear function of\\nPEpos.\\nWe also experimented with using learned positional embeddings [8] instead, and found that the two\\nversions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version\\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\\nduring training.\\n4 Why Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 5, 'page_label': '6', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='during training.\\n4 Why Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one variable-length sequence of symbol representations\\n(x1,...,x n) to another sequence of equal length (z1,...,z n), with xi,zi ∈Rd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\\nconsider three desiderata.\\nOne is the total computational complexity per layer. Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.\\nThe third is the path length between long-range dependencies in the network. Learning long-range\\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 5, 'page_label': '6', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='dependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to\\ntraverse in the network. The shorter these paths between any combination of positions in the input\\nand output sequences, the easier it is to learn long-range dependencies [11]. Hence we also compare\\nthe maximum path length between any two input and output positions in networks composed of the\\ndifferent layer types.\\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially\\nexecuted operations, whereas a recurrent layer requires O(n) sequential operations. In terms of\\ncomputational complexity, self-attention layers are faster than recurrent layers when the sequence\\nlength n is smaller than the representation dimensionality d, which is most often the case with'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 5, 'page_label': '6', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='computational complexity, self-attention layers are faster than recurrent layers when the sequence\\nlength n is smaller than the representation dimensionality d, which is most often the case with\\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\\n[31] and byte-pair [25] representations. To improve computational performance for tasks involving\\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size rin\\n6'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 6, 'page_label': '7', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='the input sequence centered around the respective output position. This would increase the maximum\\npath length to O(n/r). We plan to investigate this approach further in future work.\\nA single convolutional layer with kernel width k<n does not connect all pairs of input and output\\npositions. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels,\\nor O(logk(n)) in the case of dilated convolutions [ 15], increasing the length of the longest paths\\nbetween any two positions in the network. Convolutional layers are generally more expensive than\\nrecurrent layers, by a factor of k. Separable convolutions [ 6], however, decrease the complexity\\nconsiderably, to O(k·n·d+ n·d2). Even with k = n, however, the complexity of a separable\\nconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 6, 'page_label': '7', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='convolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.\\nAs side beneﬁt, self-attention could yield more interpretable models. We inspect attention distributions\\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\\nand semantic structure of the sentences.\\n5 Training\\nThis section describes the training regime for our models.\\n5.1 Training Data and Batching\\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\\nsentence pairs. Sentences were encoded using byte-pair encoding [ 3], which has a shared source-\\ntarget vocabulary of about 37000 tokens. For English-French, we used the signiﬁcantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 6, 'page_label': '7', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='target vocabulary of about 37000 tokens. For English-French, we used the signiﬁcantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\\nvocabulary [31]. Sentence pairs were batched together by approximate sequence length. Each training\\nbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000\\ntarget tokens.\\n5.2 Hardware and Schedule\\nWe trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We\\ntrained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the\\nbottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps\\n(3.5 days).\\n5.3 Optimizer\\nWe used the Adam optimizer [17] with β1 = 0.9, β2 = 0.98 and ϵ= 10−9. We varied the learning\\nrate over the course of training, according to the formula:'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 6, 'page_label': '7', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='(3.5 days).\\n5.3 Optimizer\\nWe used the Adam optimizer [17] with β1 = 0.9, β2 = 0.98 and ϵ= 10−9. We varied the learning\\nrate over the course of training, according to the formula:\\nlrate= d−0.5\\nmodel ·min(step_num−0.5,step_num·warmup_steps−1.5) (3)\\nThis corresponds to increasing the learning rate linearly for the ﬁrst warmup_stepstraining steps,\\nand decreasing it thereafter proportionally to the inverse square root of the step number. We used\\nwarmup_steps= 4000.\\n5.4 Regularization\\nWe employ three types of regularization during training:\\nResidual Dropout We apply dropout [27] to the output of each sub-layer, before it is added to the\\nsub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the\\npositional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\\nPdrop = 0.1.\\n7'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 7, 'page_label': '8', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\\nModel\\nBLEU Training Cost (FLOPs)\\nEN-DE EN-FR EN-DE EN-FR\\nByteNet [15] 23.75\\nDeep-Att + PosUnk [32] 39.2 1.0 ·1020\\nGNMT + RL [31] 24.6 39.92 2.3 ·1019 1.4 ·1020\\nConvS2S [8] 25.16 40.46 9.6 ·1018 1.5 ·1020\\nMoE [26] 26.03 40.56 2.0 ·1019 1.2 ·1020\\nDeep-Att + PosUnk Ensemble [32] 40.4 8.0 ·1020\\nGNMT + RL Ensemble [31] 26.30 41.16 1.8 ·1020 1.1 ·1021\\nConvS2S Ensemble [8] 26.36 41.29 7.7 ·1019 1.2 ·1021\\nTransformer (base model) 27.3 38.1 3.3 · 1018\\nTransformer (big) 28.4 41.0 2.3 ·1019\\nLabel Smoothing During training, we employed label smoothing of value ϵls = 0.1 [30]. This\\nhurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\\n6 Results\\n6.1 Machine Translation\\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 7, 'page_label': '8', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='6 Results\\n6.1 Machine Translation\\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\\nin Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The conﬁguration of this model is\\nlisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model\\nsurpasses all previously published models and ensembles, at a fraction of the training cost of any of\\nthe competitive models.\\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\\noutperforming all of the previously published single models, at less than 1/4 the training cost of the\\nprevious state-of-the-art model. The Transformer (big) model trained for English-to-French used\\ndropout rate Pdrop = 0.1, instead of 0.3.\\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 7, 'page_label': '8', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='dropout rate Pdrop = 0.1, instead of 0.3.\\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which\\nwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We\\nused beam search with a beam size of 4 and length penalty α= 0.6 [31]. These hyperparameters\\nwere chosen after experimentation on the development set. We set the maximum output length during\\ninference to input length + 50, but terminate early when possible [31].\\nTable 2 summarizes our results and compares our translation quality and training costs to other model\\narchitectures from the literature. We estimate the number of ﬂoating point operations used to train a\\nmodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained\\nsingle-precision ﬂoating-point capacity of each GPU 5.\\n6.2 Model Variations\\nTo evaluate the importance of different components of the Transformer, we varied our base model'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 7, 'page_label': '8', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='single-precision ﬂoating-point capacity of each GPU 5.\\n6.2 Model Variations\\nTo evaluate the importance of different components of the Transformer, we varied our base model\\nin different ways, measuring the change in performance on English-to-German translation on the\\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no\\ncheckpoint averaging. We present these results in Table 3.\\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\\n5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.\\n8'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 8, 'page_label': '9', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\\nmodel. All metrics are on the English-to-German translation development set, newstest2013. Listed\\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\\nper-word perplexities.\\nN d model dff h d k dv Pdrop ϵls\\ntrain PPL BLEU params\\nsteps (dev) (dev) ×106\\nbase 6 512 2048 8 64 64 0.1 0.1 100K 4.92 25.8 65\\n(A)\\n1 512 512 5.29 24.9\\n4 128 128 5.00 25.5\\n16 32 32 4.91 25.8\\n32 16 16 5.01 25.4\\n(B) 16 5.16 25.1 58\\n32 5.01 25.4 60\\n(C)\\n2 6.11 23.7 36\\n4 5.19 25.3 50\\n8 4.88 25.5 80\\n256 32 32 5.75 24.5 28\\n1024 128 128 4.66 26.0 168\\n1024 5.12 25.4 53\\n4096 4.75 26.2 90\\n(D)\\n0.0 5.77 24.6\\n0.2 4.95 25.5\\n0.0 4.67 25.3\\n0.2 5.47 25.7\\n(E) positional embedding instead of sinusoids 4.92 25.7\\nbig 6 1024 4096 16 0.3 300K 4.33 26.4 213\\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 8, 'page_label': '9', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='(E) positional embedding instead of sinusoids 4.92 25.7\\nbig 6 1024 4096 16 0.3 300K 4.33 26.4 213\\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This\\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\\nfunction than dot product may be beneﬁcial. We further observe in rows (C) and (D) that, as expected,\\nbigger models are better, and dropout is very helpful in avoiding over-ﬁtting. In row (E) we replace our\\nsinusoidal positional encoding with learned positional embeddings [8], and observe nearly identical\\nresults to the base model.\\n7 Conclusion\\nIn this work, we presented the Transformer, the ﬁrst sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained signiﬁcantly faster than architectures based'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 8, 'page_label': '9', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='multi-headed self-attention.\\nFor translation tasks, the Transformer can be trained signiﬁcantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\\nmodel outperforms even all previously reported ensembles.\\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efﬁciently handle large inputs and outputs\\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\\nThe code we used to train and evaluate our models is available at https://github.com/\\ntensorflow/tensor2tensor.\\nAcknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 8, 'page_label': '9', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='tensorflow/tensor2tensor.\\nAcknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\\ncomments, corrections and inspiration.\\n9'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 9, 'page_label': '10', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='References\\n[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\\narXiv:1607.06450, 2016.\\n[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\\nlearning to align and translate. CoRR, abs/1409.0473, 2014.\\n[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V . Le. Massive exploration of neural\\nmachine translation architectures. CoRR, abs/1703.03906, 2017.\\n[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\\nreading. arXiv preprint arXiv:1601.06733, 2016.\\n[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,\\nand Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical\\nmachine translation. CoRR, abs/1406.1078, 2014.\\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\\npreprint arXiv:1610.02357, 2016.'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 9, 'page_label': '10', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='machine translation. CoRR, abs/1406.1078, 2014.\\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\\npreprint arXiv:1610.02357, 2016.\\n[7] Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation\\nof gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\\n[8] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-\\ntional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\\n[9] Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint\\narXiv:1308.0850, 2013.\\n[10] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\\nRecognition, pages 770–778, 2016.\\n[11] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient ﬂow in'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 9, 'page_label': '10', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='Recognition, pages 770–778, 2016.\\n[11] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient ﬂow in\\nrecurrent nets: the difﬁculty of learning long-term dependencies, 2001.\\n[12] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation,\\n9(8):1735–1780, 1997.\\n[13] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring\\nthe limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\\n[14] Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\\non Learning Representations (ICLR), 2016.\\n[15] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\\nray Kavukcuoglu. Neural machine translation in linear time.arXiv preprint arXiv:1610.10099v2,\\n2017.\\n[16] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 9, 'page_label': '10', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='2017.\\n[16] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.\\n[17] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\\n[18] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\\narXiv:1703.10722, 2017.\\n[19] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130, 2017.\\n[20] Samy Bengio Łukasz Kaiser. Can active memory replace attention? In Advances in Neural\\nInformation Processing Systems, (NIPS), 2016.\\n10'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 10, 'page_label': '11', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='[21] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\\nbased neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\\n[22] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention\\nmodel. In Empirical Methods in Natural Language Processing, 2016.\\n[23] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\\nsummarization. arXiv preprint arXiv:1705.04304, 2017.\\n[24] Oﬁr Press and Lior Wolf. Using the output embedding to improve language models. arXiv\\npreprint arXiv:1608.05859, 2016.\\n[25] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words\\nwith subword units. arXiv preprint arXiv:1508.07909, 2015.\\n[26] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,\\nand Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\\nlayer. arXiv preprint arXiv:1701.06538, 2017.'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 10, 'page_label': '11', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='and Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\\nlayer. arXiv preprint arXiv:1701.06538, 2017.\\n[27] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\\nnov. Dropout: a simple way to prevent neural networks from overﬁtting. Journal of Machine\\nLearning Research, 15(1):1929–1958, 2014.\\n[28] Sainbayar Sukhbaatar, arthur szlam, Jason Weston, and Rob Fergus. End-to-end memory\\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,\\nAdvances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates,\\nInc., 2015.\\n[29] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural\\nnetworks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\\n[30] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.'),\n",
       " Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '..\\\\data\\\\pdf\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 10, 'page_label': '11', 'source_file': 'NIPS-2017-attention-is-all-you-need-Paper.pdf', 'file_type': 'pdf'}, page_content='networks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\\n[30] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.\\nRethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\\n[31] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\\nMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine\\ntranslation system: Bridging the gap between human and machine translation. arXiv preprint\\narXiv:1609.08144, 2016.\\n[32] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\\nfast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\\n11')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = split_documents(all_pdf_documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53187b1a",
   "metadata": {},
   "source": [
    "### Embedding and VectorStoreDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "590f400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88607132",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using SentenceTransformer\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initialize the embedding manager\n",
    "        \n",
    "        Args:\n",
    "            model_name: HuggingFace model name for sentence embeddings\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the SentenceTransformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts\n",
    "        \n",
    "        Args:\n",
    "            texts: List of text strings to embed\n",
    "\n",
    "        Returns:\n",
    "            numpy array of embeddings with shape (len(texts), embedding_dim)\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        \n",
    "        print(f\"Generating embeddings for {len(texts)} texts...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "    \n",
    "    # def get_embedding_dimension(self) -> int:\n",
    "    #     \"\"\"Get the embedding dimension of the model\"\"\"\n",
    "    #     if not self.model:\n",
    "    #         raise ValueError(\"Model not loaded\")\n",
    "    #     return self.model.get_sentence_embedding_dimension()\n",
    "\n",
    "    ### Initialze the embedding manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c6fa9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "Model loaded successfully. Embedding dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x228a91f77a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_manager = EmbeddingManager()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1ebdea",
   "metadata": {},
   "source": [
    "### VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cf4bf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized. Collection: pdf_documents\n",
      "Existing documents in collection: 0\n"
     ]
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Manages document embeddings in a ChromaDB vector store\"\"\"\n",
    "\n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store\"):\n",
    "        \"\"\"\n",
    "        Initialize the vector store\n",
    "        \n",
    "        Args:\n",
    "            collection_name: Name of the ChromaDB collection\n",
    "            persist_directory: Directory to persist the vector store\n",
    "        \"\"\"\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "    \n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize ChromaDB client and collection\"\"\"\n",
    "        try:\n",
    "            # Create persistent ChromaDB client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "\n",
    "            # Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\": \"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents: List[any], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Add documents and their embeddings to the vector store\n",
    "        \n",
    "        Args:\n",
    "            documents: List of Langchain documents\n",
    "            embeddings: Corresponding embeddings for the documents\n",
    "        \"\"\"\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "\n",
    "        # Prepare data for ChromaDB\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "\n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # Generate unique ID\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            # Prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            # Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "\n",
    "            # Embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "        \n",
    "        # Add to collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "vectorstore = VectorStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26f4b929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 \\n \\n \\nArtificial Intelligence \\nand the Future of \\nTeaching and Learning \\nInsights and Recommendations \\nMay 2023',\n",
       " 'Artificial Intelligence and the Future of Teaching and Learning \\nMiguel A. Cardona, Ed.D. \\nSecretary, U.S. Department of Education \\nRoberto J. Rodríguez \\nAssistant Secretary, Office of Planning, Evaluation, and Policy Development \\nKristina Ishmael \\nDeputy Director, Office of Educational Technology \\nMay 2023 \\n \\nExamples Are Not Endorsements \\nThis document contains examples and resource materials that are provided for the user’s \\nconvenience. The inclusion of any material is not intended to reflect its importance nor is it \\nintended to endorse any views expressed or products or services offered. These materials may \\ncontain the views and recommendations of various subject matter experts as well as hypertext links, \\ncontact addresses, and websites to information created and maintained by other public and private \\norganizations. The opinions expressed in any of these materials do not necessarily reflect the',\n",
       " 'contact addresses, and websites to information created and maintained by other public and private \\norganizations. The opinions expressed in any of these materials do not necessarily reflect the \\npositions or policies of the U.S. Department of Education. The U.S. Department of Education does \\nnot control or guarantee the accuracy, relevance, timeliness, or completeness of any information \\nfrom other sources that are included in these materials. Other than statutory and regulatory \\nrequirements included in the document, the contents of this guidance do not have the force and \\neffect of law and are not meant to bind the public. \\nContracts and Procurement \\nThis document is not intended to provide legal advice or approval of any potential federal \\ncontractor’s business decision or strategy in relation to any current or future federal procurement \\nand/or contract. Further, this document is not an invitation for bid, request for proposal, or other \\nsolicitation. \\nLicensing and Availability',\n",
       " 'and/or contract. Further, this document is not an invitation for bid, request for proposal, or other \\nsolicitation. \\nLicensing and Availability \\nThis report is in the public domain and available on the U.S. Department of Education’s \\n(Department’s) website at https://tech.ed.gov. \\nRequests for alternate format documents such as Braille or large print should be submitted to the \\nAlternate Format Center by calling 1-202-260-0852 or by contacting the 504 coordinator via email \\nat om_eeos@ed.gov. \\nNotice to Limited English Proficient Persons \\nIf you have difficulty understanding English, you may request language assistance services for \\nDepartment information that is available to the public. These language assistance services are \\navailable free of charge. If you need more information about interpretation or translation services, \\nplease call 1-800-USA-LEARN (1-800-872-5327) (TTY: 1-800-437-0833); email us at',\n",
       " 'available free of charge. If you need more information about interpretation or translation services, \\nplease call 1-800-USA-LEARN (1-800-872-5327) (TTY: 1-800-437-0833); email us at \\nEd.Language.Assistance@ed.gov; or write to U.S. Department of Education, Information Resource \\nCenter, LBJ Education Building, 400 Maryland Ave. SW, Washington, DC 20202. \\nHow to Cite \\nWhile permission to reprint this publication is not necessary, the suggested citation is as follows:  \\nU.S. Department of Education, Office of Educational Technology, Artificial Intelligence and \\nFuture of Teaching and Learning: Insights and Recommendations, Washington, DC, 2023.  \\nThis report is available at https://tech.ed.gov',\n",
       " 'Table of Contents \\nIntroduction ................................ ................................ ................................ ..........................  1 \\nRising Interest in AI in Education ......................................................................................................................................................... 1 \\nThree Reasons to Address AI in Education Now................................................................................................................... 2 \\nToward Policies for AI in Education .................................................................................................................................................. 3 \\nBuilding Ethical, Equitable Policies Together................................ ........................  6',\n",
       " 'Building Ethical, Equitable Policies Together................................ ........................  6 \\nGuiding Questions ........................................................................................................................................................................................... 6 \\nFoundation 1: Center People (Parents, Educators, and Students) ......................................................................... 6 \\nFoundation 2: Advance Equity...............................................................................................................................................................7 \\nFoundation 3: Ensure Safety, Ethics, and Effectiveness ................................................................................................ 8 \\nFoundation 4: Promote Transparency ........................................................................................................................................... 9',\n",
       " 'Foundation 4: Promote Transparency ........................................................................................................................................... 9 \\nOverview of Document ............................................................................................................................................................................ 10 \\nWhat is AI? ................................ ................................ ................................ ..........................  11 \\nPerspective: Human-Like Reasoning ........................................................................................................................................... 12 \\nPerspective: An Algorithm that Pursues a Goal................................................................................................................... 12',\n",
       " 'Perspective: An Algorithm that Pursues a Goal................................................................................................................... 12 \\nPerspective: Intelligence Augmentation ................................................................................................................................... 14 \\nDefinition of “Model”.................................................................................................................................................................................... 14 \\nInsight: AI Systems Enable New Forms of Interaction ................................................................................................... 15 \\nKey Recommendation: Human in the Loop AI ..................................................................................................................... 16',\n",
       " 'Key Recommendation: Human in the Loop AI ..................................................................................................................... 16 \\nLearning ................................ ................................ ................................ ..............................  18 \\nInsight: AI Enables Adaptivity in Learning................................................................................................................................. 18 \\nIntelligent Tutoring Systems: An Example of AI Models ............................................................................................. 19 \\nImportant Directions for Expanding AI-Based Adaptivity .......................................................................................... 20 \\nA Duality: Learning With and About AI ........................................................................................................................................ 22',\n",
       " 'A Duality: Learning With and About AI ........................................................................................................................................ 22 \\nA Challenge: Systems Thinking About AI in Education ................................................................................................. 22 \\nOpen Questions About AI for Learning ....................................................................................................................................... 23 \\nKey Recommendation: Seek AI Models Aligned to a Vision for Learning .................................................... 24 \\nTeaching ................................ ................................ ................................ .............................  25 \\nAlways Center Educators in Instructional Loops ............................................................................................................... 25',\n",
       " 'Always Center Educators in Instructional Loops ............................................................................................................... 25 \\nInsight: Using AI to Improve Teaching Jobs .......................................................................................................................... 26 \\nPreparing and Supporting Teachers in Planning and Reflecting ........................................................................ 29 \\nDesigning, Selecting, and Evaluating AI Tools .................................................................................................................... 30 \\nChallenge: Balancing Human and Computer Decision-Making .......................................................................... 30 \\nChallenge: Making Teaching Jobs Easier While Avoiding Surveillance ........................................................ 31',\n",
       " 'Challenge: Making Teaching Jobs Easier While Avoiding Surveillance ........................................................ 31 \\nChallenge: Responding to Students’ Strengths While Protecting Their Privacy .................................... 32 \\nQuestions Worth Asking About AI for Teaching .................................................................................................................34 \\nKey Recommendation: Inspectable, Explainable, Overridable AI .......................................................................34',\n",
       " 'Formative Assessment ................................ ................................ ................................ . 37 \\nBuilding on Best Practices ..................................................................................................................................................................... 37 \\nImplications for Teaching and Learning ................................................................................................................................... 38 \\nInsight: AI Can Enhance Feedback Loops ............................................................................................................................... 39 \\nAn Example: Automated Essay Scoring .................................................................................................................................... 40 \\nKey Opportunities for AI in Formative Assessment ......................................................................................................... 41',\n",
       " 'Key Opportunities for AI in Formative Assessment ......................................................................................................... 41 \\nKey Recommendation: Harness Assessment Expertise to Reduce Bias ...................................................... 42 \\nRelated Questions.........................................................................................................................................................................................43 \\nResearch and Development ................................ ................................ .......................  44 \\nInsight: Research Can Strengthen the Role of Context in AI ....................................................................................44 \\nAttention to the Long Tail of Learner Variability ................................................................................................................ 46',\n",
       " 'Attention to the Long Tail of Learner Variability ................................................................................................................ 46 \\nPartnership in Design-Based Research ......................................................................................................................................47 \\nRe-thinking Teacher Professional Development .............................................................................................................. 48 \\nConnecting with Public Policy ........................................................................................................................................................... 49 \\nKey Recommendation: Focus R&D on Addressing Context.................................................................................... 50',\n",
       " 'Key Recommendation: Focus R&D on Addressing Context.................................................................................... 50 \\nOngoing Questions for Researchers ............................................................................................................................................ 50 \\nDesired National R&D Objectives .................................................................................................................................................... 51 \\nRecommendations ................................ ................................ ................................ .........  52 \\nInsight: Aligning AI to Policy Objectives ..................................................................................................................................... 52 \\nCalling Education Leaders to Action ............................................................................................................................................ 53',\n",
       " 'Calling Education Leaders to Action ............................................................................................................................................ 53 \\nRecommendation #1: Emphasize Humans in the Loop ............................................................................................... 53 \\nRecommendation #2: Align AI Models to a Shared Vision for Education .....................................................54 \\nRecommendation #3: Design Using Modern Learning Principles ..................................................................... 56 \\nRecommendation #4: Prioritize Strengthening Trust .....................................................................................................57 \\nRecommendation #5: Inform and Involve Educators ....................................................................................................57 \\nRecommendation #6: Focus R&D on Addressing Context and Enhancing Trust and Safety .... 59',\n",
       " 'Recommendation #6: Focus R&D on Addressing Context and Enhancing Trust and Safety .... 59 \\nRecommendation #7: Develop Education-Specific Guidelines and Guardrails..................................... 60 \\nNext Steps .......................................................................................................................................................................................................... 60 \\nCommon Acronyms and Abbreviations ................................ ................................ . 62 \\nAcknowledgements ................................ ................................ ................................ .......  63 \\nReferences................................ ................................ ................................ .........................  64',\n",
       " '1 \\nIntroduction \\nThe U.S. Department of Education (Department) is committed to supporting the use of \\ntechnology to improve teaching and learning and to support innovation throughout educational \\nsystems. This report addresses the clear need for sharing knowledge and developing policies for \\n“Artificial Intelligence,” a rapidly advancing class of foundational capabilities which are \\nincreasingly embedded in all types of educational technology systems and are also available to \\nthe public. We will consider “educational technology” (edtech) to include both (a) technologies \\nspecifically designed for educational use, as well as (b) general technologies that are widely used \\nin educational settings. Recommendations in this report seek to engage teachers, educational \\nleaders, policy makers, researchers, and educational technology innovators and providers as they \\nwork together on pressing policy issues that arise as Artificial Intelligence (AI) is used in \\neducation.',\n",
       " 'work together on pressing policy issues that arise as Artificial Intelligence (AI) is used in \\neducation.  \\nAI can be defined as “automation based on associations.” When computers automate reasoning \\nbased on associations in data (or associations deduced from expert knowledge), two shifts \\nfundamental to AI occur and shift computing beyond conventional edtech: (1) from capturing \\ndata to detecting patterns in data and (2) from providing access to instructional resources to \\nautomating decisions about instruction and other educational processes. Detecting patterns and \\nautomating decisions are leaps in the level of responsibilities that can be delegated to a computer \\nsystem. The process of developing an AI system may lead to bias in how patterns are detected \\nand unfairness in how decisions are automated. Thus, educational systems must govern their use \\nof AI systems. This report describes opportunities for using AI to improve education, recognizes',\n",
       " 'and unfairness in how decisions are automated. Thus, educational systems must govern their use \\nof AI systems. This report describes opportunities for using AI to improve education, recognizes \\nchallenges that will arise, and develops recommendations to guide further policy development.  \\nRising Interest in AI in Education  \\nToday, many priorities for improvements to teaching and learning are unmet. Educators seek \\ntechnology-enhanced approaches addressing these priorities that would be safe, effective, and \\nscalable. Naturally, educators wonder if the rapid advances in technology in everyday lives could \\nhelp. Like all of us, educators use AI-powered services in their everyday lives, such as voice \\nassistants in their homes; tools that can correct grammar, complete sentences, and write essays; \\nand automated trip planning on their phones. Many educators are actively exploring AI tools as',\n",
       " 'assistants in their homes; tools that can correct grammar, complete sentences, and write essays; \\nand automated trip planning on their phones. Many educators are actively exploring AI tools as \\nthey are newly released to the public1. Educators see opportunities to use AI-powered capabilities \\nlike speech recognition to increase the support available to students with disabilities, multilingual \\nlearners, and others who could benefit from greater adaptivity and personalization in digital \\ntools for learning. They are exploring how AI can enable writing or improving lessons, as well as \\ntheir process for finding, choosing, and adapting material for use in their lessons.  \\nEducators are also aware of new risks. Useful, powerful functionality can also be accompanied \\nwith new data privacy and security risks. Educators recognize that AI can automatically produce \\noutput that is inappropriate or wrong. They are wary that the associations or automations',\n",
       " 'with new data privacy and security risks. Educators recognize that AI can automatically produce \\noutput that is inappropriate or wrong. They are wary that the associations or automations \\ncreated by AI may amplify unwanted biases. They have noted new ways in which students may \\n \\n1 Walton Family Foundation (March 1, 2023). Teachers and students embrace ChatGPT for education. \\nhttps://www.waltonfamilyfoundation.org/learning/teachers-and-students-embrace-chatgpt-for-education',\n",
       " '2 \\nrepresent others’ work as their own. They are well-aware of “teachable moments” and \\npedagogical strategies that a human teacher can address but are undetected or misunderstood by \\nAI models. They worry whether recommendations suggested by an algorithm would be fair. \\nEducators’ concerns are manifold. Everyone in education has a responsibility to harness the \\ngood to serve educational priorities while also protecting against the dangers that may arise as a \\nresult of AI being integrated in edtech. \\nTo develop guidance for edtech, the Department works closely with educational constituents. \\nThese constituents include educational leaders—teachers, faculty, support staff, and other \\neducators—researchers; policymakers; advocates and funders; technology developers; \\ncommunity members and organizations; and, above all, learners and their families/caregivers. \\nRecently, through its activities with constituents, the Department noticed a sharp rise in interest',\n",
       " 'community members and organizations; and, above all, learners and their families/caregivers. \\nRecently, through its activities with constituents, the Department noticed a sharp rise in interest \\nand concern about AI. For example, a 2021 field scan found that developers of all kinds of \\ntechnology systems—for student information, classroom instruction, school logistics, parent-\\nteacher communication, and more—expect to add AI capabilities to their systems. Through a \\nseries of four listening sessions conducted in June and August 2022 and attended by more than \\n700 attendees, it became clear that constituents believe that action is required now in order to get \\nahead of the expected increase of AI in education technology—and they want to roll up their \\nsleeves and start working together. In late 2022 and early 2023, the public became aware of new \\ngenerative AI chatbots and began to explore how AI could be used to write essays, create lesson',\n",
       " 'sleeves and start working together. In late 2022 and early 2023, the public became aware of new \\ngenerative AI chatbots and began to explore how AI could be used to write essays, create lesson \\nplans, produce images, create personalized assignments for students, and more. From public \\nexpression in social media, at conferences, and in news media, the Department learned more \\nabout risks and benefits of AI-enabled chatbots. And yet this report will not focus on a specific AI \\ntool, service, or announcement, because AI-enabled systems evolve rapidly. Finally, the \\nDepartment engaged the educational policy expertise available internally and in its relationships \\nwith AI policy experts to shape the findings and recommendations in this report.  \\nThree Reasons to Address AI in Education Now \\n“I strongly believe in the need for stakeholders to understand the cyclical \\neffects of AI and education. By understanding how different activities',\n",
       " 'Three Reasons to Address AI in Education Now \\n“I strongly believe in the need for stakeholders to understand the cyclical \\neffects of AI and education. By understanding how different activities \\naccrue, we have the ability to support virtuous cycles. Otherwise, we will \\nlikely allow vicious cycles to perpetuate.”  \\n —Lydia Liu \\nDuring the listening sessions, constituents articulated three reasons to address AI now: \\nFirst, AI may enable achieving educational priorities in better ways, at scale, and with lower costs. \\nAddressing varied unfinished learning of students due to the pandemic is a policy priority, and \\nAI may improve the adaptivity of learning resources to students’ strengths and needs. Improving \\nteaching jobs is a priority, and via automated assistants or other tools, AI may provide teachers \\ngreater support. AI may also enable teachers to extend the support they offer to individual',\n",
       " 'teaching jobs is a priority, and via automated assistants or other tools, AI may provide teachers \\ngreater support. AI may also enable teachers to extend the support they offer to individual \\nstudents when they run out of time. Developing resources that are responsive to the knowledge \\nand experiences students bring to their learning—their community and cultural assets—is a \\npriority, and AI may enable greater customizability of curricular resources to meet local needs.',\n",
       " '3 \\nAs seen in voice assistants, mapping tools, shopping recommendations, essay-writing capabilities, \\nand other familiar applications, AI may enhance educational services.  \\nSecond, urgency and importance arise through awareness of system-level risks and anxiety about \\npotential future risks. For example, students may become subject to greater surveillance. Some \\nteachers worry that they may be replaced—to the contrary, the Department firmly rejects the \\nidea that AI could replace teachers. Examples of discrimination from algorithmic bias are on the \\npublic’s mind, such as a voice recognition system that doesn’t work as well with regional dialects, \\nor an exam monitoring system that may unfairly identify some groups of students for \\ndisciplinary action. Some uses of AI may be infrastructural and invisible, which creates concerns \\nabout transparency and trust. AI often arrives in new applications with the aura of magic, but',\n",
       " 'disciplinary action. Some uses of AI may be infrastructural and invisible, which creates concerns \\nabout transparency and trust. AI often arrives in new applications with the aura of magic, but \\neducators and procurement policies require that edtech show efficacy. AI may provide \\ninformation that appears authentic, but actually is inaccurate or lacking a basis in reality. Of the \\nhighest importance, AI brings new risks in addition to the well-known data privacy and data \\nsecurity risks, such as the risk of scaling pattern detectors and automations that result in \\n“algorithmic discrimination” (e.g., systematic unfairness in the learning opportunities or \\nresources recommended to some populations of students). \\nThird, urgency arises because of the scale of possible unintended or unexpected consequences. \\nWhen AI enables instructional decisions to be automated at scale, educators may discover \\nunwanted consequences. In a simple example, if AI adapts by speeding curricular pace for some',\n",
       " 'When AI enables instructional decisions to be automated at scale, educators may discover \\nunwanted consequences. In a simple example, if AI adapts by speeding curricular pace for some \\nstudents and by slowing the pace for other students (based on incomplete data, poor theories, or \\nbiased assumptions about learning), achievement gaps could widen. In some cases, the quality of \\navailable data may produce unexpected results. For example, an AI-enabled teacher hiring \\nsystem might be assumed to be more objective than human-based résumé scoring. Yet, if the AI \\nsystem relies on poor quality historical data, it might de-prioritize candidates who could bring \\nboth diversity and talent to a school’s teaching workforce. \\nIn summary, it is imperative to address AI in education now to realize key opportunities, prevent \\nand mitigate emergent risks, and tackle unintended consequences. \\nToward Policies for AI in Education',\n",
       " 'and mitigate emergent risks, and tackle unintended consequences. \\nToward Policies for AI in Education \\nThe 2023 AI Index Report from the Stanford Institute for Human-Centered AI has documented \\nnotable acceleration of investment in AI as well as an increase of research on ethics, including \\nissues of fairness and transparency.2 Of course, research on topics like ethics is increasing \\nbecause problems are observed. Ethical problems will occur in education, too.3 The report found \\na striking interest in 25 countries in the number of legislative proposals that specifically include \\nAI. In the United States, multiple executive orders are focused on ensuring AI is trustworthy and \\nequitable, and the White House Office of Science and Technology Policy has introduced a \\n \\n2 Maslej, N., Fattorini, L., Brynjolfsson E., Etchemendy, J., Ligett, K., Lyons, T., Manyika, J., Ngo, H., Niebles, J.C., Parli, V.,',\n",
       " '2 Maslej, N., Fattorini, L., Brynjolfsson E., Etchemendy, J., Ligett, K., Lyons, T., Manyika, J., Ngo, H., Niebles, J.C., Parli, V., \\nShoham, Y., Wald, R., Clark, J. and Perrault, R., (2023). The AI index 2023 annual report. Stanford University: AI Index \\nSteering Committee, Institute for Human-Centered AI.  \\n3 Holmes, W. & Porayska-Pomsta, K. (Eds.) (2022). The ethics of artificial intelligence in education. Routledge. ISBN 978-\\n0367349721',\n",
       " '4 \\nBlueprint for an AI Bill of Rights (Blueprint)4 that provides principles and practices that help \\nachieve this goal. These initiatives, along with other AI-related policy activities occurring in both \\nthe executive and legislative branches, will guide the use of AI throughout all sectors of society. \\nIn Europe, the European Commission recently released Ethical guidelines on the use of artificial \\nintelligence (AI) and data in teaching and learning for educators.5 \\nAI is moving fast and heralding societal changes that require a national policy response. In \\naddition to broad policies for all sectors of society, education-specific policies are needed to \\naddress new opportunities and challenges within existing frameworks that take into \\nconsideration federal student privacy laws (such as the Family Educational Rights and Privacy \\nAct, or FERPA), as well as similar state related laws. AI also makes recommendations and takes',\n",
       " 'consideration federal student privacy laws (such as the Family Educational Rights and Privacy \\nAct, or FERPA), as well as similar state related laws. AI also makes recommendations and takes \\nactions automatically in support of student learning, and thus educators will need to consider \\nhow such recommendations and actions can comply with laws such as the Individuals with \\nDisabilities Education Act (IDEA). We discuss specific policies in the concluding section. \\nFigure 1: Research about AI is growing rapidly. Other indicators, such as dollars invested and \\nnumber of people employed, show similar trends. \\n \\nAI is advancing exponentially (see Figure 1), with powerful new AI features for generating images \\nand text becoming available to the public, and leading to changes in how people create text and \\n \\n4 White House Office of Science and Technology Policy (October 2022), Blueprint for an AI bill of rights: Making automated',\n",
       " '4 White House Office of Science and Technology Policy (October 2022), Blueprint for an AI bill of rights: Making automated \\nsystems work for the American people. The White House Office of Science and Technology Policy. \\nhttps://www.whitehouse.gov/ostp/ai-bill-of-rights/  \\n5 European Commission, Directorate-General for Education, Youth, Sport and Culture. (2022). Ethical guidelines on the use of \\nartificial intelligence (AI) and data in teaching and learning for educators, Publications Office of the European \\nUnion. https://data.europa.eu/doi/10.2766/153756',\n",
       " '5 \\nimages6. The advances in AI are not only happening in research labs but also are making news in \\nmainstream media and in educational-specific publications.  \\nResearchers have articulated a range of concepts and frameworks for ethical AI7, as well as for \\nrelated concepts such as equitable, responsible, and human-centered AI. Listening session \\nparticipants called for building on these concepts and frameworks but also recognized the need \\nto do more; participants noted a pressing need for guardrails and guidelines that make \\neducational use of AI advances safe, especially given this accelerating pace of incorporation of AI \\ninto mainstream technologies. As policy development takes time, policy makers and educational \\nconstituents together need to start now to specify the requirements, disclosures, regulations, and \\nother structures that can shape a positive and safe future for all constituents—especially students \\nand teachers.',\n",
       " 'other structures that can shape a positive and safe future for all constituents—especially students \\nand teachers.  \\nPolicies are urgently needed to implement the following:  \\n1. leverage automation to advance learning outcomes while protecting human decision \\nmaking and judgment;  \\n2. interrogate the underlying data quality in AI models to ensure fair and unbiased pattern \\nrecognition and decision making in educational applications, based on accurate \\ninformation appropriate to the pedagogical situation;  \\n3. enable examination of how particular AI technologies, as part of larger edtech or \\neducational systems, may increase or undermine equity for students; and \\n4. take steps to safeguard and advance equity, including providing for human checks and \\nbalances and limiting any AI systems and tools that undermine equity. \\n  \\n \\n6 Sharples, M. & Pérez y Pérez, R. (2022). Story machines: How computers have become creative writers. Routledge. ISBN \\n9780367751951',\n",
       " '6 Sharples, M. & Pérez y Pérez, R. (2022). Story machines: How computers have become creative writers. Routledge. ISBN \\n9780367751951 \\n7 Akgun, S., Greenhow, C. (2022). Artificial intelligence in education: Addressing ethical challenges in K-12 settings. AI \\nEthics, 2, 431–440. https://doi.org/10.1007/s43681-021-00096-7',\n",
       " '6 \\n \\nBuilding Ethical, Equitable \\nPolicies Together \\nIn this report, we aim to build on the listening sessions the Department hosted to engage and \\ninform all constituents involved in making educational decisions so they can prepare for and \\nmake better decisions about the role of AI in teaching and learning. AI is a complex and broad \\ntopic, and we are not able to cover everything nor resolve issues that still require more \\nconstituent engagement. This report is intended to be a starting point. \\nThe opportunities and issues of AI in education are equally important in K-12, higher education, \\nand workforce learning. Due to scope limitations, the examples in this report will focus on K-12 \\neducation. The implications are similar at all levels of education, and the Department intends \\nfurther activities in 2023 to engage constituents beyond K-12 schools. \\nGuiding Questions \\nUnderstanding that AI increases automation and allows machines to do some tasks that only',\n",
       " 'further activities in 2023 to engage constituents beyond K-12 schools. \\nGuiding Questions \\nUnderstanding that AI increases automation and allows machines to do some tasks that only \\npeople did in the past leads us to a pair of bold, overarching questions:  \\n1. What is our collective vision of a desirable and achievable educational system that \\nleverages automation to advance learning while protecting and centering human agency? \\n2. How and on what timeline will we be ready with necessary guidelines and guardrails, as \\nwell as convincing evidence of positive impacts, so that constituents can ethically and \\nequitably implement this vision widely? \\nIn the Learning, Teaching, and Assessment sections of this report, we elaborate on elements of \\nan educational vision grounded in what today’s learners, teachers, and educational systems need, \\nand we describe key insights and next steps required. Below, we articulate four key foundations',\n",
       " 'an educational vision grounded in what today’s learners, teachers, and educational systems need, \\nand we describe key insights and next steps required. Below, we articulate four key foundations \\nfor framing these themes. These foundations arise from what we know about the effective use of \\neducational technology to improve opportunity, equity, and outcomes for students and also \\nrelate to the new Blueprint. \\nFoundation 1: Center People (Parents, Educators, and Students) \\nEducation-focused AI policies at the federal, state, and district levels will be needed to guide and \\nempower local and individual decisions about which technologies to adopt and use in schools \\nand classrooms. Consider what is happening in everyday lives. Many of us use AI-enabled \\nproducts because they are often better and more convenient. For example, few people want to \\nuse paper maps anymore; people find that technology helps us plan the best route to a',\n",
       " 'products because they are often better and more convenient. For example, few people want to \\nuse paper maps anymore; people find that technology helps us plan the best route to a \\ndestination more efficiently and conveniently. And yet, people often do not realize how much \\nprivacy they are giving up when they accept AI-enabled systems into their lives. AI will bring \\nprivacy and other risks that are hard to address only via individual decision making; additional \\nprotections will be needed.',\n",
       " '7 \\nThere should be clear limits on the ability to collect, use, transfer, and \\nmaintain our personal data, including limits on targeted advertising. \\nThese limits should put the burden on platforms to minimize how much \\ninformation they collect, rather than burdening Americans with reading \\nfine print.8 \\nAs protections are developed, we recommend that policies center people, not machines. To this \\nend, a first recommendation in this document (in the next section) is an emphasis on AI with \\nhumans in the loop. Teachers, learners, and others need to retain their agency to decide what \\npatterns mean and to choose courses of action. The idea of humans in the loop builds on the \\nconcept of “Human Alternatives, Consideration, and Fallback” in the Blueprint and ethical \\nconcepts used more broadly in evaluating AI, such as preserving human dignity. A top policy \\npriority must be establishing human in the loop as a requirement in educational applications,',\n",
       " 'concepts used more broadly in evaluating AI, such as preserving human dignity. A top policy \\npriority must be establishing human in the loop as a requirement in educational applications, \\ndespite contrary pressures to use AI as an alternative to human decision making. Policies should \\nnot hinder innovation and improvement, nor should they be burdensome to implement. Society \\nneeds an education-focused AI policy that protects civil rights and promotes democratic values \\nin the building, deployment, and governance of automated systems to be used across the many \\ndecentralized levels of the American educational system. \\nFoundation 2: Advance Equity \\n“AI brings educational technology to an inflection point. We can either \\nincrease disparities or shrink them, depending on what we do now.”  \\n—Dr. Russell Shilling \\nA recent Executive Order9 issued by President Biden sought to strengthen the connection among',\n",
       " 'increase disparities or shrink them, depending on what we do now.”  \\n—Dr. Russell Shilling \\nA recent Executive Order9 issued by President Biden sought to strengthen the connection among \\nracial equity, education and AI, stating that “members of underserved communities—many of \\nwhom have endured generations of discrimination and disinvestment—still confront significant \\nbarriers to realizing the full promise of our great Nation, and the Federal Government has a \\nresponsibility to remove these barriers” and that the Federal Government shall both “pursue \\neducational equity so that our Nation’s schools put every student on a path to success” and also \\n“root out bias in the design and use of new technologies, such as artificial intelligence.” A specific \\nvision of equity, such as described in the Department’s recent report, Advancing Digital Equity for \\nAll10 is essential to policy discussion about AI in education. This report defines digital equity as',\n",
       " 'All10 is essential to policy discussion about AI in education. This report defines digital equity as \\n \\n8 The White House (September 8, 2022). Readout of White House listening session on tech platform accountability. \\nhttps://www.whitehouse.gov/briefing-room/statements-releases/2022/09/08/readout-of-white-house-listening-session-\\non-tech-platform-accountability/ \\n9 The White House (February 17, 2023). Executive order on further advancing racial equity and support for underserved \\ncommunities through the federal government. https://www.whitehouse.gov/briefing-room/presidential-\\nactions/2023/02/16/executive-order-on-further-advancing-racial-equity  \\n10 U.S. Department of Education, Office of Educational Technology (2022). Advancing digital equity for all: Community-\\nbased recommendations for developing effective digital equity plans to close the digital divide and enable technology-\\nempowered learning. US Department of Education.',\n",
       " '8 \\n“the condition in which individuals and communities have the information technology capacity \\nthat is needed for full participation in the society and economy of the United States.” \\nIssues related to racial equity and unfair bias were at the heart of every listening session we held. \\nIn particular, we heard a conversation that was increasingly attuned to issues of data quality and \\nthe consequences of using poor or inappropriate data in AI systems for education. Datasets are \\nused to develop AI, and when they are non-representative or contain undesired associations or \\npatterns, resulting AI models may act unfairly in how they detect patterns or automate decisions. \\nSystematic, unwanted unfairness in how a computer detects patterns or automates decisions is \\ncalled “algorithmic bias.” Algorithmic bias could diminish equity at scale with unintended \\ndiscrimination. As this document discussed in the Formative Assessment section, this is not a new',\n",
       " 'called “algorithmic bias.” Algorithmic bias could diminish equity at scale with unintended \\ndiscrimination. As this document discussed in the Formative Assessment section, this is not a new \\nconversation. For decades, constituents have rightly probed whether assessments are unbiased \\nand fair. Just as with assessments, whether an AI model exhibits algorithmic bias or is judged to \\nbe fair and trustworthy is critical as local school leaders make adoption decisions about using AI \\nto achieve their equity goals.  \\nWe highlight the concept of “algorithmic discrimination” in the Blueprint. Bias is intrinsic to \\nhow AI algorithms are developed using historical data, and it can be difficult to anticipate all \\nimpacts of biased data and algorithms during system design. The Department holds that biases \\nin AI algorithms must be addressed when they introduce or sustain unjust discriminatory \\npractices in education. For example, in postsecondary education, algorithms that make',\n",
       " 'in AI algorithms must be addressed when they introduce or sustain unjust discriminatory \\npractices in education. For example, in postsecondary education, algorithms that make \\nenrollment decisions, identify students for early intervention, or flag possible student cheating \\non exams must be interrogated for evidence of unfair discriminatory bias—and not only when \\nsystems are designed, but also later, as systems become widely used. \\nFoundation 3: Ensure Safety, Ethics, and Effectiveness \\nA central safety argument in the Department’s policies is the need for data privacy and security \\nin the systems used by teachers, students, and others in educational institutions. The \\ndevelopment and deployment of AI requires access to detailed data. This data goes beyond \\nconventional student records (roster and gradebook information) to detailed information about \\nwhat students do as they learn with technology and what teachers do as they use technology to',\n",
       " 'conventional student records (roster and gradebook information) to detailed information about \\nwhat students do as they learn with technology and what teachers do as they use technology to \\nteach. AI’s dependence on data requires renewed and strengthened attention to data privacy, \\nsecurity, and governance (as also indicated in the Blueprint). As AI models are not generally \\ndeveloped in consideration of educational usage or student privacy, the educational application \\nof these models may not be aligned with the educational institution’s efforts to comply with \\nfederal student privacy laws, such as FERPA, or state privacy laws.',\n",
       " '9 \\nFigure 2: The Elementary and Secondary Education Act defines four levels of evidence.\\n \\nFurther, educational leaders are committed to basing their decisions about the adoption of \\neducational technology on evidence of effectiveness—a central foundation of the Department’s \\npolicy. For example, the requirement to base decisions on evidence also arises in the Elementary \\nand Secondary Education Act (ESEA), as amended, which introduced four tiers of evidence (see \\nFigure 2). Our nation’s research agencies, including the Institute of Education Sciences, are \\nessential to producing the needed evidence. The Blueprint calls for evidence of effectiveness, but \\nthe education sector is ahead of that game: we need to insist that AI-enhanced edtech rises to \\nmeet ESEA standards as well. \\nFoundation 4: Promote Transparency  \\nThe central role of complex AI models in a technology’s detection of patterns and',\n",
       " 'meet ESEA standards as well. \\nFoundation 4: Promote Transparency  \\nThe central role of complex AI models in a technology’s detection of patterns and \\nimplementation of automation is an important way in which AI-enabled applications, products, \\nand services will be different from conventional edtech. The Blueprint introduces the need for \\ntransparency about AI models in terms of disclosure (“notice”) and explanation. In education, \\ndecision makers will need more than notice—they will need to understand how AI models work \\nin a range of general educational use cases, so they can better anticipate limitations, problems, \\nand risks.  \\nAI models in edtech will be approximations of reality and, thus, constituents can always ask these \\nquestions: How precise are the AI models? Do they accurately capture what is most important? \\nHow well do the recommendations made by an AI model fit educational goals? What are the \\nbroader implications of using AI models at scale in educational processes?',\n",
       " 'How well do the recommendations made by an AI model fit educational goals? What are the \\nbroader implications of using AI models at scale in educational processes?  \\nBuilding on what was heard from constituents, the sections of this report develop the theme of \\nevaluating the quality of AI systems and tools using multiple dimensions as follows: \\n● About AI: AI systems and tools must respect data privacy and security. Humans must be \\nin the loop. \\n● Learning: AI systems and tools must align to our collective vision for high-quality \\nlearning, including equity. \\n● Teaching: AI systems and tools must be inspectable, explainable, and provide human \\nalternatives to AI-based suggestions; educators will need support to exercise professional \\njudgment and override AI models, when necessary.',\n",
       " '10 \\n● Formative Assessment: AI systems and tools must minimize bias, promote fairness, and \\navoid additional testing time and burden for students and teachers. \\n● Research and Development: AI systems and tools must account for the context of \\nteaching and learning and must work well in educational practice, given variability in \\nstudents, teachers, and settings. \\n● Recommendations: Use of AI systems and tools must be safe and effective for students. \\nThey must include algorithmic discrimination protections, protect data privacy, provide \\nnotice and explanation, and provide a recourse to humans when problems arise. The \\npeople most affected by the use of AI in education must be part of the development of \\nthe AI model, system, or tool, even if this slows the pace of adoption. \\n \\nWe return to the idea that these considerations fit together in a comprehensive perspective on \\nthe quality of AI models in the Recommendations section. \\nOverview of Document',\n",
       " 'We return to the idea that these considerations fit together in a comprehensive perspective on \\nthe quality of AI models in the Recommendations section. \\nOverview of Document \\nWe begin in the next section by elaborating a definition of AI, followed by addressing learning, \\nteaching, assessment, and research and development. Organizing key insights by these topics \\nkeeps us focused on exploring implications for improving educational opportunity and \\noutcomes for students throughout the report. \\nWithin these topics, three important themes are explored: \\n1. Opportunities and Risks. Policies should focus on the most valuable educational \\nadvances while mitigating risks. \\n2. Trust and Trustworthiness. Trust and safeguarding are particularly important in \\neducation because we have an obligation to keep students out of harm’s way and \\nsafeguard their learning experiences.  \\n3. Quality of AI Models. The process of developing and then applying a model is at the',\n",
       " 'safeguard their learning experiences.  \\n3. Quality of AI Models. The process of developing and then applying a model is at the \\nheart of any AI system. Policies need to support evaluation of the qualities of AI models \\nand their alignment to goals for teaching and learning during the processes of \\neducational adoption and use. \\n“AI in education can only grow at the speed of trust.” \\n—Dr. Dale Allen',\n",
       " '11 \\nWhat is AI? \\nOur preliminary definition of AI as automation based on associations requires elaboration. \\nBelow we address three additional perspectives on what constitutes AI. Educators will find these \\ndifferent perspectives arise in the marketing of AI functionality and are important to understand \\nwhen evaluating edtech systems that incorporate AI. One useful glossary of AI for Education \\nterms is the CIRCLS Glossary of Artificial Intelligence Terms for Educators.11  \\nAI is not one thing but an umbrella term for a growing set of modeling capabilities, as visualized \\nin Figure 3. \\nFigure 3: Components, types, and subfields of AI based on Regona et al (2022).12  \\n \\n \\n11 Search for “AI Glossary Educators” to find other useful definitions. \\n12 Regona, Massimo & Yigitcanlar, Tan & Xia, Bo & Li, R.Y.M. (2022). Opportunities and adoption challenges of AI in the \\nconstruction industry: A PRISMA review. Journal of Open Innovation Technology Market and Complexity, 8(45).',\n",
       " 'construction industry: A PRISMA review. Journal of Open Innovation Technology Market and Complexity, 8(45). \\nhttps://doi.org/10.3390/joitmc8010045',\n",
       " '12 \\nPerspective: Human-Like Reasoning \\n“The theory and development of computer systems able to perform tasks \\nnormally requiring human intelligence such as, visual perception, speech \\nrecognition, learning, decision-making, and natural language  \\nprocessing.” 13 \\nBroad cultural awareness of AI may be traced to the landmark 1968 film “2001: A Space \\nOdyssey”—in which the “Heuristically-programmed ALgorithmic” computer, or “HAL,” \\nconverses with astronaut Frank. HAL helps Frank pilot the journey through space, a job that \\nFrank could not do on his own. However, Frank eventually goes outside the spacecraft, HAL \\ntakes over control, and this does not end well for Frank. HAL exhibits human-like behaviors, \\nsuch as reasoning, talking, and acting. Like all applications of AI, HAL can help humans but also \\nintroduces unanticipated risks—especially since AI reasons in different ways and with different \\nlimitations than people do.',\n",
       " 'introduces unanticipated risks—especially since AI reasons in different ways and with different \\nlimitations than people do. \\nThe idea of “human-like” is helpful because it can be a shorthand for the idea that computers \\nnow have capabilities that are very different from the capabilities of early edtech applications. \\nEducational applications will be able to converse with students and teachers, co-pilot how \\nactivities unfold in classrooms, and take actions that impact students and teachers more broadly. \\nThere will be both opportunities to do things much better than we do today and risks that must \\nbe anticipated and addressed. \\nThe “human-like” shorthand is not always useful, however, because AI processes information \\ndifferently from how people process information. When we gloss over the differences between \\npeople and computers, we may frame policies for AI in education that miss the mark. \\nPerspective: An Algorithm that Pursues a Goal',\n",
       " 'people and computers, we may frame policies for AI in education that miss the mark. \\nPerspective: An Algorithm that Pursues a Goal \\n“Any computational method that is made to act independently towards a \\ngoal based on inferences from theory or patterns in data.” 14 \\nThis second definition emphasizes that AI systems and tools identify patterns and choose actions \\nto achieve a given goal. These pattern recognition capabilities and automated recommendations \\nwill be used in ways that impact the educational process, including student learning and teacher \\ninstructional decision making. For example, today’s personalized learning systems may \\nrecognize signs that a student is struggling and may recommend an alternative instructional \\nsequence. The scope of pattern recognition and automated recommendations will expand. \\n \\n13 IEEE-USA Board of Directors. (February 10, 2017). Artificial intelligence research, development and regulation. IEEE',\n",
       " '13 IEEE-USA Board of Directors. (February 10, 2017). Artificial intelligence research, development and regulation. IEEE \\nhttp://globalpolicy.ieee.org/wp-content/uploads/2017/10/IEEE17003.pdf \\n14 Friedman, L., Blair Black, N., Walker, E., & Roschelle, J. (November 8, 2021) Safe AI in education needs you. Association of \\nComputing Machinery blog, https://cacm.acm.org/blogs/blog-cacm/256657-safe-ai-in-education-needs-you/fulltext',\n",
       " '13 \\nCorrespondingly, humans must determine the types and degree of responsibility we will grant to \\ntechnology within educational processes, which is not a new dilemma.  \\nFor decades, the lines between the role of teachers and computers have been discussed in \\neducation, for example, in debates using terms such as “’computer-aided instruction,” “blended \\ninstruction,” and “personalized learning.” Yet, how are instructional choices made in systems that \\ninclude both humans and algorithms? Today, AI systems and tools are already enabling the \\nadaptation of instructional sequences to student needs to give students feedback and hints, for \\nexample, during mathematics problem solving or foreign language learning. This discussion \\nabout the use of AI in classroom pedagogy and student learning will be renewed and intensify as \\nAI-enabled systems and tools advance in capability and become more ubiquitous.',\n",
       " 'about the use of AI in classroom pedagogy and student learning will be renewed and intensify as \\nAI-enabled systems and tools advance in capability and become more ubiquitous. \\nLet’s start with another simple example. When a teacher says, “Display a map of ancient Greece \\non the classroom screen,” an AI system may choose among hundreds of maps by noting the \\nlesson objectives, what has worked well in similar classrooms, or which maps have desirable \\nfeatures for student learning. In this case, when an AI system suggests an instructional resource \\nor provides a choice among a few options, the instructor may save time and may focus on more \\nimportant goals. However, there are also forms of AI-enabled automation that the classroom \\ninstructor may reject, for example, enabling an AI system or tool to select the most appropriate \\nand relevant readings for students associated with a historical event. In this case, an educator',\n",
       " 'instructor may reject, for example, enabling an AI system or tool to select the most appropriate \\nand relevant readings for students associated with a historical event. In this case, an educator \\nmay choose not to utilize AI-enabled systems or tools given the risk of AI creating false facts \\n(“hallucinating”) or steering students toward inaccurate depictions of historical events found on \\nthe internet. Educators will be weighing benefits and risks like these daily. \\nComputers process theory and data differently than humans. AI’s success depends on \\nassociations or relationships found in the data provided to an algorithm during the AI model \\ndevelopment process. Although some associations may be useful, others may be biased or \\ninappropriate. Finding bad associations in data is a major risk, possibly leading to algorithmic \\ndiscrimination. Every guardian is familiar with the problem: A person or computer may say,',\n",
       " 'inappropriate. Finding bad associations in data is a major risk, possibly leading to algorithmic \\ndiscrimination. Every guardian is familiar with the problem: A person or computer may say, \\n“Our data suggests your student should be placed in this class,” and the guardian may well argue, \\n“No, you are using the wrong data. I know my child better, and they should instead be placed in \\nanother class.” This problem is not limited exclusively to AI systems and tools, but the use of AI \\nmodels can amplify the problem when a computer uses data to make a recommendation because \\nit may appear to be more objective and authoritative, even if it is not. \\nAlthough this perspective can be useful, it can be misleading. A human view of agency, pursuing \\ngoals, and reasoning includes our human abilities to make sense of multiple contexts. For \\nexample, a teacher may see three students each make the same mathematical error but recognize',\n",
       " 'goals, and reasoning includes our human abilities to make sense of multiple contexts. For \\nexample, a teacher may see three students each make the same mathematical error but recognize \\nthat one student has an Individualized Education Program to address vision issues, another \\nmisunderstands a mathematical concept, and a third just experienced a frustrating interaction on \\nthe playground; the same instructional decision is therefore not appropriate. However, AI \\nsystems often lack data and judgement to appropriately include context as they detect patterns \\nand automate decisions. Further, case studies show that technology has the potential to quickly \\nderail from safe to unsafe or from effective to ineffective when the context shifts even slightly. \\nFor this and other reasons, people must be involved in goal setting, pattern analysis, and \\ndecision-making.15 \\n \\n15 Russell, S. (2019). Human compatible: Artificial intelligence and the problem of control. Viking. ISBN 978-0-525-55861-3.',\n",
       " '14 \\nPerspective: Intelligence Augmentation \\n“Augmented intelligence is a design pattern for a human-centered \\npartnership model of people and artificial intelligence (AI) working \\ntogether to enhance cognitive performance, including learning, decision \\nmaking, and new experiences.” 16 \\nFoundation #1 (above) keeps humans in the loop and positions AI systems and tools to support \\nhuman reasoning. “Intelligence Augmentation” (IA)17 centers “intelligence” and “decision \\nmaking” in humans but recognizes that people sometimes are overburdened and benefit from \\nassistive tools. AI may help teachers make better decisions because computers notice patterns \\nthat teachers can miss. For example, when a teacher and student agree that the student needs \\nreminders, an AI system may provide reminders in whatever form a student likes without \\nadding to the teacher’s workload. Intelligence Automation (IA) uses the same basic capabilities of',\n",
       " 'reminders, an AI system may provide reminders in whatever form a student likes without \\nadding to the teacher’s workload. Intelligence Automation (IA) uses the same basic capabilities of \\nAI, employing associations in data to notice patterns, and, through automation, takes actions \\nbased on those patterns. However, IA squarely focuses on helping people in human activities of \\nteaching and learning, whereas AI tends to focus attention on what computers can do. \\nDefinition of “Model” \\nThe above perspectives open a door to making sense of AI. Yet, to assess AI meaningfully, \\nconstituents must consider specific models and how they are developed. In everyday usage, the \\nterm “model” has multiple definitions. We clarify our intended meaning, which is a meaning \\nsimilar to “mathematical model,” below. (Conversely, note that “model” as used in “AI model” is \\nunlike the usage in “model school” or “instructional model” as AI model is not a singular case',\n",
       " 'similar to “mathematical model,” below. (Conversely, note that “model” as used in “AI model” is \\nunlike the usage in “model school” or “instructional model” as AI model is not a singular case \\ncreated by experts to serve as an exemplar.) \\nAI models are like financial models: an approximation of reality that is useful for identifying \\npatterns, making predictions, or analyzing alternative decisions. In a typical middle school math \\ncurriculum, students use a mathematical model to analyze which of two cell phone plans is \\nbetter. Financial planners use this type of model to provide guidance on a retirement portfolio. \\nAt its heart, AI is a highly advanced mathematical toolkit for building and using models. Indeed, \\nin well-known chatbots, complex essays are written one word at a time. The underlying AI model \\npredicts which next words would likely follow the text written so far; AI chatbots use a very large',\n",
       " 'in well-known chatbots, complex essays are written one word at a time. The underlying AI model \\npredicts which next words would likely follow the text written so far; AI chatbots use a very large \\nstatistical model to add one likely word at a time, thereby writing surprisingly coherent essays. \\nWhen we ask about the model at the heart of AI, we begin to get answers about “what aspects of \\nreality does the model approximate well?” and “how appropriate is it to the decision to be made?” \\nOne could similarly ask about algorithms—the specific decision-making processes that an AI \\nmodel uses to go from inputs to outputs. One could also ask about the quality of the data used to \\nbuild the model—for example, how representative is that data? Switching among three terms—\\n \\n16 Gartner (n.d.) Gartner glossary: Augmented intelligence. Gartner. https://www.gartner.com/en/information-\\ntechnology/glossary/augmented-intelligence',\n",
       " '16 Gartner (n.d.) Gartner glossary: Augmented intelligence. Gartner. https://www.gartner.com/en/information-\\ntechnology/glossary/augmented-intelligence \\n17 Englebart, D.C. (October 1962). Augmenting human intellect: A conceptual framework. SRI Summary Report AFOSR-\\n3223. https://www.dougengelbart.org/pubs/augment-3906.html',\n",
       " \"15 \\nmodels, algorithms, and data—will become confusing. Because the terms are closely related, \\nwe’ve chosen to focus on the concept of AI models. We want to bring to the fore the idea that \\nevery AI model is incomplete, and it's important to know how well the AI model fits the reality \\nwe care about, where the model will break down, and how. \\nSometimes people avoid talking about the specifics of models to create a mystique. Talking as \\nthough AI is unbounded in its potential capabilities and a nearly perfect approximation to reality \\ncan convey an excitement about the possibilities of the future. The future, however, can be \\noversold. Similarly, sometimes people stop calling a model AI when its use becomes \\ncommonplace, yet such systems are still AI models with all of the risks discussed here. We need \\nto know exactly when and where AI models fail to align to visions for teaching and learning. \\nInsight: AI Systems Enable New Forms of Interaction\",\n",
       " 'to know exactly when and where AI models fail to align to visions for teaching and learning. \\nInsight: AI Systems Enable New Forms of Interaction \\nAI models allow computational processes to make recommendations or plans and also enable \\nthem to support forms of interaction that are more natural, such as speaking to an assistant. AI-\\nenabled educational systems will be desirable in part due to their ability to support more natural \\ninteractions during teaching and learning. In classic edtech platforms, the ways in which teachers \\nand students interact with edtech are limited. Teachers and students may choose items from a \\nmenu or in a multiple-choice question. They may type short answers. They may drag objects on \\nthe screen or use touch gestures. The computer provides outputs to students and teachers \\nthrough text, graphics, and multimedia. Although these forms of inputs and outputs are versatile,',\n",
       " 'the screen or use touch gestures. The computer provides outputs to students and teachers \\nthrough text, graphics, and multimedia. Although these forms of inputs and outputs are versatile, \\nno one would mistake this style of interaction with the way two people interact with one another; \\nit is specific to human-computer interaction. With AI, interactions with computers are likely to \\nbecome more like human-to-human interactions (see Figure 4). A teacher may speak to an AI \\nassistant, and it may speak back. A student may make a drawing, and the computer may highlight \\na portion of the drawing. A teacher or student may start to write something, and the computer \\nmay finish their sentence—as when today’s email programs can complete thoughts faster than \\nwe can type them. \\nAdditionally, the possibilities for automated actions that can be executed by AI tools are \\nexpanding. Current personalization tools may automatically adjust the sequence, pace, hints, or',\n",
       " 'Additionally, the possibilities for automated actions that can be executed by AI tools are \\nexpanding. Current personalization tools may automatically adjust the sequence, pace, hints, or \\ntrajectory through learning experiences.18 Actions in the future might look like an AI system or \\ntool that helps a student with homework19 or a teaching assistant that reduces a teacher’s \\nworkload by recommending lesson plans that fit a teacher’s needs and are similar to lesson plans \\na teacher previously liked.20 Further, an AI-enabled assistant may appear as an additional \\n“partner” in a small group of students who are working together on a collaborative assignment.21 \\nAn AI-enabled tool may also help teachers with complex classroom routines.22 For example, a \\n \\n18 Shemshack, A., Spector, J.M. (2020) A systematic literature review of personalized learning terms. Smart Learning \\nEnvironments, 7(33). https://doi.org/10.1186/s40561-020-00140-9',\n",
       " '18 Shemshack, A., Spector, J.M. (2020) A systematic literature review of personalized learning terms. Smart Learning \\nEnvironments, 7(33). https://doi.org/10.1186/s40561-020-00140-9 \\n19 Roschelle, J., Feng, M., Murphy, R. & Mason, C.A. (2016). Online mathematics homework increases student achievement. \\nAERA Open, 2(4), 1-12. DOI: 10.1177/2332858416673968 \\n20 Celik, I., Dindar, M., Muukkonen, H. & Järvelä, S. (2022). The promises and challenges of artificial intelligence for \\nteachers: A systematic review of research. TechTrends, 66, 616–630. https://doi.org/10.1007/s11528-022-00715-y \\n21 Chen, C., Park, H.W. & Breazeal, C. (2020). Teaching and learning with children: Impact of reciprocal peer learning with \\na social robot on children’s learning and emotive engagement. Computers & Education, 150, \\nhttps://doi.org/10.1016/j.compedu.2020.103836 \\n22 Holstein, K., McLaren, B.M., & Aleven, V. (2019). Co-designing a real-time classroom orchestration tool to support',\n",
       " 'https://doi.org/10.1016/j.compedu.2020.103836 \\n22 Holstein, K., McLaren, B.M., & Aleven, V. (2019). Co-designing a real-time classroom orchestration tool to support \\nteacher–AI complementarity. Journal of Learning Analytics, 6(2). https://doi.org/10.18608/jla.2019.62.3',\n",
       " '16 \\ntool may help teachers with orchestrating23 the movement of students from a full class discussion \\ninto small groups and making sure each group has the materials needed to start their work. \\nFigure 4. Differences that teachers and students may experience in future technologies. \\n \\nKey Recommendation: Human in the Loop AI \\nMany have experienced a moment where technology surprised them with an uncanny ability to \\nrecommend what feels like a precisely personalized product, song, or even phrase to complete a \\nsentence in a word processor such as the one being used to draft this document. Throughout this \\nsupplement, we talk about specific, focused applications where AI systems may bring value (or \\nrisks) into education. At no point do we intend to imply that AI can replace a teacher, a guardian, \\nor an educational leader as the custodian of their students’ learning. We talk about the limitations',\n",
       " 'or an educational leader as the custodian of their students’ learning. We talk about the limitations \\nof models in AI and the conversations that educational constituents need to have about what \\nqualities they want AI models to have and how they should be used. \\n“We can use AI to study the diversity, the multiplicity of effective learning \\napproaches and think about the various models to help us get a broader \\nunderstanding of what effective, meaningful engagement might look like \\nacross a variety of different contexts.” \\n—Dr. Marcelo Aaron Bonilla Worsley \\n \\n \\n23 Roschelle, J., Dimitriadis, Y. & Hoppe, U. (2013). Classroom orchestration: Synthesis. Computers & Education, 69, 512-526. \\nhttps://doi.org/10.1016/j.compedu.2013.04.010',\n",
       " '17 \\nThese limitations lead to our first recommendation: that we pursue a vision of AI where humans \\nare in the loop. That means that people are part of the process of noticing patterns in an \\neducational system and assigning meaning to those patterns. It also means that teachers remain \\nat the helm of major instructional decisions. It means that formative assessments involve teacher \\ninput and decision making, too. One loop is the cycle of recognizing patterns in what students do \\nand selecting next steps or resources that could support their learning. Other loops involve \\nteachers planning and reflecting on lessons. Response to Intervention is another well-known \\ntype of loop.  \\nThe idea of humans in the loop is part of our broader discussions happening about AI and \\nsociety, not just AI in education. Interested readers could look for more on human-centered AI, \\nresponsible AI, value-sensitive AI, AI for social good, and other similar terms that ally with',\n",
       " 'society, not just AI in education. Interested readers could look for more on human-centered AI, \\nresponsible AI, value-sensitive AI, AI for social good, and other similar terms that ally with \\nhumans in the loop, such as “human-centered AI.” \\nExercising judgement and control in the use of AI systems and tools is an essential part of \\nproviding the best opportunity to learn for all students—especially when educational decisions \\ncarry consequence. AI does not have the broad qualities of contextual judgment that people do. \\nTherefore, people must remain responsible for the health and safety of our children, for all \\nstudents’ educational success and preparation for their futures, and for creating a more equitable \\nand just society.',\n",
       " '18 \\nLearning \\nThe Department’s long-standing edtech vision sees students as active learners; students \\nparticipate in discussions that advance their understanding, use visualizations and simulations to \\nexplain concepts as they relate to the real world, and leverage helpful scaffolding and timely \\nfeedback as they learn. Constituents want technology to align to and build on these and other \\nresearch-based understandings of how people learn. Educators can draw upon two books titled \\nHow People Learn and How People Learn II by the National Academies of Sciences, Engineering, \\nand Medicine for a broad synthesis of what we know about learning.24 As we shape AI-enhanced \\nedtech around research-based principles, a key goal must be to strengthen and support learning \\nfor those who have experienced unfavorable circumstances for learning, such as caused by the \\nCOVID-19 pandemic or by broader inequities. And we must keep a firm eye toward the forms of',\n",
       " 'for those who have experienced unfavorable circumstances for learning, such as caused by the \\nCOVID-19 pandemic or by broader inequities. And we must keep a firm eye toward the forms of \\nlearning that will most benefit learners in their future lives in communities and workplaces. \\nExamples of AI supporting learning principles in this section include the following: AI-based \\ntutoring for students as they solve math problems (based on cognitive learning theories), \\nadapting to learners with special needs (based on the Universal Design for Learning framework \\nand related theories), and AI support for effective student teamwork (based on theories in the \\nfield called “Computer Supported Collaborative Learning”). \\nInsight: AI Enables Adaptivity in Learning \\nAdaptivity has been recognized as a key way in which technology can improve learning.25 AI can \\nbe a toolset for improving the adaptivity of edtech. AI may improve a technology’s ability to',\n",
       " 'Adaptivity has been recognized as a key way in which technology can improve learning.25 AI can \\nbe a toolset for improving the adaptivity of edtech. AI may improve a technology’s ability to \\nmeet students where they are, build on their strengths, and grow their knowledge and skills. \\nBecause of AI’s powers of work with natural forms of input and the foundational strengths of AI \\nmodels (as discussed in the What is AI? section), AI can be an especially strong toolkit for \\nexpanding the adaptivity provided to students. \\nAnd yet, especially with AI, adaptivity is always more specific and limited than what a broad \\nphrase like “meet students where they are” might suggest. Core limits arise from the nature of \\nthe model at the heart of any specific AI-enabled system. Models are approximations of reality. \\nWhen important parts of human learning are left out of the model or less fully developed, the',\n",
       " 'the model at the heart of any specific AI-enabled system. Models are approximations of reality. \\nWhen important parts of human learning are left out of the model or less fully developed, the \\nresulting adaptivity will also be limited, and the resulting supports for learning may be brittle or \\nnarrow. Consequently, this section on Learning focuses on one key concept: Work toward AI \\nmodels that fit the fullness of visions for learning—and avoid limiting learning to what AI can \\ncurrently model well. \\nAI models are demonstrating greater skills because of advances in what are called “large language \\nmodels” or sometimes “foundational models.” These very general models still have limits. For \\nexample, generative AI models discussed in the mainstream news can quickly generate \\nconvincing essays about a wide variety of topics while other models can draw credible images \\nbased on just a few prompts. Despite the excitement about foundational models, experts in our',\n",
       " 'convincing essays about a wide variety of topics while other models can draw credible images \\nbased on just a few prompts. Despite the excitement about foundational models, experts in our \\n \\n24 National Research Council. 2000. How people learn: Brain, mind, experience, and school. The National Academies Press. \\nhttps://doi.org/10.17226/9853; National Academies of Sciences, Engineering, and Medicine. 2018. How people learn II: \\nLearners, contexts, and cultures. The National Academies Press. https://doi.org/10.17226/24783 \\n25 Aleven, V., McLaughlin, E. A., Glenn, R. A., & Koedinger, K. R. (2016). Instruction based on adaptive learning \\ntechnologies. In Mayer, R.E. & Alexander, P.A., Handbook of research on learning and instruction, 522-560. ISBN: 113883176X',\n",
       " '19 \\nlistening sessions warned that AI models are narrower than visions for human learning and that \\ndesigning learning environments with these limits in mind remains very important. The models \\nare also brittle and can’t perform well when contexts change. In addition, they don’t have the \\nsame “common sense” judgment that people have, often responding in ways that are unnatural \\nor incorrect.26 Given the unexpected ways in which foundational models miss the mark, keeping \\nhumans in the loop remains highly important. \\nIntelligent Tutoring Systems: An Example of AI Models \\nOne long-standing type of AI-enabled technology is an Intelligent Tutoring System (ITS).27 In an \\nearly success, scientists were able to build accurate models of how human experts solve \\nmathematical problems. The resulting model was incorporated into a system that would observe \\nstudent problem solving as they worked on mathematical problems on a computer. Researchers',\n",
       " 'mathematical problems. The resulting model was incorporated into a system that would observe \\nstudent problem solving as they worked on mathematical problems on a computer. Researchers \\nwho studied human tutors found that feedback on specific steps (and not just right or wrong \\nsolutions) is a likely key to why tutoring is so effective.28 For example, when a student diverged \\nfrom the expert model, the system gave feedback to help the student get back on track.29 \\nImportantly, this feedback went beyond right or wrong, and instead, the model was able to \\nprovide feedback on specific steps of a solution process. A significant advancement of AI, \\ntherefore, can be its ability to provide adaptivity at the step-by-step level and its ability to do so \\nat scale with modest cost. \\nAs a research and development (R&D) field emerged to advance ITS, the work has gone beyond \\nmathematics problems to additional important issues beyond step-by-step problem solving. In',\n",
       " 'As a research and development (R&D) field emerged to advance ITS, the work has gone beyond \\nmathematics problems to additional important issues beyond step-by-step problem solving. In \\nthe early work, some limitations can be observed. The kinds of problems that an ITS could \\nsupport were logical or mathematical, and they were closed tasks, with clear expectations for \\nwhat a solution and solution process should look like. Also, the “approximation of reality” in \\nearly AI models related to cognition and not to other elements of human learning, for example, \\nsocial or motivational aspects. Over time, these early limitations have been addressed in two \\nways: by expanding the AI models and by involving humans in the loop, a perspective that is also \\nimportant now. Today, for example, if an ITS specializes in feedback as a student practices, a \\nhuman teacher could still be responsible for motivating student engagement and self-regulation',\n",
       " 'important now. Today, for example, if an ITS specializes in feedback as a student practices, a \\nhuman teacher could still be responsible for motivating student engagement and self-regulation \\nalong with other aspects of instruction. In other contemporary examples, the computer ITS \\nmight focus on problem solving practice, while teachers work with students in small groups. \\nFurther, students can be in the loop with AI, as is the case with “open learner models”—a type of \\nAI-enabled system that provides information to support student self-monitoring and \\nreflection.30 \\n \\n26 Dieterle, E., Dede, C. & Walker, M. (2022). The cyclical ethical effects of using artificial intelligence in education. AI & \\nSociety. https://link.springer.com/article/10.1007/s00146-022-01497-w \\n27 Mousavinasab, E., Zarifsanaiey, N., R. Niakan Kalhori, S., Rakhshan, M., Keikha, L., & Ghazi Saeedi, M. (2021). Intelligent',\n",
       " 'Society. https://link.springer.com/article/10.1007/s00146-022-01497-w \\n27 Mousavinasab, E., Zarifsanaiey, N., R. Niakan Kalhori, S., Rakhshan, M., Keikha, L., & Ghazi Saeedi, M. (2021). Intelligent \\ntutoring systems: A systematic review of characteristics, applications, and evaluation methods. Interactive Learning \\nEnvironments, 29(1), 142–163. https://psycnet.apa.org/doi/10.1080/10494820.2018.1558257 \\n28 Van Lehn, K. (2011) The relative effectiveness of human tutoring, intelligent tutoring systems, and other tutoring \\nsystems. Educational Psychologist, 46(4), 197-221. https://doi.org/10.1080/00461520.2011.611369 \\n29 Ritter, S., Anderson, J.R., Koedinger, K.R. & Corbett, A. (2007). Cognitive Tutor: Applied research in mathematics \\neducation. Psychonomic Bulletin & Review, 14, 249–255/ https://doi.org/10.3758/BF03194060 \\n30 Winne, P.H. (2021). Open learner models working in symbiosis with self-regulating learners: A research agenda.',\n",
       " '30 Winne, P.H. (2021). Open learner models working in symbiosis with self-regulating learners: A research agenda. \\nInternational Journal of Artificial Intelligence in Education, 31(3), 446-459. https://doi.org/10.1007/s40593-020-00212-4',\n",
       " '20 \\nAlthough R&D along the lines of an ITS should not limit the view of what’s possible, such an \\nexample is useful because so much research and evaluation has been done on the ITS approach. \\nResearchers have looked across all the available high-quality studies in a meta-analysis and \\nconcluded that ITS approaches are effective.31 Right now, many school systems are looking at \\nhigh-intensity human tutoring to help students with unfinished learning. Human tutoring is very \\nexpensive, and it is hard to find enough high-quality human tutors. With regard to large-scale \\nneeds, if it is possible for an ITS to supplement what human tutors do, it might be possible to \\nextend beyond the amount of tutoring that people can provide to students.  \\nImportant Directions for Expanding AI-Based Adaptivity \\nAdaptivity is sometimes referred to as “personalization.” Although this is a convenient term, \\nmany observers have noted how imprecise it is.32 For some educators, personalization means',\n",
       " 'Adaptivity is sometimes referred to as “personalization.” Although this is a convenient term, \\nmany observers have noted how imprecise it is.32 For some educators, personalization means \\ngiving learners “voice and choice,” and for others it means that a learning management system \\nrecommends an individual “playlist” of activities to each student. Hidden in that imprecision is \\nthe reality that many edtech products that personalize do so in limited ways. Adjusting the \\ndifficulty and the order of lesson materials are among the two most common ways that edtech \\nproducts adapt. And yet, any teacher knows there is more to supporting learning than adjusting \\nthe difficulty and sequence of materials. For example, a good teacher can find ways to engage a \\nstudent by connecting to their own past experiences and can shape explanations until they really \\nconnect in an “aha!” moment for that student. When we say, “meet the learner where they are,”',\n",
       " 'student by connecting to their own past experiences and can shape explanations until they really \\nconnect in an “aha!” moment for that student. When we say, “meet the learner where they are,” \\nhuman teachers bring a much more complete picture of each learner than most available edtech. \\nThe teacher is also not likely to “over personalize” (by performing like an algorithm that only \\npresents material for which the learner has expressed interest), thereby limiting the student’s \\nexposure to new topics. The nature of “teachable moments” that a human teacher can grasp is \\nbroader than the teachable moments today’s AI models grasp. \\nIn our listening sessions, we heard many ways in which the core models in an AI system must be \\nexpanded. We discuss these below. \\n1. From deficit-based to asset-oriented. Listening session attendees noted that the rhetoric \\naround adaptivity has often been deficit-based; technology tries to pinpoint what a',\n",
       " \"1. From deficit-based to asset-oriented. Listening session attendees noted that the rhetoric \\naround adaptivity has often been deficit-based; technology tries to pinpoint what a \\nstudent is lacking and then provides instruction to fill that specific gap. Teachers also \\norient to students' strengths; they find competencies or “assets” a student has and use \\nthose to build up the students’ knowledge. AI models cannot be fully equitable while \\nfailing to recognize or build upon each student’s sources of competency. AI models that \\nare more asset-oriented would be an advance.  \\n2. From individual cognition to including social and other aspects of learning. The \\nexisting adaptivity rhetoric has also tended to focus on individualized learning and \\nmostly on cognitive elements of learning, with motivational and other elements only \\nbrought in to support the cognitive learning goals. Attendees observe that their vision for\",\n",
       " 'mostly on cognitive elements of learning, with motivational and other elements only \\nbrought in to support the cognitive learning goals. Attendees observe that their vision for \\nlearning is broader than cognition. Social learning is important, for example, especially \\n \\n31 Kulik, J.A., & Fletcher, J.D. (2016). Effectiveness of intelligent tutoring systems: A meta-analytic review. Review of \\nEducational Research, 86(1), 42–78; Ma, W., Adescope, O.O, Nesbit, J.C. & Liu, Q. (2014). Intelligent tutoring systems and \\nlearning outcomes: A meta-analysis. Journal of Educational Psychology, 106(4), 901–918. http://dx.doi.org/10.1037/a0037123 \\n32 Plass, J.L., & Pawar, S. (2020). Toward a taxonomy of adaptivity for learning. Journal of Research on Technology in \\nEducation, 52(3), 275–300. https://doi.org/10.1080/15391523.2020.1719943;',\n",
       " '21 \\nfor students to learn to reason, explain, and justify. For students who are learning English, \\ncustomized and adaptive support for improving language skills while learning curricular \\ncontent is clearly important. Developing self-regulation skills is also important. A modern \\nvision of learning is not individualistic; it recognizes that students learn in groups and \\ncommunities too.  \\n3. From neurotypical to neurodiverse learners. AI models could help in including \\nneurodiverse learners (students who access, process, and interact with the world in less \\ncommon ways than “neurotypical” students) who could benefit from different learning \\npaths and from forms of display and input that fit their strengths. Constituents want AI \\nmodels that can support learning for neurodiverse learners and learners with disabilities. \\nThus, they want AI models that can work with multiple paths to learning and multiple',\n",
       " 'models that can support learning for neurodiverse learners and learners with disabilities. \\nThus, they want AI models that can work with multiple paths to learning and multiple \\nmodalities of interaction. Such models should be tested for efficacy, to guard against the \\npossibility that some students could be assigned a “personalized” but inadequate learning \\nresource. In addition, some systems for neurodiverse students are presently \\nunderutilized, so designs that support intended use will also be important. \\n4. From fixed tasks to active, open, and creative tasks. As mentioned above, AI models are \\nhistorically better at closed tasks like solving a math problem or logical tasks like playing \\na game. In terms of life-wide and lifelong opportunities, we value learning how to \\nsucceed at open-ended and creative tasks that require extended engagement from the \\nlearner, and these are often not purely mathematical or logical. We want students to learn',\n",
       " \"succeed at open-ended and creative tasks that require extended engagement from the \\nlearner, and these are often not purely mathematical or logical. We want students to learn \\nto invent and create innovative approaches. We want AI models that enable progress on \\nopen, creative tasks. \\n5. From correct answers to additional goals. At the heart of many adaptivity approaches \\nnow on the market, the model inside the technology counts students' wrong answers and \\ndecides whether to speed up, slow down, or offer a different type of learning support. Yet, \\nright and wrong answers are not the only learning goals. We want students to learn how \\nto self-regulate when they experience difficulties in learning, for example, such as being \\nable to persist in working on a difficult problem or knowing how and when to ask for \\nhelp. We want learners to become skilled in teamwork and in leading teams. As students \\ngrow, we want them to develop more agency and to be able to act on their own to\",\n",
       " 'help. We want learners to become skilled in teamwork and in leading teams. As students \\ngrow, we want them to develop more agency and to be able to act on their own to \\nadvance toward their own learning goals.  \\nListing every dimension of expansion that we heard in our listening sessions is beyond the scope \\nof this report. Some additional dimensions are presented in the following sections on Teaching, \\nAssessment, and Research. For example, in Research, we discuss all the ways in which AI systems \\nhave trouble with context—context that humans readily grasp and consider.  \\nOverall, constituents in the listening sessions realized we need an ambitious outlook on learning \\nto respond to the future today’s learners face. Constituents were concerned about ways in which \\nAI might narrow learning. For example, if the incorporation of AI into education slowed \\nattention to students’ skills on creative, open-ended tasks and their ability to lead and collaborate',\n",
       " 'AI might narrow learning. For example, if the incorporation of AI into education slowed \\nattention to students’ skills on creative, open-ended tasks and their ability to lead and collaborate \\nin teams, then school districts may be less able to realize their students’ progress in relation to a \\nPortrait of a Graduate who excels in communication and other skills valued in communities and \\ncareers.',\n",
       " '22 \\nConstituents reminded us that as we conceptualize what we want AI in edtech to accomplish, we \\nmust start and constantly revisit a human-centered vision of learning. \\nA Duality: Learning With and About AI \\nAs AI is brought into schools, two broad perspectives about AI in education arise: (1) AI in support \\nof student learning; and (2) support for learning about AI and related technologies. So far, we’ve \\ndiscussed AI systems and tools to support student learning and mastery of subjects like \\nmathematics and writing. Yet, it is also important that students learn about AI, critically examine \\nits presence in education and society, and determine its role and value in their own lives and \\ncareers. We discuss risks across each section in this report. Here, it is important for students to \\nbecome more aware of and savvy to the risks of AI—including risks of bias and surveillance—as \\nthey appear in all elements of their lives. In the recent past, schools have supported students’',\n",
       " 'become more aware of and savvy to the risks of AI—including risks of bias and surveillance—as \\nthey appear in all elements of their lives. In the recent past, schools have supported students’ \\nunderstanding of cybersecurity, for example. AI will bring new risks, and students need to learn \\nabout them. \\nWe are encouraged by efforts we’ve seen underway that would give students opportunities to \\nlearn about how AI works while also giving them opportunities to discuss relevant topics like \\nprivacy and security.33 Other learning goals are noted in the K-12 Computer Science Framework. \\nWe’ve seen that students can begin learning about AI in elementary, middle, and high school. \\nThey can use AI to design simulations and products that they find exciting. And we’ve seen that \\nstudents want to talk about the ethics of products they experience in their everyday lives and \\nhave much to say about the kinds of products they’d like to see or not see in school. (And later, in',\n",
       " 'students want to talk about the ethics of products they experience in their everyday lives and \\nhave much to say about the kinds of products they’d like to see or not see in school. (And later, in \\nthe Research section, we note the desire for co-design processes that involve students in creating \\nthe next generation of AI-enabled edtech). Overall, it’s important to balance attention to using AI \\nto support learning and giving students opportunities to learn about AI. \\nA Challenge: Systems Thinking About AI in Education \\nAs AI expands into the educational system, our listening session attendees reminded us that it \\nwill be entering parts or locations of the system that are presently dysfunctional. AI is certainly \\nnot a fix for broken systems, and instead, must be used with even more care when the systems’ \\ncontext is unstable or uncertain.  \\n \\n33 Forsyth, S., Dalton, B., Foster, E.H., Walsh, B., Smilack, J., & Yeh, T. (2021, May). Imagine a more ethical AI: Using stories',\n",
       " \"context is unstable or uncertain.  \\n \\n33 Forsyth, S., Dalton, B., Foster, E.H., Walsh, B., Smilack, J., & Yeh, T. (2021, May). Imagine a more ethical AI: Using stories \\nto develop teens' awareness and understanding of artificial intelligence and its societal impacts. In 2021 Conference on \\nResearch in Equitable and Sustained Participation in Engineering, Computing, and Technology (RESPECT). IEEE. \\nhttps://doi.org/10.1109/RESPECT51740.2021.9620549; Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., & Breazeal, C. \\n(2022). Integrating ethics and career futures with technical learning to promote AI literacy for middle school students: An \\nexploratory study. International Journal of Artificial Intelligence in Education, 1–35. https://doi.org/10.1007/s40593-022-\\n00293-3\",\n",
       " \"23 \\n“First and foremost, they are getting deployed in educational contexts \\nthat are already fragmented and broken and unequal. Technology \\ndoesn't discriminate—we do. So, as we think about the application of \\nthese new systems, we have to really think about the contextual \\napplication of AI.”  \\n—Dr. Nicole Turner \\nAs discussed previously, because AI systems and tools do not fully align with goals for learning, \\nwe have to design educational settings to situate AI in the right place, where educators and other \\nadults can make effective use of these tools for teaching and learning. Within the ITS example, \\nwe saw that AI could make learning by practicing math problems more effective, and a whole \\ncurricular approach might include roles for teachers that emphasize mathematical practices like \\nargumentation and modeling. Further, small-group work is likely to remain important: Students \\nmight work in small groups to use mathematics to predict or justify as they work on responding\",\n",
       " 'argumentation and modeling. Further, small-group work is likely to remain important: Students \\nmight work in small groups to use mathematics to predict or justify as they work on responding \\nto a realistic challenge. At the present, one “right place” for people, and not AI, is understanding \\nhow learning can be culturally responsive and culturally sustaining, as AI is not even close to \\nbeing ready to connect learning to the unique strengths in a student’s community and family. \\nOpen Questions About AI for Learning \\nWith advances occurring in the foundations for AI, opportunities to use AI in support of learning \\nare rapidly expanding. As we explore these opportunities, the open questions below deserve \\nongoing attention: \\n● To what extent is AI enabling adaptation to students’ strengths and not just deficits? Is AI \\nenabling improved support for learners with disabilities and English language learners? \\n● How are youth voices involved in choosing and using AI for learning?',\n",
       " 'enabling improved support for learners with disabilities and English language learners? \\n● How are youth voices involved in choosing and using AI for learning? \\n● Is AI leading to narrower student activities (e.g., procedural math problems), or the fuller \\nrange of activities highlighted in the National Educational Technology Plan (NETP), \\nwhich emphasizes features such as personalized learning, project-based learning, learning \\nfrom visualizations, simulations, and virtual reality, as well as learning across school, \\ncommunity, and familial settings? \\n● Is AI supporting the whole learner, including social dimensions of learning such as \\nenabling students to be active participants in small group and collaborative learning? For \\nexample, does AI contribute to aspects of student collaboration we value like shared \\nattention, mutual engagement, peer help, self-regulation, and building on each other’s \\ncontributions?',\n",
       " 'example, does AI contribute to aspects of student collaboration we value like shared \\nattention, mutual engagement, peer help, self-regulation, and building on each other’s \\ncontributions? \\n● When AI is used, are students’ privacy and data protected? Are students and their \\nguardians informed about what happens with their data? \\n● How strong are the processes or systems for monitoring student use of AI for barriers, \\nbias, or other undesirable consequences of AI use by learners? How are emergent issues \\naddressed? \\n● Is high-quality research or evaluations about the impacts of using the AI system for \\nstudent learning available? Do we know not only whether the system works but for whom \\nand under what conditions?',\n",
       " '24 \\nKey Recommendation: Seek AI Models Aligned to a Vision for Learning \\nWe’ve called attention to how advances in AI are important to adaptivity but also to ways in \\nwhich adaptivity is limited by the model’s inherent quality. We noted that a prior wave of edtech \\nused the term “personalized” in differing ways, and it was often important to clarify what \\npersonalization meant for a particular product or service. Thus, our key recommendation is to \\ntease out the strengths and limitations of AI models inside forthcoming edtech products and to \\nfocus on AI models that align closely to desired visions of learning. AI is now advancing rapidly, \\nand we should differentiate between products that have simple AI-like features inside and \\nproducts that have more sophisticated AI models.  \\nLooking at what’s happening in research and development, we can see significant effort and push \\ntoward overcoming these limitations. We noted that decision makers need to be careful about',\n",
       " 'Looking at what’s happening in research and development, we can see significant effort and push \\ntoward overcoming these limitations. We noted that decision makers need to be careful about \\nselecting AI models that might narrow their vision for learning, as general artificial intelligence \\ndoes not exist. And because AI models will always be narrower than real world experience, we \\nneed to proceed with systems thinking in which humans are in the loop, with the strengths and \\nweaknesses of the specific educational system considered. We hold that the full system for \\nlearning is broader than its AI component.',\n",
       " '25 \\nTeaching \\nTeachers have long envisioned many things that technology could make possible for teachers, \\ntheir classrooms, and their students but not the changes wrought by the recent pandemic. Today, \\nnearly all teachers have experienced uses of technologies for instruction that no one anticipated. \\nSome of those experiences were positive, and others were not. All of the experiences provide an \\nimportant context as we think further about teaching and technology. \\nThere is a critical need to focus on addressing the challenges teachers experience. It must \\nbecome easier for teachers to do the amazing work they always do. We must also remember why \\npeople choose the teaching profession and ensure they can do the work that matters. This \\nsection discusses examples of AI supporting teachers and teaching including these concepts: AI \\nassistants to reduce routine teaching burdens; AI that provides teachers with recommendations',\n",
       " 'section discusses examples of AI supporting teachers and teaching including these concepts: AI \\nassistants to reduce routine teaching burdens; AI that provides teachers with recommendations \\nfor their students’ needs and extends their work with students; and AI that helps teachers to \\nreflect, plan, and improve their practice. \\n“One opportunity I see with AI is being able to reduce the amount of \\nattention I have to give to administrative things and increase the amount \\nof attention I can give to my students with their learning needs in the \\nclassroom. So that\\'s the first one that I\\'d say that I\\'m super excited about \\nthe possibility of AI to support me as a teacher.\"  \\n—Vidula Plante \\nAlways Center Educators in Instructional Loops \\nTo succeed with AI as an enhancement to learning and teaching, we need to always center \\neducators (ACE). Practically speaking, practicing “ACE in AI” means keeping a humanistic view of',\n",
       " 'To succeed with AI as an enhancement to learning and teaching, we need to always center \\neducators (ACE). Practically speaking, practicing “ACE in AI” means keeping a humanistic view of \\nteaching front and center. ACE leads the Department to confidently respond “no” when asked \\n“will AI replace teachers?” ACE is not just about making teachers’ jobs easier but also making it \\npossible to do what most teachers want to do. That includes, for example, understanding their \\nstudents more deeply and having more time to respond in creative ways to teachable moments. \\nTo bring more precision to how and where we should center educators, we return to our \\nadvocacy for human in the loop AI and ask, what are the loops in which teachers should be \\ncentered? Figure 5 suggests three key loops (inspired by research on adaptivity loops34): \\n  \\n \\n34 Aleven, V., McLaughlin, E.A., Glenn, R.A., & Koedinger, K.R. (2016). Instruction based on adaptive learning technologies.',\n",
       " '34 Aleven, V., McLaughlin, E.A., Glenn, R.A., & Koedinger, K.R. (2016). Instruction based on adaptive learning technologies. \\nIn Mayer, R.E. & Alexander, P.A., Handbook of research on learning and instruction, 522-560. ISBN: 113883176X',\n",
       " '26 \\n \\n1. The loop in which teachers make moment-to-moment decisions as they do the \\nimmediate work of teaching.  \\n2. The loop in which teachers prepare for, plan, and reflect on teaching, which includes \\nprofessional development. \\n3. The loop in which teachers participate in decisions about the design of AI-enabled \\ntechnologies, participate in selecting the technologies, and shape the evaluation of \\ntechnologies—thus setting a context for not only their own classroom but those of fellow \\nteachers as well.  \\nFigure 5: Three ways to center educators as we conceptualize human in the loop AI  \\n \\n \\nPlease note that in the next section, on Formative Assessment, we also discuss teachers’ important \\nrole in feedback loops that support students and enable school improvement. That section also \\nincludes a discussion of the concepts of “bias” and “fairness,” which are important to teachers. \\nInsight: Using AI to Improve Teaching Jobs',\n",
       " 'includes a discussion of the concepts of “bias” and “fairness,” which are important to teachers. \\nInsight: Using AI to Improve Teaching Jobs \\nThe job of teaching is notoriously complex, with teachers making thousands of decisions each \\nday. Teachers participate in classroom processes, in interactions with students beyond \\nclassrooms, in work with fellow teachers, and in administrative functions. They also are part of \\ntheir communities and thus are expected to interact with families and caregivers.',\n",
       " '27 \\nIf the teacher is able to efficiently predict and understand the range of \\nother answers given by students in the class, it becomes possible to think \\ncreatively about the novel answer and figure how and why the student \\nmight have generated it.35 \\nWe think about how much easier some everyday tasks have become. We can request and receive \\nalerts and notifications about events. Selecting music that we want to hear used to be a multistep \\nprocess (even with digital music), and now we can speak the name of a song we want to hear, and \\nit plays. Likewise, mapping a journey used to require a cumbersome study of maps, but now cell \\nphones let us choose among several transportation options to reach a destination. Why can’t \\nteachers be supported to notice changing student needs and provided with supports to enact a \\ntechnology-rich lesson plan? Why can’t they more easily plan their students’ learning journeys?',\n",
       " 'teachers be supported to notice changing student needs and provided with supports to enact a \\ntechnology-rich lesson plan? Why can’t they more easily plan their students’ learning journeys? \\nWhen things change in a classroom, as they always do, why don’t the tools of the classroom make \\nit easier for teachers to adapt to student strengths and needs on the fly? \\nFigure 6: Teachers work about 50 hours a week, spending less than half the time in direct \\ninteraction with students. \\n \\n \\nA report by McKinsey36 first suggested that AI’s initial benefit could be to improve teaching jobs \\nby reducing low-level burdens in administrative or clerical work (Figure 6). The report also \\nsuggests that recovered time from AI-enabled technology should be rededicated toward more \\n \\n35 Hammerness, K., Darling-Hammond, L., & Bransford, J. (2005). Preparing teachers for a changing world: What teachers should \\nlearn and be able to do. Jossey-Bass. ISBN: 0787996343',\n",
       " '35 Hammerness, K., Darling-Hammond, L., & Bransford, J. (2005). Preparing teachers for a changing world: What teachers should \\nlearn and be able to do. Jossey-Bass. ISBN: 0787996343 \\n36 Bryant, J., Heitz,C., Sanghvi, S., & Wagle, D. (2020, January 14). How artificial intelligence will impact K-12 teachers. \\nMcKinsey. https://www.mckinsey.com/industries/education/our-insights/how-artificial-intelligence-will-impact-k-12-\\nteachers',\n",
       " '28 \\neffective instruction—particularly, outcomes such as reducing the average 11 hours of weekly \\npreparation down to only six. We highlight these opportunities and two others below. \\n1. Handling low-level details to ease teaching burdens and increase focus on students. A \\ngood teacher must master all levels of details, big and small. When working with a \\nparticular student, the teacher may wish to later send that student a helpful learning \\nresource. How will they remember to send it? A voice assistant or other forms of an AI \\nassistant could make it easier to stay organized by categorizing simple voice notes for \\nteachers to follow up on after a classroom session ends. We are beginning to see AI-\\nenabled voice assistants in the market, and they could do many simple tasks so that the \\nteachers can stay focused on students. These tasks can include record-keeping, starting \\nand stopping activities, controlling displays, speakers, and other technologies in the',\n",
       " \"teachers can stay focused on students. These tasks can include record-keeping, starting \\nand stopping activities, controlling displays, speakers, and other technologies in the \\nclassroom, and providing reminders. Many workers may eventually use assistants to \\nmake their jobs easier, and teachers are the most deserving of efforts to ease their jobs \\nnow.  \\n2. Extending beyond the teacher's availability with their students but continuing to \\ndeliver on the teacher’s intent. Teachers almost always want to do more with each \\nstudent than they can, given the limited number of hours before the next school day. A \\nteacher may wish to sit with the student as they practice 10 more math problems, giving \\nthem ongoing support and feedback. If the teacher can sit with the student for only three \\nproblems, perhaps they could delegate to an AI-enabled learning system to help with the \\nrest. Teachers cannot be at their best if on call at all hours to help with homework, but\",\n",
       " 'problems, perhaps they could delegate to an AI-enabled learning system to help with the \\nrest. Teachers cannot be at their best if on call at all hours to help with homework, but \\nperhaps they can indicate what types of supports, hints, and feedback they want students \\nto receive while studying after school hours. An AI assistant can ensure that students have \\nthat support wherever and whenever they do homework or practice skills on their own. \\nTeachers may wish to provide more extensive personal notes to families/caregivers, and \\nperhaps an AI assistant could help with drafts based on students’ recent classroom work. \\nThen, the teacher could review the AI-generated comments and quickly edit where \\nneeded before returning it to the student for another draft. AI tools might also help \\nteachers with language translation so they can work with all parents and caregivers of \\ntheir students. AI tools might also help teachers with awareness. For example, in the next',\n",
       " 'teachers with language translation so they can work with all parents and caregivers of \\ntheir students. AI tools might also help teachers with awareness. For example, in the next \\nsection, Formative Assessment, we note that teachers can’t always know what’s going on for \\neach student and in each small group of students; emerging products might signal to the \\nteacher when a student or teacher may need some more personal attention. \\n3. Making teacher professional development more productive and fruitful. Emerging \\nproducts already enable a teacher to record her classroom and allow an AI algorithm to \\nsuggest highlights of the classroom discussion worth reviewing with a professional \\ndevelopment coach.37 AI can compute metrics, such as whether students have been \\ntalking more or less, which are difficult for a teacher to calculate during a lesson.38 For \\n \\n37 Chen, G., Clarke, S., & Resnick, L.B. (2015). Classroom Discourse Analyzer (CDA): A discourse analytic tool for teachers.',\n",
       " \"37 Chen, G., Clarke, S., & Resnick, L.B. (2015). Classroom Discourse Analyzer (CDA): A discourse analytic tool for teachers. \\nTechnology, Instruction, Cognition and Learning, 10(2), 85-105 \\n38 Jensen, E., Dale, M., Donnelly, P.J., Stone, C., Kelly, S., Godley, A. & D'Mello, S.K. (2020). Toward automated feedback on \\nteacher discourse to enhance teacher learning. In Proceedings of the 2020 CHI Conference on Human Factors in \\nComputing Systems (CHI '20). https://doi.org/10.1145/3313831.3376418\",\n",
       " '29 \\nteachers who want to increase student engagement, these metrics can be a valuable tool. \\nClassroom simulation tools are also emerging and can enable teachers to practice their \\nskills in realistic situations.39 Simulators can include examples of teaching from a real \\nclassroom while changing the faces and voices of the participants so that teaching \\nsituations can be shared and discussed among teachers without revealing identities.  \\nNote the emphasis above on what listening-session panelist Sarah Hampton said about the \\nhuman touch. Teachers will feel that AI is helping them teach with a focus on their human \\nconnection to their students when the necessary (but less meaningful) burdens of teaching are \\nlessened. In Figure 7, below, see concerns that teachers raised about AI during listening sessions. \\nFigure 7: Concerns raised during the listening session about teaching with AI \\n \\nPreparing and Supporting Teachers in Planning and Reflecting',\n",
       " 'Figure 7: Concerns raised during the listening session about teaching with AI \\n \\nPreparing and Supporting Teachers in Planning and Reflecting \\nACE also means preparing teachers to take advantage of possibilities like those listed above and \\nmore. In the Research section, we highlight how pre-service education still tends to \\ncompartmentalize and inadequately address the topic of technology. That section suggests a \\nneed to invest in research about how to deeply integrate technology in pre-service teacher \\ntraining programs. In-service teachers, too, will need professional development to take \\nadvantage of opportunities that AI can provide, like those presented in the Teaching section. \\nProfessional development will need to be balanced not only to discuss opportunities but also to \\ninform teachers of new risks, while providing them with tools to avoid the pitfalls of AI.',\n",
       " 'Professional development will need to be balanced not only to discuss opportunities but also to \\ninform teachers of new risks, while providing them with tools to avoid the pitfalls of AI.  \\n \\n39 Ersozlu, Z., Ledger, S., Ersozlu, A., Mayne, F., & Wildy, H. (2021). Mixed-reality learning environments in teacher \\neducation: An analysis of TeachLivETM Research. SAGE Open, 11(3). https://doi.org/10.1177/21582440211032155.',\n",
       " '30 \\n“Humans are well suited to discern the outcomes…because we are the \\nones that have the capacity for moral reflection and empathy. So, in other \\nwords, I want the AI to help me really quickly and easily see what my \\nstudent needs in their learning journey.”  \\n—Sarah Hampton \\nBy nature, teaching requires significant time in planning as well to account for the breadth of \\nneeds across their rosters—especially for inclusive learning environments and students with IEPs \\nand 504 plans. AI could help teachers with recommendations that are tuned to their situation and \\ntheir ways of practicing teaching and support with adapting found materials to fit their exact \\nclassroom needs. For students with an IEP, AI could help with finding components to add to \\nlesson plans to fully address standards and expectations and to meet each student’s unique \\nrequirements. Even beyond finding components, AI might help adapt standardized resources to',\n",
       " 'lesson plans to fully address standards and expectations and to meet each student’s unique \\nrequirements. Even beyond finding components, AI might help adapt standardized resources to \\nbetter fit specific needs—for example, providing a voice assistant that allows a student with a \\nvisual difficulty to hear material and respond to it or permitting a group of students to present \\ntheir project using American Sign Language (ASL) which could be audibly voiced for other \\nstudents using an AI ASL-to-Spoken-English translation capability. Indeed, coordinating IEPs is \\ntime-consuming work that might benefit from supportive automation and customized \\ninteractivity that can be provided by AI. \\nReflection is important too. In the bustle of a classroom, it is sometimes difficult to fully \\nunderstand what a student is expressing or what situations lead to certain positive or negative \\nbehaviors. Again, context is paramount. In the moment, teachers may not be aware of external',\n",
       " 'understand what a student is expressing or what situations lead to certain positive or negative \\nbehaviors. Again, context is paramount. In the moment, teachers may not be aware of external \\nevents that could shape their understanding of how students are showing up in their classrooms. \\nTools that notice patterns and suggest ways to share information might help students and \\nteachers communicate more fully about strengths and needs. \\nDesigning, Selecting, and Evaluating AI Tools \\nThe broadest loop teachers should be part of is the loop that determines what classroom tools do \\nand which tools are available. Today, teachers already play a role in designing and selecting \\ntechnologies. Teachers can weigh in on usability and feasibility. Teachers examine evidence of \\nefficacy and share their findings with other school leaders. Teachers already share insights on \\nwhat is needed to implement technology well.',\n",
       " 'efficacy and share their findings with other school leaders. Teachers already share insights on \\nwhat is needed to implement technology well.  \\nWhile these concerns will continue, AI will raise new concerns too. For example, the following \\nFormative Assessment section raises concerns about bias and fairness that can lead to algorithmic \\ndiscrimination. Those concerns go beyond data privacy and security; they raise attention to how \\ntechnologies may unfairly direct or limit some students’ opportunities to learn. A key takeaway \\nhere is that teachers will need time and support so they can stay abreast of both the well-known \\nand the newer issues that are arising and so they can fully participate in design, selection, and \\nevaluation processes that mitigate risks. \\nChallenge: Balancing Human and Computer Decision-Making \\nOne major new challenge with AI-enabled tools for teachers is that AI can enable autonomous',\n",
       " 'evaluation processes that mitigate risks. \\nChallenge: Balancing Human and Computer Decision-Making \\nOne major new challenge with AI-enabled tools for teachers is that AI can enable autonomous \\nactivity by a computer, and thus when a teacher delegates work to an AI-enabled tool, it may',\n",
       " '31 \\ncarry on with that work somewhat independently. Professor Inge Molenaar40 has wondered \\nabout the challenges of control in a hybrid teaching scenario: When should a teacher be in \\ncontrol? What can be delegated to a computational system? How can a teacher monitor the AI \\nsystem and override its decisions or take back control as necessary? \\nFigure 8: The tension between human and AI decision making: Who is in control? \\n \\nFigure 8 expresses the tension around control. To the left, the teacher is fully in control, and \\nthere is no use of AI in the classroom. To the right, the technology is fully in control with no \\nteacher involved—a scenario which is rarely desirable. The middle ground is not one \\ndimensional and involves many choices. Molenaar analyzed products and suggests some \\npossibilities: \\n● The technology only offers information and recommendations to the teacher. \\n● The teacher delegates specific types of tasks to the technology, for example, giving',\n",
       " 'possibilities: \\n● The technology only offers information and recommendations to the teacher. \\n● The teacher delegates specific types of tasks to the technology, for example, giving \\nfeedback on a particular math assignment or sending out reminders to students before an \\nassignment is due. \\n● The teacher delegates more broadly to the technology, with clear protocols for alerts, for \\nmonitoring, and for when the teacher takes back control. \\nThese and other choices need to be debated openly. For example, we may want to define \\ninstructional decisions that have different kinds of consequences for a student and be very \\ncareful about delegating control over highly consequential decisions (for example, placement in \\na next course of study or disciplinary referrals). For human in the loop to become more fully \\nrealized, AI technologies must allow teacher monitoring, have protocols to signal a teacher when',\n",
       " 'a next course of study or disciplinary referrals). For human in the loop to become more fully \\nrealized, AI technologies must allow teacher monitoring, have protocols to signal a teacher when \\ntheir judgment is needed, and allow for classroom, school, or district overrides when they \\ndisagree with an instructional choice for their students. We cannot forget that if a technology \\nallows a teacher choice—which it should—it will take significant time for a teacher to think \\nthrough and set up all the options, requiring greater time initially.  \\nChallenge: Making Teaching Jobs Easier While Avoiding Surveillance \\nWe also recognize that the very technologies that make jobs easier might also introduce new \\npossibilities for surveillance (Figure 9). In a familiar example, when we enable a voice assistant in \\nthe kitchen, it might help us with simple household tasks like setting a cooking timer. And yet the',\n",
       " 'the kitchen, it might help us with simple household tasks like setting a cooking timer. And yet the \\nsame voice assistant might hear things that we intended to be private. This kind of dilemma will \\n \\n40 Molenaar, I. (2022). Towards hybrid human-AI learning technologies. European Journal of Education, 00, 1–14. \\nhttps://doi.org/10.1111/ejed.12527',\n",
       " '32 \\noccur in classrooms and for teachers. When they enable an AI-assistant to capture data about \\nwhat they say, what teaching resources they search for, or other behaviors, the data could be \\nused to personalize resources and recommendations for the teacher. Yet the same data might \\nalso be used to monitor the teacher, and that monitoring might have consequences for the \\nteacher. Achieving trustworthy AI that makes teachers’ jobs better will be nearly impossible if \\nteachers experience increased surveillance. \\nA related tension is that asking teachers to be “in the loop” could create more work for teachers if \\nnot done well, and thus, being in the loop might be in tension with making teaching jobs easier. \\nAlso related is the tension between not trusting AI enough (to obtain assistance) or trusting it too \\nmuch (and incurring surveillance or loss of privacy). For example, researchers have documented',\n",
       " 'Also related is the tension between not trusting AI enough (to obtain assistance) or trusting it too \\nmuch (and incurring surveillance or loss of privacy). For example, researchers have documented \\nthat people will follow instructions from a robot during a simulated fire emergency even when \\n(a) they are told the robot is broken and (b) the advice is obviously wrong.41 We anticipate \\nteachers will need training and support to understand how and when they will need to exercise \\nhuman judgement. \\nFigure 9: Highly customized assistance vs. increased teacher surveillance \\n \\nChallenge: Responding to Students’ Strengths While Protecting Their \\nPrivacy \\nEducators seek to tackle inequities in learning, no matter how they manifest locally (e.g. in access \\nto educational opportunities, resources, or supports). In culturally responsive42 and culturally \\nsustaining43 approaches, educators design materials to build on the “assets”—individual,',\n",
       " 'to educational opportunities, resources, or supports). In culturally responsive42 and culturally \\nsustaining43 approaches, educators design materials to build on the “assets”—individual, \\ncommunity, and cultural strengths that students bring to learning. Along with considering assets, \\nof course, educators must meet students where they are, including both strengths and needs. AI \\ncould assist in this process by helping teachers with customizing curricular resources, for \\nexample. But to do so, the data inputted in an AI-enabled system would have to provide more \\ninformation about the students. This information could be, but need not be, demographic \\ndetails. It could also be information about students’ preferences, outside interests, relationships, \\n \\n41 Wagner, A.R., Borenstein, J. & Howard, A. (September 2018). Overtrust in the robotics age. Communications of the ACM, \\n61(9),22-24. https://doi.org/10.1145/3241365',\n",
       " '41 Wagner, A.R., Borenstein, J. & Howard, A. (September 2018). Overtrust in the robotics age. Communications of the ACM, \\n61(9),22-24. https://doi.org/10.1145/3241365 \\n42 Gay, G. (2018). Culturally responsive teaching: Theory, research, and practice. Teachers College Press. ISBN: 978-0807758762 \\n43 Paris, D., & Alim, H.S. (Eds.). (2017). Culturally sustaining pedagogies: Teaching and learning for justice in a changing \\nworld. Teachers College Press. ISBN: 978-0807758342',\n",
       " '33 \\nor experiences.44 What happens to this data, how it is deleted, and who sees it is of huge concern \\nto educators. As educators contemplate using AI-enabled technologies to assist in tackling \\neducational inequities, they must consider whether the information about students shared with \\nor stored in an AI-enabled system is subject to federal or state privacy laws, such as FERPA. \\nFurther, educators must consider whether interactions between students and AI systems create \\nrecords that must be protected by law, such as when a chatbot or automated tutor generates \\nconversational or written guidance to a student. Decisions made by AI technologies, along with \\nexplanations of those decisions that are generated by algorithms may also be records that must \\nbe protected by law. Therein, a third tension emerges, between more fully representing students \\nand protecting their privacy (Figure 10). \\nFigure 10: Responding to students’ strengths while fully protecting student privacy',\n",
       " 'and protecting their privacy (Figure 10). \\nFigure 10: Responding to students’ strengths while fully protecting student privacy \\nFurther, representation would be just a start toward a solution. As discussed earlier in this report, \\nAI can introduce algorithmic discrimination through bias in the data, code, or models within AI-\\nenhanced edtech. Engineers develop the pattern detection in AI models using existing data, and \\nthe data they use may not be representative or may contain associations that run counter to \\npolicy goals. Further, engineers shape the automations that AI implements when it recognizes \\npatterns, and the automations may not meet the needs of each student group with a diverse \\npopulation. The developers of AI are typically less diverse than the populations they serve, and \\nas a consequence, they may not anticipate the ways in which pattern detection and automation \\nmay harm a community, group, or individual.',\n",
       " 'as a consequence, they may not anticipate the ways in which pattern detection and automation \\nmay harm a community, group, or individual. \\nAI could help teachers to customize and personalize materials for their students, leveraging the \\nteacher’s understanding of student needs and strengths. It is time consuming to customize \\ncurricular resources, and teachers are already exploring how AI chatbots can help them design \\nadditional resources for their students. An elementary school teacher could gain powerful \\nsupports for changing the visuals in a storybook to engage their students or for adapting \\nlanguage that poorly fits local manners of speaking or even for modifying plots to incorporate \\nother dimensions of a teacher’s lesson. In the Learning section, we noted that AI could help \\nidentify learner strengths. For example, a mathematics teacher may not be aware of ways in \\nwhich a student is making great sense of graphs and tables about motions when they are in',\n",
       " 'identify learner strengths. For example, a mathematics teacher may not be aware of ways in \\nwhich a student is making great sense of graphs and tables about motions when they are in \\nanother teacher’s physics classroom and might not realize that using similar graphs about \\n \\n44 Zacamy, J. & Roschelle, J. (2022). Navigating the tensions: How could equity-relevant research also be agile, open, and \\nscalable? Digital Promise. http://hdl.handle.net/20.500.12265/159; Baker, R.S., Esbenshade, L., Vitale, J., & Karumbaiah, S. \\n(2022). Using demographic data as predictor variables: A questionable choice. https://doi.org/10.35542/osf.io/y4wvj',\n",
       " '34 \\nmotion could help with their linear function lesson. AI might help teachers when they seek to \\nreflect student strengths by creating or adapting instructional resources. \\nYet, the broad equity challenges of avoiding algorithmic discrimination while increasing \\ncommunity and cultural responsiveness must be approached within the four foundations we \\nearlier outlined: human in the loop, equity, safety and effectiveness, and evaluation of AI models. \\nWe cannot expect AI models to respect cultural responsiveness. The Department is particularly \\nconcerned that equity is something that engaged educators and other responsive adults are in the \\nbest position to address and something that is never solely addressable as a computational \\nproblem. \\nQuestions Worth Asking About AI for Teaching \\nAs leaders in both pre-service and post-service teacher education contemplate how AI can \\nimprove teaching (along with policymakers, developers, and researchers), we urge all in the',\n",
       " 'As leaders in both pre-service and post-service teacher education contemplate how AI can \\nimprove teaching (along with policymakers, developers, and researchers), we urge all in the \\necosystem to spend more time asking these questions: \\n• Is AI improving the quality of an educator’s day-to-day work? Are teachers experiencing \\nless burden and more ability to focus and effectively teach their students? \\n• As AI reduces one type of teaching burden, are we preventing new responsibilities or \\nadditional workloads being shifted and assigned to teachers in a manner that negates the \\npotential benefits of AI? \\n• Is classroom AI use providing teachers with more detailed insights into their students and \\ntheir strengths while protecting their privacy?  \\n• Do teachers have oversight of AI systems used with their learners? Are they exercising \\ncontrol in the use of AI-enabled tools and systems appropriately or inappropriately \\nyielding decision-making to these systems and tools?',\n",
       " 'control in the use of AI-enabled tools and systems appropriately or inappropriately \\nyielding decision-making to these systems and tools? \\n• When AI systems are being used to support teachers or to enhance instruction, are the \\nprotections against surveillance adequate? \\n• To what extent are teachers able to exercise voice and decision-making to improve \\nequity, reduce bias, and increase cultural responsiveness in the use of AI-enabled tools \\nand systems? \\nKey Recommendation: Inspectable, Explainable, Overridable AI \\nIn the Introduction, we discuss the notion that when AI is incorporated into a system, the core of \\nthe AI is a model. In the Learning section, we discuss that we need to be careful that models align \\nto the learning we envision (e.g., that they aren’t too narrow). Now, based on the needs of \\nteachers (as well as students and their families/caregivers), we add another layer to our criteria',\n",
       " 'to the learning we envision (e.g., that they aren’t too narrow). Now, based on the needs of \\nteachers (as well as students and their families/caregivers), we add another layer to our criteria \\nfor good AI models: the need for explainability.45 Some AI models can recognize patterns in the \\nworld and do the right action, but they cannot explain why (e.g., how they arrived at the \\n \\n45 Khosravi, H., Shum, S.B., Chen, G, Conati, C., Tsai,Y-S., Kay, J., Knight, S., Martinez-Maldonado, R., Sadiq, S., Gašević, D. \\n(2022). Explainable artificial intelligence in education. Computers and Education: Artificial Intelligence, 3. \\nhttps://doi.org/10.1016/j.caeai.2022.100074',\n",
       " '35 \\nconnection between the pattern and the action). This lack of explainability will not suffice for \\nteaching; teachers will need to know how an AI model analyzed the work of one of their students \\nand why the AI model recommended a particular tutorial, resource, or next step to the student.  \\nThus, explainability of an AI system’s decision is key to a teacher’s ability to judge that \\nautomated decision. Such explainability helps teachers to develop appropriate levels of trust and \\ndistrust in AI, particularly to know where the AI model tends to make poor decisions. \\nExplainability is also key to a teacher’s ability to monitor when an AI system may be unfairly \\nacting on the wrong information (and thus may be biased. We discuss bias and fairness more in \\nthe Assessment section next). \\nSurrounding the idea of explainability is the need for teachers to be able to inspect what an AI \\nmodel is doing. For example, what kinds of instructional recommendations are being made and',\n",
       " 'Surrounding the idea of explainability is the need for teachers to be able to inspect what an AI \\nmodel is doing. For example, what kinds of instructional recommendations are being made and \\nto which students? Which students are being assigned remedial work in a never ended loop? \\nWhich are making progress? Dashboards in current products present some of this information, \\nbut with AI, teachers may want to further explore which decisions are being made and for whom \\nand know of the student-specific factors that an AI model had available (and possibly which \\nfactors were influential) when reaching a particular decision. For example, some of today’s \\nadaptive classroom products use limited recommendation models that only consider student \\nsuccess on the last three mathematics problems and do not consider other variables that a \\nteacher would know to consider, such as whether a student has an IEP Plan or other needs.',\n",
       " 'success on the last three mathematics problems and do not consider other variables that a \\nteacher would know to consider, such as whether a student has an IEP Plan or other needs. \\nOur call for attending to equity considerations as we evaluate AI models requires information \\nabout how discriminatory bias may arise in particular AI systems and what developers have done \\nto address it. This can only be achieved with transparency for how the tools use datasets to \\nachieve outcomes and what data they have available or that a teacher could include in her \\njudgement but are not available to the system (IEP status is offered as an example above).  \\nTeachers will also need the ability to view and make their own judgement about automated \\ndecisions, such as decisions about which set of mathematics problems a student should work on \\nnext. They need to be able to intervene and override decisions when they disagree with the logic',\n",
       " 'decisions, such as decisions about which set of mathematics problems a student should work on \\nnext. They need to be able to intervene and override decisions when they disagree with the logic \\nbehind an instructional recommendation.46 Teachers need protection against adverse \\nramifications when they assert human judgement over an AI system’s decision. \\n \\n46 Ruiz, P. & Fusco, J. (2022). Teachers partnering with artificial intelligence: Augmentation and automation. Digital Promise. \\nhttps://digitalpromise.org/2022/07/06/teachers-partnering-with-artificial-intelligence-augmentation-and-automation/',\n",
       " '36 \\n“These systems sometimes are seen as a black box kind of a situation \\nwhere predictions are made based on lots of data. But what we need is to \\nhave a clear view—to clearly show how those recommendations or those \\ninteractions are made and what evidence is used or what data is used to \\nbe able to make those recommendations so teachers and everyone \\ninvolved know about why that kind of system is providing that type of \\ninformation. So, having open learning environments or inspectable \\nlearner models or applications where the stakeholders can understand \\nhow these systems make decisions or recommendations is going to be an \\nimportant aspect in the future of teaching and learning.”  \\n—Diego Zapata-Rivera',\n",
       " '37 \\nFormative Assessment \\nFormative assessment is traditionally a key use of edtech because feedback loops are vital to \\nimproving teaching and learning.47 As we have emphasized throughout this report, a top priority \\nwith AI is to keep humans in the loop and in control, which includes focusing on the people \\nengaged with formative assessments: students, teachers, school leaders, families/caregivers, and \\nothers who support learners. In the definition below, please note the overlap between definitions \\nof AI and formative assessment; both have to do with detecting patterns and choosing a future \\ncourse of action (that adapts to learner strengths and needs). \\nAssessment refers to all those activities undertaken by teachers, and by \\nthe students in assessing themselves, which provide information to be \\nused as feedback to modify the teaching and learning activities in which \\nthey are engaged. Such assessment becomes “formative assessment”',\n",
       " 'used as feedback to modify the teaching and learning activities in which \\nthey are engaged. Such assessment becomes “formative assessment” \\nwhen the evidence is actually used to adapt the teaching to meet the \\nneeds.48 \\nBuilding on Best Practices \\nA number of dimensions hold potential for shaping the future of formative assessments, and \\nmany have ready extensions to the field of AI-enabled systems and tools. For example, the 2017 \\nNETP discussed how technology can lead to improved formative assessments along seven \\ndimensions, listed below: \\n1. Enabling Enhanced Question Types: \\nto give students more ways to show what they know and can do. \\n2. Measurement of Complex Competencies:  \\nto better elicit growth in important skills that go beyond typical subject matter standards, \\nfor example, in measuring practices, social skills like teamwork, self-regulation, and \\nwork-relevant skills (e.g., making presentations or leading teams). \\n3. Providing Real-Time Feedback:',\n",
       " 'for example, in measuring practices, social skills like teamwork, self-regulation, and \\nwork-relevant skills (e.g., making presentations or leading teams). \\n3. Providing Real-Time Feedback:  \\nto maintain and increase student engagement and to support effective learning, \\nproviding timely and helpful responses and suggestions to each learner. \\n4. Increasing Accessibility:  \\nto include neurodiverse learners and to engage learners’ best communication capabilities \\nas they share what they know and can do. \\n \\n47 Shute, V.J. (2008). Focus on formative feedback. Review of Educational Research, 78(1), 153–189. \\nhttps://doi.org/10.3102/0034654307313795 \\n48 Black, P. & Wiliam, D. (1998). Inside the black box: Raising standards through classroom assessment. Phi Delta Kappan, \\n92(1), 81-90. https://kappanonline.org/inside-the-black-box-raising-standards-through-classroom-assessment/',\n",
       " '38 \\n5. Adapting to Learner Ability and Knowledge:  \\nto make assessments more precise and efficient. \\n6. Embedded Assessment in the Learning Process:  \\nto emphasize an assessment’s role in improving teaching and learning (this report does \\nnot focus on assessment for accountability purposes). \\n7. Assess for Ongoing Learning: \\nto reveal progress over time and not just predetermined milestones. \\nAI models and AI-enabled systems may have potential to strengthen formative assessments. In \\none example, a question type that invites students to draw a graph or create a model can be \\nanalyzed with AI algorithms,49 and similar student models might be grouped for the teacher to \\ninterpret. Enhanced formative assessment may enable teachers to better respond to students’ \\nunderstanding of a concept like “rate of change” in a complex, real-world situation. AI can also \\ngive learners feedback on complex skills, such as learning American Sign Language50 or speaking',\n",
       " 'understanding of a concept like “rate of change” in a complex, real-world situation. AI can also \\ngive learners feedback on complex skills, such as learning American Sign Language50 or speaking \\na foreign language51 and in other practice situations where no person is available to provide \\nimmediate feedback. \\nGenerally, an AI assistant may be able to reduce the load for teachers related to grading simpler \\naspects of student responses, allowing the teacher to focus their specialized judgment on \\nimportant qualities of a whole essay or a complex project. We also may be able to better provide \\nfeedback with accessibility. For example, an AI-enabled learning technology may be able to \\ninteract verbally with a student about their response to an essay prompt, asking questions that \\nguide the student to clarify their argument without requiring the student to read a screen or type \\nat a keyboard. In the examples shared earlier in the Learning section, we also see that AI can be',\n",
       " 'guide the student to clarify their argument without requiring the student to read a screen or type \\nat a keyboard. In the examples shared earlier in the Learning section, we also see that AI can be \\nembedded in the learning process, providing feedback to students as they work to solve a \\nproblem, rather than only later after the student has reached a wrong answer. When formative \\nassessment is more embedded, it can better support learning, and timely feedback is critical.52  \\nAlthough there are many points of connection like these between AI and formative assessments, \\nour listening sessions also revealed attendees’ desire to tackle some existing shortcomings in the \\nfield of formative assessment; namely, the time-consuming and sometime onerous nature of \\ntaking tests, quizzes, or other assessments and the lack of perceived value in the feedback loop by \\nteachers and students.  \\nImplications for Teaching and Learning',\n",
       " 'taking tests, quizzes, or other assessments and the lack of perceived value in the feedback loop by \\nteachers and students.  \\nImplications for Teaching and Learning  \\nReal-time instructional feedback can be beneficial when it helps learners and teachers to \\nimprove. But common experience too often leaves students and teachers with unpleasant \\nfeelings toward assessment and thus poses a provocative conflict between the potential benefits \\n \\n49 Zhai, X., He, P., Krajcik, J. (2022). Applying machine learning to automatically assess scientific models. Journal of Research \\nin Science Teaching. https://doi.org/10.1002/tea.21773 \\n50 Shao, Q., Sniffen, A., Blanchet, J., Hillis, M.E., Shi, X., Haris, T.K., & Balkcom, D. (2020). Teaching american sign language \\nin mixed reality. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 4(4), 1-27. \\nhttps://doi.org/10.1145/3432211',\n",
       " 'in mixed reality. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 4(4), 1-27. \\nhttps://doi.org/10.1145/3432211 \\n51 Godwin-Jones, R. (2021). Big data and language learning: Opportunities and challenges. \\u2028Language Learning & Technology, \\n25(1), 4–19. http://hdl.handle.net/10125/44747 \\n52 Wiggins, G. (2015). Seven keys to effective feedback. ACSD. https://www.ascd.org/el/articles/seven-keys-to-effective-\\nfeedback',\n",
       " '39 \\nof data collected through formative assessments and the practical implications of administering \\nadditional assessments in classrooms and schools. \\nSome AI-enabled systems and tools seek to address this potential conflict. For example, one AI-\\nenabled reading tutor listens to students as they read aloud and provides on-the-spot feedback to \\nimprove their reading.53 Students reportedly enjoyed reading aloud, and the approach was \\neffective. Researchers have also embedded formative assessments in games so that students can \\nshow how well they understand Newtonian physics as they play increasingly difficult levels of a \\ngame.54 If a student can more easily ask for and receive help when they feel frustrated or \\nconfused, reducing those feelings can feel encouraging. Student feelings of safety, confidence, \\nand trust in the feedback generated by these AI-enabled systems and tools are essential to',\n",
       " 'confused, reducing those feelings can feel encouraging. Student feelings of safety, confidence, \\nand trust in the feedback generated by these AI-enabled systems and tools are essential to \\nshowcase their learning. That focus on learning growth and gains is optimal (absent negative \\nconsequences or a high-stakes environment).55 \\nAI-enhanced formative assessments may have the potential to save teachers’ time (e.g., time \\nspent on grading), allowing the instructor to spend more time engaged in helping students. AI-\\nenhanced assessments may also benefit teachers if they provide detailed insights about student \\nstrengths or needs that may not be visible and if they support instructional adaptation or \\nimprovement by suggesting a small set of evidence-based recommendations for helping students \\nmaster content. Such assessments may also be helpful outside of the classroom if it can provide \\nfeedback when the teacher is not available, for example, in completing homework or practicing a',\n",
       " 'master content. Such assessments may also be helpful outside of the classroom if it can provide \\nfeedback when the teacher is not available, for example, in completing homework or practicing a \\nconcept during study hall. As we discussed in the Teaching section, an essential aspect of \\ndeploying AI-based formative assessment must be centering teachers in system design. \\nInsight: AI Can Enhance Feedback Loops \\nThe term “formative assessment” does not singularly mean a test or a measurement. Assessment \\nbecomes formative when it results in useful reflections and changes to the course of teaching, \\nlearning, or both.56 The term “feedback loops” emphasizes that measurement is only part of the \\nprocess. Feedback loops that lead to instructional improvement—including adaptations in \\nteaching and learning—yield the strongest outcomes for students.  \\nWe also use “feedback loops” as a plural term because there are many types and levels of loops',\n",
       " 'teaching and learning—yield the strongest outcomes for students.  \\nWe also use “feedback loops” as a plural term because there are many types and levels of loops \\nthat are important. Students can benefit from feedback when they work individually, as a \\nmember of a small group, or in a classroom discussion. Feedback loops are valuable “in the \\nmoment”—for example, as a student practices a skill. Further, feedback loops are valuable when \\nthey cover larger spans of effort and reflections, such as at the end of presenting a project or \\nterm paper. In addition, feedback loops can assist teachers, for example, helping them notice \\n \\n53 Mostow, J., Aist, G., Burkhead, P., Corbett, A., Cuneo, A., Eitelman, S., Huang, C., Junker, B., Sklar, M.B., & Tobin, B. \\n(2003). Evaluation of an automated reading tutor that listens: Comparison to human tutoring and classroom instruction. \\nJournal of Educational Computing Research, 29(1), 61–117. https://doi.org/10.2190/06AX-QW99-EQ5G-RDCF',\n",
       " \"Journal of Educational Computing Research, 29(1), 61–117. https://doi.org/10.2190/06AX-QW99-EQ5G-RDCF \\n54 Shute, V.J., Ventura, M., & Kim, Y.J. (2013). Assessment and learning of qualitative physics in Newton's Playground. The \\nJournal of Educational Research, 106(6), 423–430. https://doi.org/10.1080/00220671.2013.832970 \\n55 Shute, V J. (2008). Focus on formative feedback. Review of Educational Research, 78(1), 153–189. \\nhttps://doi.org/10.3102/0034654307313795 \\n56 Black, P., & Wiliam, D. (2009). Developing the theory of formative assessment. Educational Assessment, Evaluation and \\nAccountability, 21(1), 5-31. https://doi.org/10.1007/s11092-008-9068-5\",\n",
       " '40 \\ntheir own patterns of responding to students’ ideas. Moreover, feedback loops are critical to the \\ncontinuous improvement of products and the implementation of programs.  \\nDue to the importance of feedback loops, formative assessment could be a leading area for \\nschools’ explorations of powerful uses of AI in teaching and learning. Educators can build upon \\nalignments between their long-standing visions for formative assessment and the emerging \\ncapabilities that AI holds. Further, the professional assessment community brings a toolkit for \\nasking and answering questions about topics like bias and fairness. The psychometric toolkit of \\nmethods is a strong start toward the questions that must be asked and answered because it \\nalready contains ways to measure bias and fairness and, more generally, to benchmark the \\nquality of formative assessments. But as our discussion reveals, AI can only make feedback loops',\n",
       " 'already contains ways to measure bias and fairness and, more generally, to benchmark the \\nquality of formative assessments. But as our discussion reveals, AI can only make feedback loops \\nbetter if we keep a firm eye on the weaknesses of AI and how AI introduces new concerns. \\nAn Example: Automated Essay Scoring \\nOne instructive example is Automated Essay Scoring (AES). To become strong writers, which is a \\nvaluable life skill, students need regular and specific feedback. However, reviewing and \\nproviding feedback on essays is very time consuming for humans. Hence, Ellis Page provided a \\nfirst vision for computer programs that could review and provide feedback on student essays in 196657, \\nand much effort has gone into AES technologies in the intervening 56 years. Many research \\nreview articles are available to summarize the progress, which has been impressive.58 Further, \\nsome of today’s applications of AES technologies will be familiar to readers, such as Grammarly,',\n",
       " 'review articles are available to summarize the progress, which has been impressive.58 Further, \\nsome of today’s applications of AES technologies will be familiar to readers, such as Grammarly, \\nTurnitin, and the various essay analysis engines used by publishers and assessment companies. \\nAlso note that while the traditional AES functionality emphasizes scoring or rating essays, newer \\nAI-enabled products focus more on providing students with constructive criticism and \\ndeveloping their skills as writers. Writing is a life skill that is important to the pursuit of college \\nand career ambitions, and developing writers require comprehensive feedback. If developers \\ncould inexpensively augment human feedback to developing writers with AI feedback, it’s \\npossible that support for learning to write could become more equitable. \\nAnd yet, AES is an instructive example because researchers have analyzed limitations, too.59 AES',\n",
       " 'possible that support for learning to write could become more equitable. \\nAnd yet, AES is an instructive example because researchers have analyzed limitations, too.59 AES \\ntechnologies in AI can analyze some features of student essays but can also be misled by the \\nlength of an essay, by a student who places appropriate keywords in sentences that don’t make \\nsense, and other flaws that a human reader would easily notice. In a telling quote, one team that \\nreviewed the state of the art wrote this: \\nThe authors further note that while human and AI judgements of essays may correlate, people \\nand computers are not noticing the same things in student writing. Due to these limitations, we \\nmust continue to emphasize a human in the loop foundation for AI-enhanced formative \\nassessment. AI may support but not replace high-quality, human-led processes and practices of \\nformative assessment in schools.',\n",
       " 'assessment. AI may support but not replace high-quality, human-led processes and practices of \\nformative assessment in schools. \\n \\n57 Page, E.B. (1966). The imminence of grading essays by computer. Phi Delta Kappan, 47(5), 238–243 \\n58 Ke, Z., & Ng, V. (2019). Automated essay scoring: A survey of the state of the art. In Proceedings of the Twenty-Eighth \\nInternational Joint Conference on Artificial Intelligence, 6300–6308. https://doi.org/10.24963/ijcai.2019/879 \\n59 Doewes, A. & Pechenizkiy, M. (2021). On the limitations of human-computer agreement in automated essay scoring. In \\nProceedings of the 14th International Conference on Educational Data Mining (EDM21). \\nhttps://educationaldatamining.org/EDM2021/virtual/static/pdf/EDM21_paper_243.pdf',\n",
       " '41 \\n \\n“Nevertheless, the time when AES systems will be able to operate on a \\npar with human judges, with similar levels of connoisseurship for such \\nfeatures as meaning, emotion, originality, creativity, fluency, sense of \\naudience and so on, arguably remains a long way off.” \\n—Gardner, O’Leary, and Yuan60  \\nKey Opportunities for AI in Formative Assessment \\nBased on the listening sessions we held, we see three key areas of opportunity in supporting \\nformative assessment using AI systems and models.  \\nFirst, we recommend a strong focus on measuring what matters61 and particularly those things \\nthat have not been easily measured before and that many constituents would like to include in \\nfeedback loops. The example above, AES, was chosen because writing remains a valuable \\nacademic, workplace, and life skill. Looking at community goals through the lens of their visions \\nfor their high school graduates, we see that families/caregivers, students, and community leaders',\n",
       " 'academic, workplace, and life skill. Looking at community goals through the lens of their visions \\nfor their high school graduates, we see that families/caregivers, students, and community leaders \\nwant to nurture graduates who solve problems adaptively, who communicate and collaborate \\nwell, who persevere and self-regulate when they experience challenges. “What matters” today \\nreaches beyond a sole focus on the core academic content measured by large-scale summative \\nassessments, to support students and teachers with actionable feedback that nurtures the broader \\nskills students need to succeed and thrive. Further, within core academic content, AI may help us \\nto provide feedback on the more realistic and complex aspects of doing math, for example, or \\ninvestigating scientific phenomena, understanding history, or discussing literature.  \\nSecond, we’d like to see a strong focus on improving help-seeking and help-giving.62 Asking for',\n",
       " 'investigating scientific phenomena, understanding history, or discussing literature.  \\nSecond, we’d like to see a strong focus on improving help-seeking and help-giving.62 Asking for \\nand giving help is crucial to learning63 and practicing a growth-mindset and central to the notion \\nof human feedback loops. Students may not always know when they need help. In one example, \\ncomputer algorithms can detect a student who is “wheel spinning” (working hard on mastering \\ncontent but not making progress).64 A student who is working hard may not feel like they need \\nhelp, and the teacher may not be aware that the student is struggling if he or she appears to be \\n“on task.” AI may also be helpful by highlighting for students and teachers what forms of \\nassistance have been most useful to the student in the recent past so that an educator can expand \\naccess to specific assistance that works for that individual student. Finally, educators may learn',\n",
       " 'assistance have been most useful to the student in the recent past so that an educator can expand \\naccess to specific assistance that works for that individual student. Finally, educators may learn \\nthings from AI-enabled systems and tools that give feedback and hints during the completion of \\n \\n60 Gardner, J., O\\'Leary, M. & Yuan, L. (2021). Artificial intelligence in educational assessment: \"Breakthrough? Or \\nbuncombe and ballyhoo?\" Journal of Computer Assisted Learning, 37(5), 1207–1216. https://doi.org/10.1111/jcal.12577 \\n61 Merrill, S. (2020). In schools, are we measuring what matters? Edutopia. https://www.edutopia.org/article/schools-are-we-\\nmeasuring-what-matters \\n62 Roll, I., Aleven, V., McLaren, B.M., Koedinger, K.R. (2011). Improving students’ help-seeking skills using metacognitive \\nfeedback in an intelligent tutoring system, Learning and Instruction, 21(2), 267–280. \\nhttps://doi.org/10.1016/j.learninstruc.2010.07.004.',\n",
       " 'feedback in an intelligent tutoring system, Learning and Instruction, 21(2), 267–280. \\nhttps://doi.org/10.1016/j.learninstruc.2010.07.004. \\n63 Webb, N.M., & Farivar, S. (1994). Promoting helping behavior in cooperative small groups in middle school \\nmathematics. American Educational Research Journal, 31(2), 369–395. https://doi.org/10.3102/00028312031002369 \\n64 Kai, S., Almeda, M.V., Baker, R. S., Heffernan, C., & Heffernan, N. (2018). Decision tree modeling of wheel-spinning and \\nproductive persistence in skill builders. Journal of Educational Data Mining, 10(1), 36–71. \\nhttps://doi.org/10.5281/zenodo.3344810',\n",
       " '42 \\nhomework, utilizing that feedback to later reinforce concepts in direct instruction and \\nstrengthen the one-on-one support provided to students.65 AI-enabled systems and tools can \\nprovide teachers with additional information about the students’ recent work, so their instructor \\nhas a greater contextual sense as they begin to provide help. \\nThird, we advocate for teachers and students to be strongly involved in designing feedback \\nloops as developers produce AI-enhanced formative assessments so they can directly voice what \\nwould make assessments less onerous and more convenient and valuable to them.66 Earlier in the \\nTeaching section, we emphasized how important it is to involve teachers in designing, selecting, \\nand evaluating AI-enhanced technologies. Students need to be centered, too. They are \\nexperiencing AI in their everyday lives, and they have strong opinions on what is valuable and',\n",
       " 'and evaluating AI-enhanced technologies. Students need to be centered, too. They are \\nexperiencing AI in their everyday lives, and they have strong opinions on what is valuable and \\nsafe. There are local and cultural variations in how people provide and receive feedback, so \\nadjusting feedback to align with community norms is important. \\nKey Recommendation: Harness Assessment Expertise to Reduce Bias \\nBias and fairness are important issues in assessment design and administration,67 and they hold \\nrelevance for the area of AI-enabled assessment. In traditional assessment, a test item might be \\nbiased if unnecessary details are included that differentially advantage some students (e.g., a \\nstory-based item that references a sport that only boys play regularly may be less helpful to \\ngirls). As discussed earlier, with AI, we now must worry about algorithmic discrimination which \\ncan arise due to the manner in which AI algorithms are developed and improved from large',\n",
       " 'girls). As discussed earlier, with AI, we now must worry about algorithmic discrimination which \\ncan arise due to the manner in which AI algorithms are developed and improved from large \\ndatasets of parameters and values that may not represent all cohorts of learners. \\nAlgorithmic discrimination is not just about the measurement side of formative assessment; it is \\nalso about the feedback loop and the instructional interventions and supports that may be \\nundertaken in response to data collected by formative assessments. There is a question both \\nabout access to such interventions and the quality or appropriateness of such interventions or \\nsupports. When an algorithm suggests hints, next steps, or resources to a student, we have to \\ncheck whether the help-giving is unfair because one group systematically does not get useful \\nhelp which is discriminatory. Fairness goes beyond bias as well. In AI-enabled formative',\n",
       " 'check whether the help-giving is unfair because one group systematically does not get useful \\nhelp which is discriminatory. Fairness goes beyond bias as well. In AI-enabled formative \\nassessment, both the opportunity to learn through feedback loops, as well as the quality of \\nlearning in and outside of such loops, should be addressed. Issues of bias and fairness have arisen \\nin traditional assessments, and the field of psychometrics has already developed valuable tools to \\nchallenge and address these issues.68 Assessment as a field may have a head start on tackling bias \\nand fairness for AI in education. And yet the issues expand with AI, so the work is not done. \\nStrong and deliberate attention to bias and fairness is needed as future formative assessments are \\ndeveloped. \\n \\n65 Walker, E., Rummel, N. & Koedinger, K.R. (2015). Adaptive intelligent support to improve peer tutoring in algebra.',\n",
       " 'developed. \\n \\n65 Walker, E., Rummel, N. & Koedinger, K.R. (2015). Adaptive intelligent support to improve peer tutoring in algebra. \\nInternational Journal of Artificial Intelligence in Education, 24, 33–61 https://doi.org/10.1007/s40593-013-0001-9 \\n66 Swiecki, Z., Khosravi, H., Chen, G., Martinez-Maldonado, R., Lodge, J.M., Milligan, S., Selwyn, B. & Gašević,D. (2022). \\nAssessment in the age of artificial intelligence. Computers and Education: Artificial Intelligence, 3. k \\nhttps://doi.org/10.1016/j.caeai.2022.100075 \\n67 Reynolds, C.R., & Suzuki, L.A. (2012). Bias in psychological assessment: An empirical review and recommendations. \\nHandbook of Psychology, Second Edition. https://doi.org/10.1002/9781118133880.hop210004 \\n68 Kaplan, R.M., & Saccuzzo, D.P. (2017). Psychological testing: Principles, applications, and issues. Cengage Learning.',\n",
       " '43 \\nRelated Questions \\nAs indicated, formative assessment is an area in which AI is expanding along a continuum that \\ncan be guided by visions already in place, such as the 2017 NETP. It is an area in which AI is \\npoised to grow, especially with capabilities that power more feedback loops in student learning. \\nAs this growth takes place, we suggest ongoing attention to the following questions: \\n● Is formative assessment bringing benefits to the student learning experience and to the \\nefficacy of classroom instruction?  \\n● Are humans being centered in AI-enabled formative assessment and feedback loops? \\n● Are we providing empowering professional development to teachers so they can leverage \\nfeedback loops and safeguard against concerns? \\n● To what extent are the developers and implementers of AI-enabled systems and tools \\ntackling new sources of algorithmic bias and continuing to make assessment fairer?',\n",
       " '● To what extent are the developers and implementers of AI-enabled systems and tools \\ntackling new sources of algorithmic bias and continuing to make assessment fairer? \\n● Are governance policies regarding who owns, controls, and can view or use AI-enabled \\nformative assessment data appropriate and adequate? \\n● Do we have sufficient guardrails against misuse of formative assessment data or \\nautomatically generated interpretations of student achievement and learning, such as on \\ndashboards?  \\n● Is trust in an AI-enabled assessment system, feedback loops, and data generated by such \\nassessments growing or diminishing?',\n",
       " '44 \\nResearch and Development \\nPolicy relies upon research-based knowledge; likewise, improving practice depends on feedback \\nloops that analyze empirical evidence. Consequently, the 2010 NETP specified a series of “grand \\nchallenges” which were “R&D problems that might be funded and coordinated at a national \\nlevel.” One 2010 NETP grand challenge was to create personalized learning systems that \\ncontinuously improve as they are used: \\n“Design and validate an integrated system that provides real-time access \\nto learning experiences tuned to the levels of difficulty and assistance \\nthat optimize learning for all learners and that incorporates self-\\nimproving features that enable it to become increasingly effective \\nthrough interaction with learners.”69 \\nSince 2010, much R&D has addressed this challenge. Conferences about learning analytics, \\neducational data mining, and learning at scale have blossomed. Developers have created',\n",
       " 'Since 2010, much R&D has addressed this challenge. Conferences about learning analytics, \\neducational data mining, and learning at scale have blossomed. Developers have created \\nplatforms that use algorithms and the analysis of big data to tune learning experiences. The \\nchallenge has not been fully achieved, and further work on this challenge is still relevant today.  \\nInsight: Research Can Strengthen the Role of Context in AI \\nDespite the relevance of 2010’s grand challenges, it has become apparent that the R&D \\ncommunity is now looking to expand their attention. The 2010 challenges were stated as \\ntechnical problems. Today’s researchers want to more deeply investigate context, and today’s \\ntech companies want to develop platforms that are responsive to the learners’ characteristics and \\nsituations more broadly—not just in terms of narrow cognitive attributes. We see a push to \\ntransform R&D to address context sensitivity. We look forward to new meanings of “adaptive”',\n",
       " 'situations more broadly—not just in terms of narrow cognitive attributes. We see a push to \\ntransform R&D to address context sensitivity. We look forward to new meanings of “adaptive” \\nthat broaden outward from what the term has meant in the past decade. For example, “adaptive” \\nshould not always be a synonym of “individualized” because people are social learners. \\nResearchers therefore are broadening “adaptivity” to include support for what students do as \\nthey learn in groups, a form of learning that is prevalent in schools across the U.S. \\nThe focus on context is not an accident. Context is a traditional challenge in AI.70 Thus, \\nresearchers and developers are wise to prioritizing context. Unless we invest more in AI that is \\ncontext-sensitive, it is quite likely that AI will break and fail to achieve educational goals. \\nAgreeing to prioritize context won’t be easy. As illustrated above in Figure 12, there will be a',\n",
       " 'context-sensitive, it is quite likely that AI will break and fail to achieve educational goals. \\nAgreeing to prioritize context won’t be easy. As illustrated above in Figure 12, there will be a \\ntension between depth of context and pace of technological advances in AI R&D. On the one \\nhand, AI is sometimes presented as a race to be the first to advance new techniques or scale new \\napplications—innovation is sometimes portrayed as rapidly going to scale with a minimally \\nviable product, failing fast, and only after failure, dealing with context. On the other hand, \\nresearchers and developers see that achieving good innovations with AI in education will clearly \\n \\n69 U.S. Department of Education, Office of Educational Technology. (2010). Transforming American Education: Learning \\nPowered by Technology. U.S. Department of Education. p. 78 \\n70 Boden, M.A. (2018). Artificial intelligence: A very short introduction. Oxford. ISBN: 978-0199602919',\n",
       " '45 \\nrequire bringing more context into the process early and often. For example, researchers \\nhighlight that humans must be continually adjusting the goals for technology and have noted \\nthat when we set forth goals, we often don’t yet fully understand context; and as we learn about \\ncontext, the goals must change.71 This suggests that context must be prioritized early and \\nhabitually in R&D; we don’t want to win a race to the wrong finish line. \\nFigure 12: The tension between depth of context and pace of technological advances in AI \\n \\nFurther, intensifying focus on context in this work will change the nature of the R&D. There \\nwon’t be just one type of change in R&D because context has multiple meanings. Attendees in \\nour listening sessions described four types of context necessary for the future. \\nWe list these four types of context below and then expand on each one in its own section. These',\n",
       " 'our listening sessions described four types of context necessary for the future. \\nWe list these four types of context below and then expand on each one in its own section. These \\nfour types emerged as topics of provocations to think differently about R&D but certainly do not \\nexhaust the important ways of investigating context. \\n1. Focus on the Long Tail: How could we use big data and AI to pay more attention to the \\n“long tail” of edtech use—going beyond a few “most typical” ways of using emerging \\ntechnology and instead solving for digital equity and inclusion? \\n2. Partnership in Design-Based Research: How can we change who is involved and \\ninfluential in designing the future of AI in education to more centrally include students, \\nteachers, and other educational constituents?  \\n3. Connect with Public Policy: How can work on AI in education build on general advances \\nin AI ethics, safety, and regulation and contribute additional advances specific to \\neducational policy?',\n",
       " '3. Connect with Public Policy: How can work on AI in education build on general advances \\nin AI ethics, safety, and regulation and contribute additional advances specific to \\neducational policy?  \\n4. Rethink Teacher Professional Development: How can we solve for new systems of \\nteacher professional development (both pre-service and in-service) that align to the \\nincreasingly core role of technology in the teaching profession? \\n \\n71 Russell, S. (2019). Human compatible: Artificial intelligence and the problem of control. Penguin. ISBN: 9780525558637',\n",
       " \"46 \\n“We can't necessarily always apply traditional research methodologies to \\nthis topic because educational technology changes so quickly.”  \\n—Kristina Ishmael, Office of Educational Technology \\nAttention to the Long Tail of Learner Variability \\nAt the core of R&D of AI in education, innovators will be building models that fit available data. \\nThe increasing scale and prevalence of technologies means that the data is coming from and \\nincluding a wide range of different contexts and varied ways that people in those contexts engage \\nin teaching and learning. Researchers in our listening sessions drew attention to the promise of \\nAI for addressing “context” by reference to the long tail of learner variability. \\nFigure 13: The long tail of learner variability\\n \\nAs depicted in Figure 13, learners vary in their strengths and needs. The most frequently \\noccurring mix of strength and needs (also known as “teaching to the middle”) is depicted\",\n",
       " 'As depicted in Figure 13, learners vary in their strengths and needs. The most frequently \\noccurring mix of strength and needs (also known as “teaching to the middle”) is depicted \\nleftmost, with less frequently occurring mixes spreading to the right. Rising upward, the figure \\ndepicts the number of learners who benefit from a particular learning design, pathway, or \\napproach. We argue that AI can bring opportunities to address a wider spectrum of strengths and \\nneeds but only if developers and innovators focus on the long tail and not only “teaching to the \\nmiddle.”  \\nFor the sake of argument, the figure indicates three zones. In a first zone, curricular resources are \\nmostly standardized, with perhaps a dimension or two of adaptivity. For example, many existing \\nproducts adapt based on the correctness of student answers and may also provide options to read \\nor hear text in a second language. However, the core of the instructional approach is highly',\n",
       " 'products adapt based on the correctness of student answers and may also provide options to read \\nor hear text in a second language. However, the core of the instructional approach is highly \\nstandardized. In a second zone, there is greater balance between how much standardization and \\nhow much adaptivity students can access. Universal Design for Learning (UDL) is one set of \\nrecommendations for providing learning opportunities in multiple formats and for',\n",
       " '47 \\naccommodating different learning progressions.72 UDL can enable accommodating more ways in \\nwhich learners vary, and as teachers know, there are many more important ways to adapt to \\nstudents than found in today’s edtech products.  \\nStudents are neurodiverse. They bring different assets from their experiences at home, in their \\ncommunities, and in their cultures. They have different interests and motivations. And they \\nlearn in varied settings—classrooms and schools differ, and at-home students learn in informal \\nsettings in ways that could complement school learning. These are all important dimensions of \\n“context.” Zone 3 indicates highly adaptive learning, where standardization is less successful and \\nwhere we need to discover a wider variety of approaches to engage learners and sustain powerful \\nlearning. Researchers in our listening sessions noted the promise of Zone 3 because AI’s ability to',\n",
       " \"where we need to discover a wider variety of approaches to engage learners and sustain powerful \\nlearning. Researchers in our listening sessions noted the promise of Zone 3 because AI’s ability to \\nrecognize patterns in data can extend beyond the most common patterns and because AI's ability \\nto generate customized content can extend beyond what people can reasonably generate on their \\nown. \\nNotice that although the Zone 1 bar appears to be the tallest, and thus tends to attract initial \\nattention, there are more students in Zones 2 and 3, the regions where AI can provide more help. \\nThus, it’s important to ask where AI researchers and developers are directing their attention. \\nWhen we say a model “fits,” are we saying it fits the most common and typical uses by teachers \\nand learners? This sort of R&D is easier to do. However, machine learning and AI also can tailor a \\nmodel to the less common and more culturally specific contexts, too. Therefore, how can\",\n",
       " 'and learners? This sort of R&D is easier to do. However, machine learning and AI also can tailor a \\nmodel to the less common and more culturally specific contexts, too. Therefore, how can \\nconstituents cultivate interdisciplinary expertise to direct attention among researchers and \\ndevelopers to focus on the long tail? If we do, the quality of what we do for those represented in \\nthat tail can be more adaptive and more context-sensitive. And to be most effective, it will \\nrequire the integration of contextual, content, and technical expertise. \\nWithin the long-tail challenge, the community is wondering how we can get to research insights \\nthat are both general and specific enough. When research produces very general abstractions \\nabout learning, it often doesn’t give developers enough guidance on exactly how to adjust their \\nlearning environments. Conversely, when research produces a specific adaptive algorithm that',\n",
       " 'about learning, it often doesn’t give developers enough guidance on exactly how to adjust their \\nlearning environments. Conversely, when research produces a specific adaptive algorithm that \\nworks on one educational platform, it often remains hard to apply to additional platforms; \\nresearch can be too detailed as well. The research community is also thinking about new \\npartnerships that could bring more data and more diverse perspectives to the table, the topic of \\nthe next section.  \\nFocusing on the long tail of learner variability is particularly important to addressing a long-\\nstanding key research question: “Do new AI-enhanced approaches work to improve learning, and for \\nwhom and under what conditions?” \\nPartnership in Design-Based Research \\nOf course, teachers must be included in rethinking their own professional development. This \\nthought leads to another priority aspect of context: partnership in design-based research. With',\n",
       " 'Of course, teachers must be included in rethinking their own professional development. This \\nthought leads to another priority aspect of context: partnership in design-based research. With \\nregard to inclusive design, attendees in our listening sessions brought up a variety of co-design73 \\n \\n72 Rose, D. (2000). Universal design for learning. Journal of Special Education Technology, 15(4), 47-51. \\nhttps://doi.org/10.1177/016264340001500407 \\n73 Roschelle, J., Penuel, W., & Shechtman, N. (2006). Co-design of innovations with teachers: definition and dynamics. In \\nProceedings of the 7th International Conference on Learning Sciences, Bloomington, IN. https://doi.dx.org/10.22318/icls2006.606',\n",
       " '48 \\nand other participatory processes and goals that can be used in R&D.74 By co-design, they mean \\nsharing power with non-researchers and non-developers through all the phases of design and \\ndevelopment, which would result in more influence by teachers, students, and other constituents \\nin the shape of AI-enabled edtech. The shift toward co-design was palpable throughout our \\nlistening sessions, but as researchers and developers have not standardized on one particular co-\\ndesign method, we share some representative examples. \\n● Youth can powerfully participate in design when researcher methods include participant \\nco-design. Such research can investigate how to improve edtech while educating students. \\nA listening session attendee asked about developing students’ awareness of what data are \\nbeing collected and how data are being used by developers. \\n● There is a near future need to go beyond representation so that co-designed solutions',\n",
       " 'being collected and how data are being used by developers. \\n● There is a near future need to go beyond representation so that co-designed solutions \\nconsider more generous contexts for broader possibilities, according to attendees. \\n● The shift of power dynamics is another research-worthy interest of the panel and \\nattendees to understand the balance between a teacher’s agency and a machine’s \\nsuggestions. \\n● Likewise, such longitudinal research will require both the infrastructure and institutional \\nsupport to fund necessary experimentation and requisite failures to elicit positive results \\nand safe innovation. \\n● There is a desire for rapid cycle evaluations with inclusive feedback loops that return to \\nthe educators themselves as essential relative to traditional research approaches. \\n● Many researchers also mentioned a focus on explainable AI as essential to enable \\nparticipation in the design and evaluation of emerging AI approaches in education.',\n",
       " '● Many researchers also mentioned a focus on explainable AI as essential to enable \\nparticipation in the design and evaluation of emerging AI approaches in education. \\nThe conversations raised this question: how can co-design provide an empowering form of \\nparticipation in design and thus achieve digital inclusion goals? Such digital inclusion can span \\nmany layers of design, including diverse representation in design of policies around data, design \\nof adaptivity, and other user experiences in AI systems, design of plans for cultivating AI literacy \\nfor users of new platforms, and lastly, the design of plans to evaluate systems. \\nRe-thinking Teacher Professional Development \\nWith regard to teachers as professionals, both researchers and other educators attending our \\nlistening sessions were highly concerned about the disconnect between how teachers are \\nprepared versus how they are expected to work with emerging technology. When we discuss',\n",
       " 'listening sessions were highly concerned about the disconnect between how teachers are \\nprepared versus how they are expected to work with emerging technology. When we discuss \\nlearning, teachers are central actors, and thus the contexts in which they are prepared is centrally \\nimportant to their ability to do great work in current and emerging technological environments.  \\nTeacher professional development, professional learning, and leadership (PD or PL) for \\nemerging technologies was seen as an area needing intense re-thinking, and research could lead \\nthe way. Today, few who prepare to become a teacher in an established pre-service program \\nlearn about the effective use of educational technology in schools and classrooms; those who do \\n \\n74 Center for Integrative Research in Computing and Learning Sciences (CIRCLS). (2022, Feb.). From Broadening to \\nEmpowering: Reflecting on the CIRCLS’21 Convening. https://circls.org/circls21report',\n",
       " '49 \\nhave the opportunity to investigate technology rarely think about the structures that shape its \\nuse in the classroom and in educational leadership. Consequently, a troubling dichotomy arises \\nbetween a small set of investigators who specifically consider educational technology in their \\nresearch on teaching and a broader group of educators who see educational technology as a \\ngeneric instructional resource. The challenge is high because teacher professional development \\nwill remain highly varied by local contexts. Yet insufficient attention to teachers as leaders in the \\nuse and further development of effective educational technology is widespread in teacher \\nprofessional development research. \\nOne response can be in terms of investigating how to nurture greater AI literacy for all teachers. \\nAI literacy is not only important to protect educators and students from possible dangers but also \\nvaluable to support teachers to harness the good and do so in innovative ways. A panelist',\n",
       " 'AI literacy is not only important to protect educators and students from possible dangers but also \\nvaluable to support teachers to harness the good and do so in innovative ways. A panelist \\nreminded the group that this work implies how we prepare educators with a baseline AI literacy \\nand understanding. More transparency and authentic dialogue can foster trust, which was \\nmentioned by a researcher as a chief concern for all teachers and students. \\nThis is not to suggest that AI literacy is a complete or even a simple fix. Researchers want to ask \\nfundamental questions about what it means for teachers to be professionals, especially as \\nemerging technologies gain ground in schools and classrooms—our teachers’ professional \\nworkplaces. Researchers want to broadly reconceptualize teacher professionalism and to stop \\ntreating technology as an add-on element of professional development. \\nConnecting with Public Policy',\n",
       " 'workplaces. Researchers want to broadly reconceptualize teacher professionalism and to stop \\ntreating technology as an add-on element of professional development. \\nConnecting with Public Policy \\nDefining human-centered AI for education requires the embrace of a human-centered principle \\nand foundation for developing and formulating policies that govern the application and use of \\nAI more generally throughout society. For example, power dynamics that arise between \\ncompanies and consumers in society around issues like data ownership will also arise in the \\neducation-specific ecosystem. Further, the public discourse in which people are discussing ethics, \\nbias, responsibility, and many other necessary concepts will be happening simultaneously in \\npublic policy and in educational ecosystems.  \\nOne clear implication in our listening sessions was that efforts to improve AI literacy in \\neducation could be important and helpful to society more generally. For example, one panelist',\n",
       " 'One clear implication in our listening sessions was that efforts to improve AI literacy in \\neducation could be important and helpful to society more generally. For example, one panelist \\nsaid that an overarching goal of improving AI literacy is necessary if they are to contribute to \\nhow those technologies are designed. Another researcher was interested in how edtech can \\nprovide environments where students can experience having difficult discussions across \\nperspectives, an issue which is endemic to present society. A third researcher noted the \\ninsufficiencies of prior efforts to contend with algorithmic bias, ethics, and inclusion due to a \\nclassroom’s complex social dynamics. \\nResearchers want to take a lead in going beyond checkbox approaches to take these issues \\nseriously. And they also acknowledge that engaging with policy is often a new form of context \\nfor edtech and AI researchers, many of whom don’t have long experiences in policy arenas.',\n",
       " 'seriously. And they also acknowledge that engaging with policy is often a new form of context \\nfor edtech and AI researchers, many of whom don’t have long experiences in policy arenas. \\nLikewise, developers often do have experience with some policy issues, such as data privacy and \\nsecurity, but are now needing to become part of new conversations about ethics, bias,',\n",
       " '50 \\ntransparency, and more, a problem that the EdSAFE AI Alliance is addressing through multi-\\nsector working groups and policy advocacy.75  \\nKey Recommendation: Focus R&D on Addressing Context \\nAttendees who have participated in listening sessions leading up to this report were exceptionally \\nclear that their view of future R&D involved a shift from narrow technical questions to richer \\ncontextual questions. This expansive shift toward context, as detailed below, is the foundational \\norientation that the listening session attendees saw as being necessary to advancing R&D. \\nAttendees included these as dimensions of context: \\n• learner variability, e.g., in disabilities, languages spoken, and other relevant \\ncharacteristics; \\n• interactions with peers, teachers, and others in the learning settings; \\n• relationships across home, school, and community settings, including cultural assets; \\n• instructional resources available while learning; \\n• teacher preparation; and',\n",
       " '• relationships across home, school, and community settings, including cultural assets; \\n• instructional resources available while learning; \\n• teacher preparation; and \\n• policies and systems that structure teaching and learning. \\n \\nTo more fully represent the context of teaching and learning, including these and other \\ndimensions of text, researchers will have to work in partnership with others to understand which \\naspects of context are most relevant to teaching and learning and how they can be usefully \\nincorporated into AI models. \\nOngoing Questions for Researchers \\nAs mentioned earlier, people are good at context; AI—not so much. R&D investment in context-\\nrich edtech thus could serve multiple national interests because finding ways to do a better job \\nwith context would be a fundamental advancement in AI. Indeed, questions like these \\nreverberate across all applications of AI in society, and education is a centrally good context for \\ninvestigating them:',\n",
       " 'reverberate across all applications of AI in society, and education is a centrally good context for \\ninvestigating them: \\n● Are AI systems moving beyond the tall portions of the “long tail” to adapt to a greater \\nrange of conditions, factors, and variations in how people learn?  \\n● To what extent are AI technologies enhancing rather than replacing human control and \\njudgment of student learning? \\n● How will users understand the legal and ethical implications of sharing data with AI \\nenabled technologies and how to mitigate privacy risks? \\n● To what extent does technology account for the complex social dynamics of how people \\nwork and learn together, or is technology leading humans to narrow or oversimplify? \\n● How can we more clearly define what we mean by a context-sensitive technology in \\nterms that are both concrete and broad enough? How can we measure it? \\n \\n75 Nentrup, E. (2022). How Policymakers Can Support Educators and Technology Vendors Towards SAFE AI. EdSAFE AI',\n",
       " 'terms that are both concrete and broad enough? How can we measure it? \\n \\n75 Nentrup, E. (2022). How Policymakers Can Support Educators and Technology Vendors Towards SAFE AI. EdSAFE AI \\nAlliance. https://www.edsafeai.org/post/how-policymakers-can-support-aied',\n",
       " '51 \\n● To what extent are technical indicators and human observations of bias or unfairness \\nworking together with human observations? How can concerns about ethics and equity in \\nAI technologies become actionable both in R&D, and later, when AI is widely used? \\n● Are we learning for whom and under what conditions AI systems produce desired \\nbenefits and impacts and avoid undesirable discrimination, bias, or negative outcomes?  \\nDesired National R&D Objectives \\nAttendees sought immediate progress on some key R&D issues, such as these: \\n• Clarifying and achieving a consensus on the terms that go beyond data privacy and data \\nsecurity, including ideas like human-centered, value-sensitive, responsible, ethical, and \\nsafe so constituents can advocate for their needs meaningfully and consistently \\n• Creating and studying effective programs for AI literacy for students, teachers, and \\neducational constituents in general, including literacy with regard to the ethics and equity',\n",
       " '• Creating and studying effective programs for AI literacy for students, teachers, and \\neducational constituents in general, including literacy with regard to the ethics and equity \\nissues specific to AI in educational settings \\n• Advancing research and development to increase fairness, accountability, transparency, \\nand safety in AI systems used in educational settings \\n• Defining participatory or co-designed research processes that include educators in the \\ndevelopment and conduct of research related to the development, use, and efficacy of AI-\\nenabled systems and tools  \\n• Highlighting and advancing R&D efforts that empower the participation and voices of \\nyouth regarding research, data, and design of AI applications for teaching and learning \\nLonger term desires for a national R&D program include some of the following objectives: \\n• Funding sustainable partnerships that uncover what context means and how it can be \\naddressed over longer periods of time',\n",
       " '• Funding sustainable partnerships that uncover what context means and how it can be \\naddressed over longer periods of time \\n• Better connecting goals for “broadening participation” (for example, in STEM learning \\npathways) to strategies for addressing learner variability and diversity \\n• Prioritizing research to revitalize support for instructors in light of the increasingly \\ntechnological nature of K-12, higher education, and workplace learning settings \\n• Creating infrastructure and new ways of working together beyond individual field-\\ninitiated grants so that R&D with big data and leveraging emerging AI capabilities \\nbecomes safer and more productive',\n",
       " '52 \\nRecommendations  \\nEarlier, we asked two guiding questions: \\n1. What is our collective vision of a desirable and achievable educational system that \\nleverages automation while protecting and centering human agency? \\n2. On what timeline will we be ready with necessary guidelines and guardrails along with \\nconvincing evidence of positive impacts, so that we can ethically and equitably \\nimplement this vision widely? \\nAnswers to the first question are provided throughout the Learning, Teaching, Assessment, and \\nResearch sections. This section turns to a call to action to education leaders and to \\nrecommendations. Core to the Department’s perspective is that education will need leadership \\nspecific to our sector. Leadership should recognize and build on prior accomplishments in \\nedtech (such as strong prior work on student privacy and school data security) as well as broad \\nframeworks for safe AI (such as the Blueprint for an AI Bill of Rights). Leadership must also reach',\n",
       " 'edtech (such as strong prior work on student privacy and school data security) as well as broad \\nframeworks for safe AI (such as the Blueprint for an AI Bill of Rights). Leadership must also reach \\nbeyond these accomplishments and frameworks to address emerging opportunities and risks \\nthat are specific to novel capabilities and uses of AI in education.  \\nInsight: Aligning AI to Policy Objectives \\nIndividual sections of this policy report provided insights in each of four areas—learning, \\nteaching, assessment, and research. These insights, synthesized from extensive stakeholder \\nconsultation and listening sessions, show that the advances in AI can bring opportunities to \\nadvance the Department’s policy objectives: \\n● In support of our objective of attracting and retaining teachers, our nation could focus on \\nAI assistants that make teaching jobs better and provide teachers with the information \\nthey need to work closely and empathically with students. An emphasis on teachers in the',\n",
       " 'AI assistants that make teaching jobs better and provide teachers with the information \\nthey need to work closely and empathically with students. An emphasis on teachers in the \\nloop could ensure that AI-enabled classroom technologies keep teachers in the know, in \\ntouch with their students, and in control of important instructional decisions. Keeping the \\nteacher in the loop is important to managing risks, as well. \\n● In support of equitable learning, especially for those most affected by the pandemic, AI \\ncould shift edtech from a current deficit-based model to a strengths-based alternative. In \\naddition to finding student weaknesses and assigning fixes, edtech could make \\nrecommendations based on strengths that students bring to learning and how adapting to \\nthe whole student—a cognitive, social, and self-regulating person—could enable more \\npowerful learning. Adapting to the whole student should include supporting students',\n",
       " 'the whole student—a cognitive, social, and self-regulating person—could enable more \\npowerful learning. Adapting to the whole student should include supporting students \\nwith disabilities as well as English learners. With regard to equity, we must remain highly \\nattuned to the challenges of bias (which are inherent to how AI systems are developed) \\nand take firm action to ensure fairness. \\n● With regard to growth trajectories to successful careers, AI-enabled assessments could \\nprovide students and teachers with formative guidance on a wider range of valuable \\nskills, focusing on providing information that enhances learning. Aligned with the \\nhuman-centric view, we should take a systems view of assessments where students, \\nteachers, and others remain at the center of instructional decision making.',\n",
       " '53 \\n● With regard to equity, as research advances and brings more context into AI, we will be \\nbetter able to use AI to support goals that require customization of learning resources, \\nsuch as enabling teachers to more easily transform materials to support neurodiverse \\nlearners and increase responsiveness to local communities and cultures.  \\nGoing forward, educational leaders need to bring these and their own policy priorities to the \\ntable at every discussion about AI, driving the conversation around human priorities and not \\nonly their excitement about what new technology might do. Fundamentally, AI seeks to \\nautomate processes that achieve goals, and yet, AI should never set goals. The goals must come \\nfrom educators’ vision of teaching and learning and educators’ understanding of students’ \\nstrengths and needs. \\nCalling Education Leaders to Action \\nWe summarize seven recommendations for policy action. These recommendations are for',\n",
       " 'strengths and needs. \\nCalling Education Leaders to Action \\nWe summarize seven recommendations for policy action. These recommendations are for \\neducation leaders. In the introduction, we note the necessity of involving education constituents \\nin determining policies for AI. We also observed throughout our listening sessions that people \\ncoming from many different roles in education all have passion, knowledge, and insights to \\ncontribute. In our view, all types of constituents can be education leaders. We are reluctant to \\nsuggest any constituent role is more important to advance any of the recommendations, but we \\ncall out specific needs for action within some of the recommendations where it is warranted. \\nRecommendation #1: Emphasize Humans in the Loop \\nWe start with a central recommendation throughout this report. This recommendation was a \\nclear constituent favorite. Indeed, across more than 700 attendees in our listening sessions, the',\n",
       " 'We start with a central recommendation throughout this report. This recommendation was a \\nclear constituent favorite. Indeed, across more than 700 attendees in our listening sessions, the \\npredominant discussion tackled how constituents can achieve a consensus vision for AI-enabled \\nedtech where humans are firmly at the center. The Blueprint for an AI Bill of Rights similarly calls \\nfor “access to timely human consideration and remedy by a fallback and escalation process if an \\nautomated system fails, it produces an error, or you would like to appeal or contest its impacts…” \\nBuilding on this consensus, we call upon all constituents to adopt “humans in the loop” as a key \\ncriterion for educational use of AI.  \\nWe envision a technology-enhanced future more like an electric bike and less like robot \\nvacuums. On an electric bike, the human is fully aware and fully in control, but their burden is \\nless, and their effort is multiplied by a complementary technological enhancement. Robot',\n",
       " 'vacuums. On an electric bike, the human is fully aware and fully in control, but their burden is \\nless, and their effort is multiplied by a complementary technological enhancement. Robot \\nvacuums do their job, freeing the human from involvement or oversight.  \\nAlthough teachers should not be the only humans involved in loops, Figure 5 provided examples \\nof three types of teacher loops that are central to education and can be used to illustrate what \\n“human in the loop” means. Here, we use the example of an AI chatbot to elaborate on the \\nmeaning of the loops. First, as students become involved in extended interactions with AI \\nchatbots, teachers will need to educate students about safe AI use, monitor their use, and provide \\nhuman recourse when things go astray. Second, teachers are beginning to use chatbots to plan \\npersonalized instruction for their students; they will need to be involved in loops with other',\n",
       " 'human recourse when things go astray. Second, teachers are beginning to use chatbots to plan \\npersonalized instruction for their students; they will need to be involved in loops with other \\nteachers to understand effective prompts, to know how to analyze AI-generated lesson plans for \\nflaws, and to avoid the human tendency to overly trust AI systems and underapply human \\njudgement. Third, teachers need to be involved in the design and evaluation of AI systems before \\nthey are used in classrooms and when needs for improvement are observed. In one example, to \\ndesign AI-generated homework support for students, teachers’ in-depth understanding of the',\n",
       " '54 \\ncognitive, motivational, and social supports their students need will provide much-needed \\nguidance as a homework-support chatbot is designed.  \\nIn framing AI in education, this report advances a key recommendation of “human in the loop” \\nAI because the phrase readily communicates a criterion that everyone can use as they determine \\nwhich AI-enabled systems and tools are appropriate for use in teaching and learning. In a rather \\ntechnical field, human in the loop is an approachable and humanistic criterion. Rather than \\nsuggesting that AI-enabled systems and tools should replace teachers, this term instead solidifies \\nthe central role of educators as instructors and instructional decision makers, while reinforcing \\nthe responsibility of teachers to exercise judgement and control over the use of AI in education. \\nIt resonates with the important idea of feedback loops, which are highly important to how',\n",
       " 'the responsibility of teachers to exercise judgement and control over the use of AI in education. \\nIt resonates with the important idea of feedback loops, which are highly important to how \\npeople teach and learn. It also aligns with the ideas of inspectable, explainable, severable, and \\noverridable AI.  \\nThe Department agrees with listening session participants who argued that teachers should not \\nbe the only humans in the loop and calls upon parents, families, students, policy makers, and \\nsystem leaders to likewise examine the “loops” for which they are responsible, critically analyze \\nthe increasing role of AI in those loops, and determine what they need to do to retain support for \\nthe primacy of human judgement in educational systems. \\nRecommendation #2: Align AI Models to a Shared Vision for Education \\n“All models are wrong, but some are useful.”  \\n —George Box, Statistician \\nAs we have discussed across every section of this report, AI technologies are grounded in models,',\n",
       " \"“All models are wrong, but some are useful.”  \\n —George Box, Statistician \\nAs we have discussed across every section of this report, AI technologies are grounded in models, \\nand these models are inevitably incomplete in some way. It is up to humans to name educational \\ngoals and measure the degree to which models fit and are useful—or don’t fit and might be \\nharmful. Such an assessment of how well certain tools serve educational priorities may seem \\nobvious, but the romance of technology can lead to a “let’s see what the tech can do'' attitude, \\nwhich can weaken the focus on goals and cause us to adopt models that fit our priorities poorly.  \\nHere we call upon educational policy and decision makers at the local, state, and federal level to \\nuse their power to align priorities, educational strategies, and technology adoption decisions to \\nplace the educational needs of students ahead of the excitement about emerging AI capabilities.\",\n",
       " 'use their power to align priorities, educational strategies, and technology adoption decisions to \\nplace the educational needs of students ahead of the excitement about emerging AI capabilities. \\nWe want to strengthen their attention to existing state, district, and school-level policies that \\nguide edtech adoption and use, such as the four levels of evidence in ESSA, the privacy \\nrequirements of FERPA, and enhanced policies to come. Local education leaders know best what \\ntheir urgent educational priorities are. Every conversation about AI (or any emerging \\ntechnology) should start with the educational needs and priorities of students front and center \\nand conclude with a discussion about the evaluation of effectiveness re-centered on those needs \\nand priorities. Equity, of course, is one of those priorities that requires constant attention, \\nespecially given the worrisome consequences of potentially biased AI models.',\n",
       " 'and priorities. Equity, of course, is one of those priorities that requires constant attention, \\nespecially given the worrisome consequences of potentially biased AI models.  \\nWe especially call upon leaders to avoid romancing the magic of AI or only focusing on \\npromising applications or outcomes, but instead to interrogate with a critical eye how AI-enabled \\nsystems and tools function in the educational environment. We ask leaders to distrust broad \\nclaims and ask six types of questions, listed below. Throughout this report, we elaborated on',\n",
       " '55 \\nwhich characteristics of AI model use in education are most important to evaluate for alignment \\nto intended educational goals. To aid leaders, we summarize our insights about AI models and \\ntheir use in educational tools and systems in Figure 14.  \\nFigure 14: Recommendation for desired qualities of AI tools and systems in education \\n \\nIn this figure, we center teaching and learning in all considerations about the suitability of an AI \\nmodel for an educational use. Humans remain in the loop of defining, refining, and using AI \\nmodels. We highlight the six desirable characteristics of AI models for education (elaborating \\nfrom principles in the Blueprint for an AI Bill of Rights to fit the specifics of educational systems): \\n1. Alignment of the AI Model to Educators’ Vision for Learning: When choosing to use AI \\nin educational systems, decision makers prioritize educational goals, the fit to all we know',\n",
       " '1. Alignment of the AI Model to Educators’ Vision for Learning: When choosing to use AI \\nin educational systems, decision makers prioritize educational goals, the fit to all we know \\nabout how people learn, and alignment to evidence-based best practices in education. \\n2. Data Privacy: Ensuring security and privacy of student, teacher, and other human data in \\nAI systems is essential. \\n3. Notice and Explanation: Educators can inspect edtech to determine whether and how AI \\nis being incorporated within edtech systems. Educators’ push for AI models can explain \\nthe basis for detecting patterns and/or for making recommendations, and people retain \\ncontrol over these suggestions. \\n4. Algorithmic Discrimination Protections: Developers and implementers of AI in \\neducation take strong steps to minimizing bias and promoting fairness in AI models.',\n",
       " '56 \\n5. Safe and Effective Systems: The use of AI models in education is based on evidence of \\nefficacy (using standards already established in education for this purpose) and work for \\ndiverse learners and in varied educational settings. \\n6. Human Alternatives, Consideration and Feedback: AI models that support transparent, \\naccountable, and responsible use of AI in education by involving humans in the loop to \\nensure that educational values and principles are prioritized. \\nAlthough we first address our recommendation to interrogate how educational systems use AI \\nmodels to educational leaders who adopt technologies, other leaders also have integral roles to \\nplay. Teachers and students, as well as their families/caregivers, contribute significantly to \\nadoption decisions also. And leaders and parents must support educators when they question or \\noverride an AI model based on their professional wisdom. Developers of technologies need to be',\n",
       " 'adoption decisions also. And leaders and parents must support educators when they question or \\noverride an AI model based on their professional wisdom. Developers of technologies need to be \\nforthcoming about the models they use, and we may need policymakers to create requirements \\nfor disclosure so that the marketplace can function on the basis of information about AI models \\nand not only by the claims of their benefits. \\nWe also emphasize the need for a government role. AI models are made by people and are only \\nan approximation to reality. Thus, we need policies that require transparency about the AI \\nmodels that are embedded in educational systems, as well as models that are inspectable, \\nexplainable, and overridable. Our listening sessions featured constituent calls for government \\ndoing more to hold developers accountable for disclosing the types of AI models they employ in \\nlarge-scale products and the safeguards included in their systems. Government leaders can make',\n",
       " 'doing more to hold developers accountable for disclosing the types of AI models they employ in \\nlarge-scale products and the safeguards included in their systems. Government leaders can make \\na positive contribution to market conditions that enable building trust as AI systems are \\nprocured and implemented in education. We discuss these guidelines more in recommendation \\n#4, which is about building trust. \\nRecommendation #3: Design Using Modern Learning Principles \\nWe call for the R&D sector to ensure that product designs are based on best and most current \\nprinciples of teaching and learning. The first decade of adaptivity in edtech drew upon many \\nimportant principles, for example, around how to sequence learning experiences and how to \\ngive students feedback. And yet the underlying conception was often deficit-based. The system \\nfocused on what was wrong with the student and chose pre-existing learning resources that',\n",
       " 'give students feedback. And yet the underlying conception was often deficit-based. The system \\nfocused on what was wrong with the student and chose pre-existing learning resources that \\nmight fix that weakness. Going forward, we must harness AI’s ability to sense and build upon \\nlearner strengths. Likewise, the past decade of approaches was individualistic, and yet we know \\nthat humans are fundamentally social and that learning is powerfully social. Going forward, we \\nmust build on AI capabilities that connect with principles of collaborative and social learning and \\nwhich respect the student not just for their cognition but also for the whole human skill set. \\nGoing forward, we also must seek to create AI systems that are culturally responsive and \\nculturally sustaining, leveraging the growth of published techniques for doing so. Further, most \\nearly AI systems had few specific supports for students with disabilities and English learners.',\n",
       " 'culturally sustaining, leveraging the growth of published techniques for doing so. Further, most \\nearly AI systems had few specific supports for students with disabilities and English learners. \\nGoing forward, we must ensure that AI-enabled learning resources are intentionally inclusive of \\nthese students. The field has yet to develop edtech that builds upon each student’s ability to \\nmake choices and to self-regulate in increasingly complex environments. We have to develop \\nedtech that expands students’ abilities to learn in creative modes and to expand their ability to \\ndiscuss, write, present, and lead. \\nWe also call upon educators to reject uses of AI that are based solely on machine learning from \\ndata—without triangulation based on learning theory and knowledge from practice. Achieving',\n",
       " '57 \\neffective and equitable educational systems requires more than processing “big data,” and \\nalthough we want to harness insights from data, human interpretation of data remains highly \\nimportant. We reject a technological determinism in which patterns in data, on their own, tell us \\nwhat to do. Applications of AI in education must be grounded in established, modern learning \\nprinciples, the wisdom of educational practitioners, and should leverage the expertise in the \\neducational assessment community around detecting bias and improving fairness.  \\nRecommendation #4: Prioritize Strengthening Trust \\nTechnology can only help us to achieve educational objectives when we trust it. Yet, our listening \\nsessions revealed the ways in which distrust of edtech and AI is commonplace. Constituents \\ndistrust emerging technologies for multiple reasons. They may have experienced privacy \\nviolations. The user experience may be more burdensome than anticipated. Promised increases',\n",
       " 'distrust emerging technologies for multiple reasons. They may have experienced privacy \\nviolations. The user experience may be more burdensome than anticipated. Promised increases \\nin student learning may not be backed by efficacy research. They may have experienced \\nunanticipated consequences. Unexpected costs may arise. Constituents may distrust complexity. \\nTrust needs to incorporate safety, usability, and efficacy. \\nThe Department firmly takes the stance that constituents want AI that supports teachers and \\nrejects AI visions that replace teachers. And yet, teachers, students, and their families/caregivers \\nneed support to build appropriate levels of trust in systems that affect their work. In the broader \\necosystem, trustworthy AI is recognized as a multidimensional problem (including the \\ndimensions of Figure 14, above). If every step forward does not include strong elements of trust \\nbuilding, we worry that distrust will distract from innovation serving the public good that AI',\n",
       " 'dimensions of Figure 14, above). If every step forward does not include strong elements of trust \\nbuilding, we worry that distrust will distract from innovation serving the public good that AI \\ncould help realize. \\nWe expect that associations and societies have a key role in strengthening trust. Some important \\nassociations like the State Educational Technology Directors Association and the Consortium for \\nSchool Network work with edtech leaders, and parallel organizations like EDUCAUSE work with \\npostsecondary leaders. Other associations and societies work with teachers, education leaders, \\nand education staff developers. Industry networks, like the EdSAFE AI Alliance, can bring \\ntogether industry leaders to work together to foster trust. Additional societies bring researchers \\ntogether. These societies and associations have the reach necessary to bring all parts of the \\neducational ecosystem into discussions about trust and also the ability to represent the views of',\n",
       " 'together. These societies and associations have the reach necessary to bring all parts of the \\neducational ecosystem into discussions about trust and also the ability to represent the views of \\ntheir constituents in cross-cutting policy discussions. \\nRecommendation #5: Inform and Involve Educators \\nOur listening sessions also asked for more specific direction on the question of what education \\nleaders should do (see Figure 15). The most frequent responses fit three clusters: the need for \\nguidelines and guardrails, strengthening the role of teachers, and re-focusing research and \\ndevelopment. These are activities that constituents are asking for and that could expand trust. \\nThe recommendations that follow respond to these requests.',\n",
       " '58 \\nFigure 15: Listening session attendees prioritized involving practitioners, research, and \\nevaluation and the need for guidelines and guardrails. \\n \\nIn particular, one concern that repeatedly arose in our listening sessions was the potential for AI \\nto result in less respect for educators or less value for their skills. Across the nation, we are now \\nresponding to decreasing interest in entering or remaining in the teaching profession. Now is the \\ntime to show the respect and value we hold for educators by informing and involving them in \\nevery step of the process of designing, developing, testing, improving, adopting, and managing \\nAI-enabled edtech. This includes involving educators in reviewing existing AI-enabled systems, \\ntools, and data use in schools, designing new applications of AI based on teacher input, carrying \\nout pilot evaluations of proposed new instructional tools, collaborating with developers to',\n",
       " 'tools, and data use in schools, designing new applications of AI based on teacher input, carrying \\nout pilot evaluations of proposed new instructional tools, collaborating with developers to \\nincrease the trustworthiness of the deployed system, and raising issues about risks and \\nunexpected consequences as the system is implemented. \\nWe have already seen educators rise to the challenge of creating overall guidelines, designing \\nspecific uses of available AI-enabled systems and tools, and ferreting out concerns. And yet, the \\ninfluence of educators in the future of AI-enabled products cannot be assumed; instead, \\nconstituents need policies that put muscle behind it. Could we create a national corps of leading \\neducators representing every state and region to provide leadership? Could we commit to \\ndeveloping necessary professional development supports? Can we find ways to compensate \\neducators so they can be at the forefront of designing the future of education? Our policies',\n",
       " 'developing necessary professional development supports? Can we find ways to compensate \\neducators so they can be at the forefront of designing the future of education? Our policies \\nshould enable educators to be closely involved in design of AI-enabled educational systems. \\nAlthough we know that the responsibility for informing and involving educators must be \\ndistributed at all levels of national and school governance, the Office of Educational Technology',\n",
       " '59 \\ncan play a key role in informing and involving educators through its reports, events, outreach, \\nand in a future NETP. Although examples above refer to K-12 teachers, higher education \\ninstructors must also be included. We also call on the edtech industry to involve educators \\nthroughout their design and development processes. For example, AI-enabled teaching assistants \\nare only likely to help teachers do their job if teachers are thoroughly involved as the assistants \\nare designed. We call upon institutions that prepare teachers to integrate technology more \\nsystematically into their programs; for example, the use of technology in teaching and learning \\nshould be a core theme across teacher preparation programs, not an issue that arises only in one \\ncourse. \\nRecommendation #6: Focus R&D on Addressing Context and \\nEnhancing Trust and Safety \\nResearch that focuses on how AI-enabled systems can adapt to context (including variability',\n",
       " 'course. \\nRecommendation #6: Focus R&D on Addressing Context and \\nEnhancing Trust and Safety \\nResearch that focuses on how AI-enabled systems can adapt to context (including variability \\namong learners) in instructional approaches and across educational settings is essential to \\nanswering the question of, “Do specific applications of AI work in education, and if so, for whom \\nand under what conditions?” The italicized phrase points to variability among learners and \\ndiversity in the settings for learning. We call upon innovators in R&D to focus their efforts to \\nadvance AI on the long tail of learning variability, where large populations of students would \\nbenefit from customization of learning. We also call on R&D to lead by establishing how trust \\ncan be strengthened in AI-enabled systems, building on the Blueprint’s call for safe and effective \\nsystems yet also including education-specific requirements, such as how teachers can be',\n",
       " 'can be strengthened in AI-enabled systems, building on the Blueprint’s call for safe and effective \\nsystems yet also including education-specific requirements, such as how teachers can be \\nmeaningfully involved in design phases, not only in implementation and evaluation. \\nAlthough many products today are adaptive, some adapt on just one or a few dimensions of \\nvariability, such as student’s accuracy in problem solving. As teachers know, there are many \\nmore important ways to adapt to students’ strengths and needs. Students are neurodiverse and \\nmay have specific disabilities. They bring different assets from their experiences at home, in \\ncommunities, and in their cultures. They have different interests and motivations. They are in \\ndifferent places in their journeys to master the English language. And they learn in varied \\nsettings. Classrooms and schools are different, and at home, students learn in informal settings in',\n",
       " 'different places in their journeys to master the English language. And they learn in varied \\nsettings. Classrooms and schools are different, and at home, students learn in informal settings in \\nways that could complement school learning. We recommend attention to “context” as a means \\nfor expressing the multiple dimensions that must be considered when elaborating the phrase \\n“for whom and under what conditions.” We also acknowledge the role of researchers in \\nconducting evaluations, which must now consider not only efficacy but must also explore where \\nharm may arise and the system problems that can occur through weak trust or over-trust in AI \\nsystems. \\nR&D must take the lead in making AI models more context-sensitive and ensuring that they are \\neffective, safe, and trustworthy for use with varied learners in diverse settings. Although AI has \\ncapabilities to find patterns beyond the limited number of variables that people normally think',\n",
       " 'effective, safe, and trustworthy for use with varied learners in diverse settings. Although AI has \\ncapabilities to find patterns beyond the limited number of variables that people normally think \\nabout, AI is not particularly good at understanding and working with context in the ways people \\ndo. Over time, we’ve seen learning sciences grow to be less about individualistic cognitive \\nprinciples and more encompassing first of social learning and then of the many dimensions of \\ncontext that matter in learning. Our use of AI needs to follow this trajectory toward context to \\nsupport educational applications. \\nTo achieve human-centric vision, listening session attendees argued that teams will need time \\nand freedom to explore how best to manage the tension between the pace of technological',\n",
       " '60 \\nadvancement and the need for broader contextual insights—for trust and for safety. They will \\nneed time and freedom to pioneer new processes that better involve teachers and students as co-\\ndesigners, with attention to balancing power dynamics. And they will need to shift attention \\nfrom older ways of framing priorities (such as achievement gaps) to new ways of prioritizing \\ndigital equity. We call on R&D funders to focus resources on the long tail of learner variability, \\nthe need for AI-enabled systems that better incorporate context, and time required to get \\ncontextual considerations right. We call upon researchers and developers to prioritize challenges \\nof context, trust, and safety in their work to advance AI.  \\nRecommendation #7: Develop Education-Specific Guidelines and \\nGuardrails \\nOur final recommendation is central to policymakers. A feature of the American educational \\nsystem is the emphasis on local decision making. With technology growing in complexity at such',\n",
       " 'Guardrails \\nOur final recommendation is central to policymakers. A feature of the American educational \\nsystem is the emphasis on local decision making. With technology growing in complexity at such \\na rapid pace, it is becoming difficult for local leaders to make informed decisions about the \\ndeployment of artificial intelligence. As we have discussed, the issues are not only data privacy \\nand security but extend to new topics such as bias, transparency, and accountability. It will be \\nharder to evaluate promising edtech platforms that rely on AI systems against this evolving, \\ncomplex set of criteria.  \\nRegulations related to key student and family data privacy laws like the Family Educational \\nRights & Privacy Act (FERPA), the Children’s Internet Privacy Act (CIPA), and the Children’s \\nOnline Privacy Protection Act (COPPA) warrant review and further consideration in light of new \\nand emerging technologies in schools. Laws such as the Individuals with Disabilities Education',\n",
       " 'Online Privacy Protection Act (COPPA) warrant review and further consideration in light of new \\nand emerging technologies in schools. Laws such as the Individuals with Disabilities Education \\nAct (IDEA) may likewise be considered as new situations arise in the use of AI-enabled learning \\ntechnologies. As discussed throughout this document, the Blueprint for an AI Bill of Rights is an \\nimportant framework throughout this work.  \\nThe Department encourages parallel work by constituents in all levels of the educational system. \\nIn addition to the key federal laws cited immediately above, many states have also passed privacy \\nlaws that govern the use of educational technology and edtech platforms in classrooms. Further \\nconstituents can expect general frameworks for responsible AI in parallel sectors like health, \\nsafety, and consumer products to be informative but not sufficient for education’s specific needs.',\n",
       " 'constituents can expect general frameworks for responsible AI in parallel sectors like health, \\nsafety, and consumer products to be informative but not sufficient for education’s specific needs. \\nLeaders at every level need awareness of how this work reaches beyond implications for privacy \\nand security (e.g., to include awareness of potential bias and unfairness), and they need \\npreparation to effectively confront the next level of issues.  \\nNext Steps \\nWe are heartened to see intensifying discussions throughout the educational ecosystem about \\nthe role of AI. We see progress that we can build upon occurring, as constituents discuss these \\nthree types of questions: What are the most significant opportunities and risks? How can we \\nachieve trustworthy educational AI? How can we understand the models at the heart of \\napplications of AI and ensure they have the qualities that align to educational aspirations?',\n",
       " 'achieve trustworthy educational AI? How can we understand the models at the heart of \\napplications of AI and ensure they have the qualities that align to educational aspirations?  \\nThe Department developed this report with awareness of contributions arising from many types \\nof organizations and collectives. Internationally, we recognize parallel efforts to consider AI in \\nthe European Union, at the United Nations, and indeed throughout the world. We are aware of \\nprogress being led by organizations such as UNESCO, the EdSAFE AI Alliance, and research',\n",
       " '61 \\norganizations in many countries. We plan to continue cross-agency work, for example, by \\ncontinuing to coordinate with the Office of Science and Technology Policy and other Federal \\nagencies as agencies implement next steps guided by the Blueprint for an AI Bill of Rights. We see a \\nbroad and fertile context for necessary next steps:  \\n● Working within this context and with others, the Department will consider specific \\npolicies and regulations so that educators can realize the opportunities of AI in edtech \\nwhile minimizing risks. For example, the Department is developing a set of AI usage \\nscenarios to strengthen the process of evaluating and enhancing policies and regulations. \\nThe principles and practices in the Blueprint for an AI Bill of Rights will be used to ensure \\nthe scenarios mitigate important risks and harms.  \\n● Working with constituents (including education leaders; teachers, faculty, support staff,',\n",
       " 'the scenarios mitigate important risks and harms.  \\n● Working with constituents (including education leaders; teachers, faculty, support staff, \\nand other educators; researchers; policymakers; funders; technology developers; \\ncommunity members and organizations; and above all, learners and their \\nfamilies/caregivers), we will develop additional resources and events to increase \\nunderstanding of AI and to involve those who will be most affected by these new \\ntechnologies.  \\n● Working across sectors, such as education, innovation, research, and policy, we will revise \\nand update the NETP to guide all constituents toward safe, equitable, and effective AI in \\neducation in the United States, in alignment with our overall educational priorities.',\n",
       " '62 \\nCommon Acronyms and \\nAbbreviations \\n⚫ AES: Automated Essay Scoring \\n⚫ AI: Artificial Intelligence \\n⚫ CIPA: Children’s Internet Protection Act \\n⚫ COPPA: Children’s Online Privacy Protection Act \\n⚫ Edtech: Educational Technology \\n⚫ ESEA: Elementary and Secondary Education Act \\n⚫ ESSA: Every Student Succeeds Act \\n⚫ FERPA: Family Educational Rights and Privacy Act \\n⚫ IA: Intelligence Augmentation \\n⚫ IDEA: Individuals with Disabilities Education Act \\n⚫ IEP: Individualized Education Program \\n⚫ ITS: Intelligent Tutoring Systems \\n⚫ NETP: National Education Technology Plan \\n⚫ R&D: Research & Development',\n",
       " '63 \\nAcknowledgements \\nProject Team \\nArtificial Intelligence and the Future of Teaching and Learning was developed under the leadership \\nand guidance of Roberto J. Rodríguez, Assistant Secretary for the Office of Planning, Evaluation, \\nand Policy Development, Kristina Ishmael, Deputy Director of the Office of Educational \\nTechnology, and Bernadette Adams, Senior Policy Advisor for the Office of Educational \\nTechnology at the U.S. Department of Education.  \\nSupport for the creation of this document was provided by Digital Promise, led by Jeremy \\nRoschelle with Carly Chillmon, Judi Fusco, Gabrielle Lue, Eric Nentrup, My Nguyen, Pati \\nRuiz, and Zohal Shah. Special thanks to Center for Integrative Research in Computing and \\nLearning Sciences postdocs Michael Chang and Aditi Mallavarapu. \\nListening Session Panelists and Hosts\\nHal Abelson \\nRyan Baker \\nNancye Blair Black \\nMarcelo Aaron Bonilla \\nWorsley \\nMichael Chang \\nCarly Chillmon \\nSherice Clarke \\nTammy Clegg \\nSidney d’Mello \\nJudi Fusco',\n",
       " 'Hal Abelson \\nRyan Baker \\nNancye Blair Black \\nMarcelo Aaron Bonilla \\nWorsley \\nMichael Chang \\nCarly Chillmon \\nSherice Clarke \\nTammy Clegg \\nSidney d’Mello \\nJudi Fusco \\nDragan Gasevic \\nKip Glazer \\nJanice Gobert \\nSarah Hampton \\nKristina Ishmael \\nJim Larimore \\nNicol Turner Lee \\nSherry Loftin \\nGabrielle Lue \\nAditi Mallavarapu \\nOle Molvig \\nPeter Norvig \\nThomas Philip \\nVidula Plante \\nJeremy Roschelle \\nPati Ruiz \\nAlina Von Davier \\nErin Walker \\nDiego Zapata \\nWe also thank 1,075 people who registered for Listening Sessions and 700 who attended.',\n",
       " '64 \\nReferences \\nAkgun, S., Greenhow, C. (2022). Artificial intelligence in education: Addressing ethical \\nchallenges in K-12 settings. AI Ethics, 2, 431–440. https://doi.org/10.1007/s43681-021-\\n00096-7 \\nAleven, V., McLaughlin, E. A., Glenn, R. A., & Koedinger, K. R. (2016). Instruction based on \\nadaptive learning technologies. In Mayer, R.E. & Alexander, P.A., Handbook of research on \\nlearning and instruction, 522-560. ISBN: 113883176X \\nBaker, R.S., Esbenshade, L., Vitale, J., & Karumbaiah, S. (2022). Using demographic data as \\npredictor variables: A questionable choice. https://doi.org/10.35542/osf.io/y4wvj \\nBlack, P. & Wiliam, D. (1998). Inside the black box: Raising standards through classroom \\nassessment. Phi Delta Kappan, 92(1), 81-90. https://kappanonline.org/inside-the-black-\\nbox-raising-standards-through-classroom-assessment/ \\nBlack, P., & Wiliam, D. (2009). Developing the theory of formative assessment. Educational',\n",
       " 'box-raising-standards-through-classroom-assessment/ \\nBlack, P., & Wiliam, D. (2009). Developing the theory of formative assessment. Educational \\nAssessment, Evaluation and Accountability, 21(1), 5-31. https://doi.org/10.1007/s11092-008-\\n9068-5 \\nBoden, M.A. (2018). Artificial intelligence: A very short introduction. Oxford. ISBN: 978-0199602919 \\nBryant, J., Heitz,C., Sanghvi, S., & Wagle, D. (2020, January 14). How artificial intelligence will \\nimpact K-12 teachers. McKinsey. https://www.mckinsey.com/industries/education/our-\\ninsights/how-artificial-intelligence-will-impact-k-12-teachers \\nCelik, I., Dindar, M., Muukkonen, H. & Järvelä, S. (2022). The promises and challenges of \\nartificial intelligence for teachers: A systematic review of research. TechTrends, 66, 616–\\n630. https://doi.org/10.1007/s11528-022-00715-y \\nCenter for Integrative Research in Computing and Learning Sciences (CIRCLS). (2022, Feb.). \\nFrom Broadening to empowering: Reflecting on the CIRCLS’21 Convening.',\n",
       " 'Center for Integrative Research in Computing and Learning Sciences (CIRCLS). (2022, Feb.). \\nFrom Broadening to empowering: Reflecting on the CIRCLS’21 Convening. \\nhttps://circls.org/circls21report \\nChen, C., Park, H.W. & Breazeal, C. (2020). Teaching and learning with children: Impact of \\nreciprocal peer learning with a social robot on children’s learning and emotive \\nengagement. Computers & Education, 150, https://doi.org/10.1016/j.compedu.2020.103836 \\nChen, G., Clarke, S., & Resnick, L.B. (2015). Classroom Discourse Analyzer (CDA): A discourse \\nanalytic tool for teachers. Technology, Instruction, Cognition and Learning, 10(2), 85-105 \\nDieterle, E., Dede, C. & Walker, M. (2022). The cyclical ethical effects of using artificial \\nintelligence in education. AI & Society. https://link.springer.com/article/10.1007/s00146-\\n022-01497-w \\nDoewes, A. & Pechenizkiy, M. (2021). On the limitations of human-computer agreement in',\n",
       " 'intelligence in education. AI & Society. https://link.springer.com/article/10.1007/s00146-\\n022-01497-w \\nDoewes, A. & Pechenizkiy, M. (2021). On the limitations of human-computer agreement in \\nautomated essay scoring. In Proceedings of the 14th International Conference on Educational \\nData Mining (EDM21). \\nhttps://educationaldatamining.org/EDM2021/virtual/static/pdf/EDM21_paper_243.pdf \\nEnglebart, D.C. (October 1962). Augmenting human intellect: A conceptual framework. SRI Summary \\nReport AFOSR-3223. https://www.dougengelbart.org/pubs/augment-3906.html \\nErsozlu, Z., Ledger, S., Ersozlu, A., Mayne, F., & Wildy, H. (2021). Mixed-reality learning \\nenvironments in teacher education: An analysis of TeachLivETM Research. SAGE Open, \\n11(3). https://doi.org/10.1177/21582440211032155. \\nEuropean Commission, Directorate-General for Education, Youth, Sport and Culture. \\n(2022). Ethical guidelines on the use of artificial intelligence (AI) and data in teaching and',\n",
       " \"European Commission, Directorate-General for Education, Youth, Sport and Culture. \\n(2022). Ethical guidelines on the use of artificial intelligence (AI) and data in teaching and \\nlearning for educators. Publications Office of the European \\nUnion. https://data.europa.eu/doi/10.2766/153756 \\nForsyth, S., Dalton, B., Foster, E.H., Walsh, B., Smilack, J., & Yeh, T. (2021, May). Imagine a more \\nethical AI: Using stories to develop teens' awareness and understanding of artificial \\nintelligence and its societal impacts. In 2021 Conference on Research in Equitable and \\nSustained Participation in Engineering, Computing, and Technology (RESPECT). IEEE. \\nhttps://doi.org/10.1109/RESPECT51740.2021.9620549 \\nFriedman, L., Blair Black, N., Walker, E., & Roschelle, J. (November 8, 2021) Safe AI in education \\nneeds you. Association of Computing Machinery BLOG@ACM, \\nhttps://cacm.acm.org/blogs/blog-cacm/256657-safe-ai-in-education-needs-you/fulltext\",\n",
       " '65 \\nGardner, J., O\\'Leary, M. & Yuan, L. (2021). Artificial intelligence in educational assessment: \\n\"Breakthrough? Or buncombe and ballyhoo?\" Journal of Computer Assisted Learning, 37(5), \\n1207–1216. https://doi.org/10.1111/jcal.12577 \\nGartner (n.d.) Gartner glossary: Augmented intelligence. Gartner. \\nhttps://www.gartner.com/en/information-technology/glossary/augmented-intelligence \\nGay, G. (2018). Culturally responsive teaching: Theory, research, and practice. Teachers College Press. \\nISBN: 978-0807758762 \\nGodwin-Jones, R. (2021). Big data and language learning: Opportunities and challenges. \\u2028\\nLanguage Learning & Technology, 25(1), 4–19. http://hdl.handle.net/10125/44747 \\nHammerness, K., Darling-Hammond, L., & Bransford, J. (2005). Preparing teachers for a changing \\nworld: What teachers should learn and be able to do. Jossey-Bass. ISBN: 0787996343 \\nHolmes, W. & Porayska-Pomsta, K. (Eds.) (2022). The ethics of artificial intelligence in education. \\nRoutledge. ISBN 978-0367349721',\n",
       " \"Holmes, W. & Porayska-Pomsta, K. (Eds.) (2022). The ethics of artificial intelligence in education. \\nRoutledge. ISBN 978-0367349721 \\nHolstein, K., McLaren, B.M., & Aleven, V. (2019). Co-designing a real-time classroom \\norchestration tool to support teacher–AI complementarity. Journal of Learning Analytics, \\n6(2). https://doi.org/10.18608/jla.2019.62.3 \\nIEEE-USA Board of Directors. (February 10, 2017). Artificial intelligence research, development and \\nregulation. IEEE http://globalpolicy.ieee.org/wp-content/uploads/2017/10/IEEE17003.pdf \\nJensen, E., Dale, M., Donnelly, P.J., Stone, C., Kelly, S., Godley, A. & D'Mello, S.K. (2020). Toward \\nautomated feedback on teacher discourse to enhance teacher learning. In Proceedings of \\nthe 2020 CHI Conference on Human Factors in Computing Systems (CHI '20). \\nhttps://doi.org/10.1145/3313831.3376418 \\nKai, S., Almeda, M.V., Baker, R. S., Heffernan, C., & Heffernan, N. (2018). Decision tree modeling\",\n",
       " 'https://doi.org/10.1145/3313831.3376418 \\nKai, S., Almeda, M.V., Baker, R. S., Heffernan, C., & Heffernan, N. (2018). Decision tree modeling \\nof wheel-spinning and productive persistence in skill builders. Journal of Educational Data \\nMining, 10(1), 36–71. https://doi.org/10.5281/zenodo.3344810 \\nKaplan, R.M., & Saccuzzo, D.P. (2017). Psychological testing: Principles, applications, and issues. \\nCengage Learning. \\nKe, Z., & Ng, V. (2019). Automated essay scoring: A survey of the state of the art. In Proceedings of \\nthe Twenty-Eighth International Joint Conference on Artificial Intelligence, 6300–6308. \\nhttps://doi.org/10.24963/ijcai.2019/879 \\nKhosravi, H., Shum, S.B., Chen, G, Conati, C., Tsai,Y-S., Kay, J., Knight, S., Martinez-Maldonado, \\nR., Sadiq, S., Gašević, D. (2022). Explainable artificial intelligence in education. \\nComputers and Education: Artificial Intelligence, 3. \\nhttps://doi.org/10.1016/j.caeai.2022.100074',\n",
       " 'R., Sadiq, S., Gašević, D. (2022). Explainable artificial intelligence in education. \\nComputers and Education: Artificial Intelligence, 3. \\nhttps://doi.org/10.1016/j.caeai.2022.100074 \\nKulik, J.A., & Fletcher, J.D. (2016). Effectiveness of intelligent tutoring systems: A meta-analytic \\nreview. Review of Educational Research, 86(1), 42–78 \\nMa, W., Adescope, O.O, Nesbit, J.C. & Liu, Q. (2014). Intelligent tutoring systems and learning \\noutcomes: A meta-analysis. Journal of Educational Psychology, 106(4), 901–918. \\nhttp://dx.doi.org/10.1037/a0037123 \\nMaslej, N., Fattorini, L., Brynjolfsson E., Etchemendy, J., Ligett, K., Lyons, T., Manyika, J., Ngo, \\nH., Niebles, J.C., Parli, V., Shoham, Y., Wald, R., Clark, J. and Perrault, R., (2023). The AI \\nindex 2023 annual report. Stanford University: AI Index Steering Committee, Institute for \\nHuman-Centered AI.  \\nMerrill, S. (2020). In schools, are we measuring what matters? Edutopia.',\n",
       " 'index 2023 annual report. Stanford University: AI Index Steering Committee, Institute for \\nHuman-Centered AI.  \\nMerrill, S. (2020). In schools, are we measuring what matters? Edutopia. \\nhttps://www.edutopia.org/article/schools-are-we-measuring-what-matters \\nMolenaar, I. (2022). Towards hybrid human-AI learning technologies. European Journal of \\nEducation, 00, 1–14. https://doi.org/10.1111/ejed.12527 \\nMostow, J., Aist, G., Burkhead, P., Corbett, A., Cuneo, A., Eitelman, S., Huang, C., Junker, B., \\nSklar, M.B., & Tobin, B. (2003). Evaluation of an automated reading tutor that listens: \\nComparison to human tutoring and classroom instruction. Journal of Educational \\nComputing Research, 29(1), 61–117. https://doi.org/10.2190/06AX-QW99-EQ5G-RDCF \\nMousavinasab, E., Zarifsanaiey, N., R. Niakan Kalhori, S., Rakhshan, M., Keikha, L., & Ghazi \\nSaeedi, M. (2021). Intelligent tutoring systems: A systematic review of characteristics,',\n",
       " 'Mousavinasab, E., Zarifsanaiey, N., R. Niakan Kalhori, S., Rakhshan, M., Keikha, L., & Ghazi \\nSaeedi, M. (2021). Intelligent tutoring systems: A systematic review of characteristics, \\napplications, and evaluation methods. Interactive Learning Environments, 29(1), 142–163. \\nhttps://psycnet.apa.org/doi/10.1080/10494820.2018.1558257 \\nNational Academies of Sciences, Engineering, and Medicine. 2018. How people learn II: Learners, \\ncontexts, and cultures. The National Academies Press. https://doi.org/10.17226/24783',\n",
       " '66 \\nNational Research Council. 2000. How people learn: Brain, mind, experience, and school. The \\nNational Academies Press. https://doi.org/10.17226/9853 \\nNentrup, E. (2022). How Policymakers Can Support Educators and Technology Vendors Towards SAFE \\nAI. EdSAFE AI Alliance. https://www.edsafeai.org/post/how-policymakers-can-support-\\naied \\nPage, E.B. (1966). The imminence of grading essays by computer. Phi Delta Kappan, 47(5), 238–\\n243 \\nParis, D., & Alim, H.S. (Eds.). (2017). Culturally sustaining pedagogies: Teaching and learning for \\njustice in a changing world. Teachers College Press. ISBN: 978-0807758342 \\nPlass, J.L., & Pawar, S. (2020). Toward a taxonomy of adaptivity for learning. Journal of Research \\non Technology in Education, 52(3), 275–300. https://doi.org/10.1080/15391523.2020.1719943  \\nRegona, Massimo & Yigitcanlar, Tan & Xia, Bo & Li, R.Y.M. (2022). Opportunities and adoption \\nchallenges of AI in the construction industry: A PRISMA review. Journal of Open',\n",
       " 'Regona, Massimo & Yigitcanlar, Tan & Xia, Bo & Li, R.Y.M. (2022). Opportunities and adoption \\nchallenges of AI in the construction industry: A PRISMA review. Journal of Open \\nInnovation Technology Market and Complexity, 8(45). https://doi.org/10.3390/joitmc8010045 \\nReynolds, C.R., & Suzuki, L.A. (2012). Bias in psychological assessment: An empirical review and \\nrecommendations. Handbook of Psychology, Second Edition. \\nhttps://doi.org/10.1002/9781118133880.hop210004 \\nRitter, S., Anderson, J.R., Koedinger, K.R. & Corbett, A. (2007). Cognitive Tutor: Applied \\nresearch in mathematics education. Psychonomic Bulletin & Review, 14, 249–255/ \\nhttps://doi.org/10.3758/BF03194060 \\nRoll, I., Aleven, V., McLaren, B.M., Koedinger, K.R. (2011). Improving students’ help-seeking \\nskills using metacognitive feedback in an intelligent tutoring system, Learning and \\nInstruction, 21(2), 267–280. https://doi.org/10.1016/j.learninstruc.2010.07.004.',\n",
       " 'skills using metacognitive feedback in an intelligent tutoring system, Learning and \\nInstruction, 21(2), 267–280. https://doi.org/10.1016/j.learninstruc.2010.07.004. \\nRoschelle, J., Dimitriadis, Y. & Hoppe, U. (2013). Classroom orchestration: Synthesis. Computers \\n& Education, 69, 512-526. https://doi.org/10.1016/j.compedu.2013.04.010 \\nRoschelle, J., Feng, M., Murphy, R. & Mason, C.A. (2016). Online mathematics homework \\nincreases student achievement. AERA Open, 2(4), 1-12. DOI: 10.1177/2332858416673968 \\nRoschelle, J., Penuel, W., & Shechtman, N. (2006). Co-design of innovations with teachers: \\ndefinition and dynamics. In Proceedings of the 7th International Conference on Learning \\nSciences, Bloomington, IN. https://doi.dx.org/10.22318/icls2006.606 \\nRose, D. (2000). Universal design for learning. Journal of Special Education Technology, 15(4), 47-51. \\nhttps://doi.org/10.1177/016264340001500407',\n",
       " 'Rose, D. (2000). Universal design for learning. Journal of Special Education Technology, 15(4), 47-51. \\nhttps://doi.org/10.1177/016264340001500407 \\nRuiz, P. & Fusco, J. (2022). Teachers partnering with artificial intelligence: Augmentation and \\nautomation. Digital Promise. https://digitalpromise.org/2022/07/06/teachers-partnering-\\nwith-artificial-intelligence-augmentation-and-automation/ \\nRussell, S. (2019). Human compatible: Artificial intelligence and the problem of control. Viking. ISBN \\n978-0-525-55861-3. \\nShao, Q., Sniffen, A., Blanchet, J., Hillis, M.E., Shi, X., Haris, T.K., & Balkcom, D. (2020). \\nTeaching american sign language in mixed reality. Proceedings of the ACM on Interactive, \\nMobile, Wearable and Ubiquitous Technologies, 4(4), 1-27. https://doi.org/10.1145/3432211 \\nSharples, M. & Pérez y Pérez, R. (2022). Story machines: How computers have become creative writers. \\nRoutledge. ISBN 9780367751951',\n",
       " \"Sharples, M. & Pérez y Pérez, R. (2022). Story machines: How computers have become creative writers. \\nRoutledge. ISBN 9780367751951 \\nShemshack, A., Spector, J.M. (2020) A systematic literature review of personalized learning \\nterms. Smart Learning Environments, 7(33). https://doi.org/10.1186/s40561-020-00140-9 \\nShute, V J. (2008). Focus on formative feedback. Review of Educational Research, 78(1), 153–189. \\nhttps://doi.org/10.3102/0034654307313795 \\nShute, V. J., Ventura, M., & Kim, Y. J. (2013). Assessment and learning of qualitative physics in \\nNewton's Playground. The Journal of Educational Research, 106(6), 423-430. \\nhttps://doi.org/10.1080/00220671.2013.832970 \\nSwiecki, Z., Khosravi, H., Chen, G., Martinez-Maldonado, R., Lodge, J.M., Milligan, S., Selwyn, B. \\n& Gašević,D. (2022). Assessment in the age of artificial intelligence. Computers and \\nEducation: Artificial Intelligence, 3. https://doi.org/10.1016/j.caeai.2022.100075\",\n",
       " '& Gašević,D. (2022). Assessment in the age of artificial intelligence. Computers and \\nEducation: Artificial Intelligence, 3. https://doi.org/10.1016/j.caeai.2022.100075 \\nThe White House (February 17, 2023). Executive order on further advancing racial equity and support \\nfor underserved communities through the federal government. \\nhttps://www.whitehouse.gov/briefing-room/presidential-actions/2023/02/16/executive-\\norder-on-further-advancing-racial-equity',\n",
       " '67 \\nThe White House (September 8, 2022). Readout of White House listening session on tech platform \\naccountability. https://www.whitehouse.gov/briefing-room/statements-\\nreleases/2022/09/08/readout-of-white-house-listening-session-on-tech-platform-\\naccountability/ \\nU.S. Department of Education, Office of Educational Technology (2022). Advancing digital equity \\nfor all: Community-based recommendations for developing effective digital equity plans to close the \\ndigital divide and enable technology-empowered learning. US Department of Education. \\nU.S. Department of Education, Office of Educational Technology. (2010). Transforming American \\nEducation: Learning Powered by Technology. U.S. Department of Education. p. 78 \\nVan Lehn, K. (2011) The relative effectiveness of human tutoring, intelligent tutoring systems, \\nand other tutoring systems. Educational Psychologist, 46(4), 197-221. \\nhttps://doi.org/10.1080/00461520.2011.611369',\n",
       " 'and other tutoring systems. Educational Psychologist, 46(4), 197-221. \\nhttps://doi.org/10.1080/00461520.2011.611369 \\nWagner, A.R., Borenstein, J. & Howard, A. (September 2018). Overtrust in the robotics age. \\nCommunications of the ACM, 61(9), 22-24. https://doi.org/10.1145/3241365 \\nWalker, E., Rummel, N. & Koedinger, K.R. (2015). Adaptive intelligent support to improve peer \\ntutoring in algebra. International Journal of Artificial Intelligence in Education, 24, 33–61 \\nhttps://doi.org/10.1007/s40593-013-0001-9 \\nWalton Family Foundation (March 1, 2023). Teachers and students embrace ChatGPT for education. \\nhttps://www.waltonfamilyfoundation.org/learning/teachers-and-students-embrace-\\nchatgpt-for-education \\nWebb, N.M., & Farivar, S. (1994). Promoting helping behavior in cooperative small groups in \\nmiddle school mathematics. American Educational Research Journal, 31(2), 369–395. \\nhttps://doi.org/10.3102/00028312031002369',\n",
       " 'middle school mathematics. American Educational Research Journal, 31(2), 369–395. \\nhttps://doi.org/10.3102/00028312031002369 \\nWhite House Office of Science and Technology Policy (October 2022), Blueprint for an AI bill of \\nrights: Making automated systems work for the American people. The White House Office of \\nScience and Technology Policy. https://www.whitehouse.gov/ostp/ai-bill-of-rights/  \\nWiggins, G. (2015). Seven keys to effective feedback. ACSD. https://www.ascd.org/el/articles/seven-\\nkeys-to-effective-feedback \\nWinne, P.H. (2021). Open learner models working in symbiosis with self-regulating learners: A \\nresearch agenda. International Journal of Artificial Intelligence in Education, 31(3), 446-459. \\nhttps://doi.org/10.1007/s40593-020-00212-4 \\nZacamy, J. & Roschelle, J. (2022). Navigating the tensions: How could equity-relevant research also be \\nagile, open, and scalable? Digital Promise. http://hdl.handle.net/20.500.12265/159',\n",
       " 'Zacamy, J. & Roschelle, J. (2022). Navigating the tensions: How could equity-relevant research also be \\nagile, open, and scalable? Digital Promise. http://hdl.handle.net/20.500.12265/159 \\nZhai, X., He, P., Krajcik, J. (2022). Applying machine learning to automatically assess scientific \\nmodels. Journal of Research in Science Teaching. https://doi.org/10.1002/tea.21773 \\nZhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., & Breazeal, C. (2022). Integrating ethics and \\ncareer futures with technical learning to promote AI literacy for middle school students: \\nAn exploratory study. International Journal of Artificial Intelligence in Education, 1–35. \\nhttps://doi.org/10.1007/s40593-022-00293-3',\n",
       " 'Attention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser ∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly',\n",
       " 'entirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.0 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature.\\n1 Introduction\\nRecurrent neural networks, long short-term memory [12] and gated recurrent [7] neural networks\\nin particular, have been ﬁrmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 29, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder',\n",
       " 'transduction problems such as language modeling and machine translation [ 29, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [31, 21, 13].\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and',\n",
       " 'efﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.',\n",
       " 'Recurrent models typically factor computation along the symbol positions of the input and output\\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\\nstates ht, as a function of the previous hidden state ht−1 and the input for position t. This inherently\\nsequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsigniﬁcant improvements in computational efﬁciency through factorization tricks [18] and conditional\\ncomputation [26], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in',\n",
       " 'Attention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [2, 16]. In all but a few cases [22], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for signiﬁcantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2 Background\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[20], ByteNet [15] and ConvS2S [8], all of which use convolutional neural networks as basic building',\n",
       " 'The goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[20], ByteNet [15] and ConvS2S [8], all of which use convolutional neural networks as basic building\\nblock, computing hidden representations in parallel for all input and output positions. In these models,\\nthe number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difﬁcult to learn dependencies between distant positions [ 11]. In the Transformer this is\\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribed in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions',\n",
       " 'described in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 22, 23, 19].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [28].\\nTo the best of our knowledge, however, the Transformer is the ﬁrst transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate',\n",
       " 'aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [14, 15] and [8].\\n3 Model Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 29].\\nHere, the encoder maps an input sequence of symbol representations (x1,...,x n) to a sequence\\nof continuous representations z = (z1,...,z n). Given z, the decoder then generates an output\\nsequence (y1,...,y m) of symbols one element at a time. At each step the model is auto-regressive\\n[9], consuming the previously generated symbols as additional input when generating the next.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1 Encoder and Decoder Stacks',\n",
       " 'connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1 Encoder and Decoder Stacks\\nEncoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. The ﬁrst is a multi-head self-attention mechanism, and the second is a simple, position-\\n2',\n",
       " 'Figure 1: The Transformer - model architecture.\\nwise fully connected feed-forward network. We employ a residual connection [10] around each of\\nthe two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\\nLayerNorm(x+ Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.\\nDecoder: The decoder is also composed of a stack of N = 6identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This',\n",
       " 'around each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\\npredictions for position ican depend only on the known outputs at positions less than i.\\n3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1 Scaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\n3',\n",
       " 'Scaled Dot-Product Attention\\n Multi-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nquery with all keys, divide each by √dk, and apply a softmax function to obtain the weights on the\\nvalues.\\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\\ninto a matrix Q. The keys and values are also packed together into matrices Kand V. We compute\\nthe matrix of outputs as:\\nAttention(Q,K,V ) = softmax(QKT\\n√dk\\n)V (1)\\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\\nof 1√dk\\n. Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is',\n",
       " 'of 1√dk\\n. Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\\nmuch faster and more space-efﬁcient in practice, since it can be implemented using highly optimized\\nmatrix multiplication code.\\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\\ndot product attention without scaling for larger values of dk [3]. We suspect that for large values of\\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\\nextremely small gradients 4. To counteract this effect, we scale the dot products by 1√dk\\n.\\n3.2.2 Multi-Head Attention\\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,\\nwe found it beneﬁcial to linearly project the queries, keys and values htimes with different, learned',\n",
       " 'we found it beneﬁcial to linearly project the queries, keys and values htimes with different, learned\\nlinear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of\\nqueries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\\noutput values. These are concatenated and once again projected, resulting in the ﬁnal values, as\\ndepicted in Figure 2.\\nMulti-head attention allows the model to jointly attend to information from different representation\\nsubspaces at different positions. With a single attention head, averaging inhibits this.\\n4To illustrate why the dot products get large, assume that the components of q and k are independent random\\nvariables with mean 0 and variance 1. Then their dot product, q · k = ∑dk\\ni=1 qiki, has mean 0 and variance dk.\\n4',\n",
       " 'MultiHead(Q,K,V ) = Concat(head1,..., headh)WO\\nwhere headi = Attention(QWQ\\ni ,KW K\\ni ,VW V\\ni )\\nWhere the projections are parameter matricesWQ\\ni ∈Rdmodel×dk , WK\\ni ∈Rdmodel×dk , WV\\ni ∈Rdmodel×dv\\nand WO ∈Rhdv×dmodel .\\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\\ndk = dv = dmodel/h= 64. Due to the reduced dimension of each head, the total computational cost\\nis similar to that of single-head attention with full dimensionality.\\n3.2.3 Applications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[31, 2, 8].',\n",
       " 'position in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[31, 2, 8].\\n• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\\nand queries come from the same place, in this case, the output of the previous layer in the\\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder.\\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward\\ninformation ﬂow in the decoder to preserve the auto-regressive property. We implement this\\ninside of scaled dot-product attention by masking out (setting to −∞) all values in the input\\nof the softmax which correspond to illegal connections. See Figure 2.\\n3.3 Position-wise Feed-Forward Networks',\n",
       " 'of the softmax which correspond to illegal connections. See Figure 2.\\n3.3 Position-wise Feed-Forward Networks\\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\\nconnected feed-forward network, which is applied to each position separately and identically. This\\nconsists of two linear transformations with a ReLU activation in between.\\nFFN(x) = max(0,xW1 + b1)W2 + b2 (2)\\nWhile the linear transformations are the same across different positions, they use different parameters\\nfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.\\nThe dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality\\ndff = 2048.\\n3.4 Embeddings and Softmax\\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input\\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-',\n",
       " 'Similarly to other sequence transduction models, we use learned embeddings to convert the input\\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\\nmation and softmax function to convert the decoder output to predicted next-token probabilities. In\\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\\nlinear transformation, similar to [24]. In the embedding layers, we multiply those weights by √dmodel.\\n3.5 Positional Encoding\\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\\norder of the sequence, we must inject some information about the relative or absolute position of the\\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\\n5',\n",
       " 'Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\\nfor different layer types. nis the sequence length, dis the representation dimension, kis the kernel\\nsize of convolutions and rthe size of the neighborhood in restricted self-attention.\\nLayer Type Complexity per Layer Sequential Maximum Path Length\\nOperations\\nSelf-Attention O(n2 ·d) O(1) O(1)\\nRecurrent O(n·d2) O(n) O(n)\\nConvolutional O(k·n·d2) O(1) O(logk(n))\\nSelf-Attention (restricted) O(r·n·d) O(1) O(n/r)\\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\\nas the embeddings, so that the two can be summed. There are many choices of positional encodings,\\nlearned and ﬁxed [8].\\nIn this work, we use sine and cosine functions of different frequencies:\\nPE(pos,2i) = sin(pos/100002i/dmodel )\\nPE(pos,2i+1) = cos(pos/100002i/dmodel )\\nwhere posis the position and iis the dimension. That is, each dimension of the positional encoding',\n",
       " 'PE(pos,2i) = sin(pos/100002i/dmodel )\\nPE(pos,2i+1) = cos(pos/100002i/dmodel )\\nwhere posis the position and iis the dimension. That is, each dimension of the positional encoding\\ncorresponds to a sinusoid. The wavelengths form a geometric progression from 2πto 10000 ·2π. We\\nchose this function because we hypothesized it would allow the model to easily learn to attend by\\nrelative positions, since for any ﬁxed offset k, PEpos+k can be represented as a linear function of\\nPEpos.\\nWe also experimented with using learned positional embeddings [8] instead, and found that the two\\nversions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version\\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\\nduring training.\\n4 Why Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-',\n",
       " 'during training.\\n4 Why Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one variable-length sequence of symbol representations\\n(x1,...,x n) to another sequence of equal length (z1,...,z n), with xi,zi ∈Rd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\\nconsider three desiderata.\\nOne is the total computational complexity per layer. Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.\\nThe third is the path length between long-range dependencies in the network. Learning long-range\\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to',\n",
       " 'dependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to\\ntraverse in the network. The shorter these paths between any combination of positions in the input\\nand output sequences, the easier it is to learn long-range dependencies [11]. Hence we also compare\\nthe maximum path length between any two input and output positions in networks composed of the\\ndifferent layer types.\\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially\\nexecuted operations, whereas a recurrent layer requires O(n) sequential operations. In terms of\\ncomputational complexity, self-attention layers are faster than recurrent layers when the sequence\\nlength n is smaller than the representation dimensionality d, which is most often the case with',\n",
       " 'computational complexity, self-attention layers are faster than recurrent layers when the sequence\\nlength n is smaller than the representation dimensionality d, which is most often the case with\\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\\n[31] and byte-pair [25] representations. To improve computational performance for tasks involving\\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size rin\\n6',\n",
       " 'the input sequence centered around the respective output position. This would increase the maximum\\npath length to O(n/r). We plan to investigate this approach further in future work.\\nA single convolutional layer with kernel width k<n does not connect all pairs of input and output\\npositions. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels,\\nor O(logk(n)) in the case of dilated convolutions [ 15], increasing the length of the longest paths\\nbetween any two positions in the network. Convolutional layers are generally more expensive than\\nrecurrent layers, by a factor of k. Separable convolutions [ 6], however, decrease the complexity\\nconsiderably, to O(k·n·d+ n·d2). Even with k = n, however, the complexity of a separable\\nconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.',\n",
       " 'convolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.\\nAs side beneﬁt, self-attention could yield more interpretable models. We inspect attention distributions\\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\\nand semantic structure of the sentences.\\n5 Training\\nThis section describes the training regime for our models.\\n5.1 Training Data and Batching\\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\\nsentence pairs. Sentences were encoded using byte-pair encoding [ 3], which has a shared source-\\ntarget vocabulary of about 37000 tokens. For English-French, we used the signiﬁcantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece',\n",
       " 'target vocabulary of about 37000 tokens. For English-French, we used the signiﬁcantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\\nvocabulary [31]. Sentence pairs were batched together by approximate sequence length. Each training\\nbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000\\ntarget tokens.\\n5.2 Hardware and Schedule\\nWe trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We\\ntrained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the\\nbottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps\\n(3.5 days).\\n5.3 Optimizer\\nWe used the Adam optimizer [17] with β1 = 0.9, β2 = 0.98 and ϵ= 10−9. We varied the learning\\nrate over the course of training, according to the formula:',\n",
       " '(3.5 days).\\n5.3 Optimizer\\nWe used the Adam optimizer [17] with β1 = 0.9, β2 = 0.98 and ϵ= 10−9. We varied the learning\\nrate over the course of training, according to the formula:\\nlrate= d−0.5\\nmodel ·min(step_num−0.5,step_num·warmup_steps−1.5) (3)\\nThis corresponds to increasing the learning rate linearly for the ﬁrst warmup_stepstraining steps,\\nand decreasing it thereafter proportionally to the inverse square root of the step number. We used\\nwarmup_steps= 4000.\\n5.4 Regularization\\nWe employ three types of regularization during training:\\nResidual Dropout We apply dropout [27] to the output of each sub-layer, before it is added to the\\nsub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the\\npositional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\\nPdrop = 0.1.\\n7',\n",
       " 'Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\\nModel\\nBLEU Training Cost (FLOPs)\\nEN-DE EN-FR EN-DE EN-FR\\nByteNet [15] 23.75\\nDeep-Att + PosUnk [32] 39.2 1.0 ·1020\\nGNMT + RL [31] 24.6 39.92 2.3 ·1019 1.4 ·1020\\nConvS2S [8] 25.16 40.46 9.6 ·1018 1.5 ·1020\\nMoE [26] 26.03 40.56 2.0 ·1019 1.2 ·1020\\nDeep-Att + PosUnk Ensemble [32] 40.4 8.0 ·1020\\nGNMT + RL Ensemble [31] 26.30 41.16 1.8 ·1020 1.1 ·1021\\nConvS2S Ensemble [8] 26.36 41.29 7.7 ·1019 1.2 ·1021\\nTransformer (base model) 27.3 38.1 3.3 · 1018\\nTransformer (big) 28.4 41.0 2.3 ·1019\\nLabel Smoothing During training, we employed label smoothing of value ϵls = 0.1 [30]. This\\nhurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\\n6 Results\\n6.1 Machine Translation\\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)',\n",
       " '6 Results\\n6.1 Machine Translation\\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\\nin Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The conﬁguration of this model is\\nlisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model\\nsurpasses all previously published models and ensembles, at a fraction of the training cost of any of\\nthe competitive models.\\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\\noutperforming all of the previously published single models, at less than 1/4 the training cost of the\\nprevious state-of-the-art model. The Transformer (big) model trained for English-to-French used\\ndropout rate Pdrop = 0.1, instead of 0.3.\\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which',\n",
       " 'dropout rate Pdrop = 0.1, instead of 0.3.\\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which\\nwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We\\nused beam search with a beam size of 4 and length penalty α= 0.6 [31]. These hyperparameters\\nwere chosen after experimentation on the development set. We set the maximum output length during\\ninference to input length + 50, but terminate early when possible [31].\\nTable 2 summarizes our results and compares our translation quality and training costs to other model\\narchitectures from the literature. We estimate the number of ﬂoating point operations used to train a\\nmodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained\\nsingle-precision ﬂoating-point capacity of each GPU 5.\\n6.2 Model Variations\\nTo evaluate the importance of different components of the Transformer, we varied our base model',\n",
       " 'single-precision ﬂoating-point capacity of each GPU 5.\\n6.2 Model Variations\\nTo evaluate the importance of different components of the Transformer, we varied our base model\\nin different ways, measuring the change in performance on English-to-German translation on the\\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no\\ncheckpoint averaging. We present these results in Table 3.\\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\\n5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.\\n8',\n",
       " 'Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\\nmodel. All metrics are on the English-to-German translation development set, newstest2013. Listed\\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\\nper-word perplexities.\\nN d model dff h d k dv Pdrop ϵls\\ntrain PPL BLEU params\\nsteps (dev) (dev) ×106\\nbase 6 512 2048 8 64 64 0.1 0.1 100K 4.92 25.8 65\\n(A)\\n1 512 512 5.29 24.9\\n4 128 128 5.00 25.5\\n16 32 32 4.91 25.8\\n32 16 16 5.01 25.4\\n(B) 16 5.16 25.1 58\\n32 5.01 25.4 60\\n(C)\\n2 6.11 23.7 36\\n4 5.19 25.3 50\\n8 4.88 25.5 80\\n256 32 32 5.75 24.5 28\\n1024 128 128 4.66 26.0 168\\n1024 5.12 25.4 53\\n4096 4.75 26.2 90\\n(D)\\n0.0 5.77 24.6\\n0.2 4.95 25.5\\n0.0 4.67 25.3\\n0.2 5.47 25.7\\n(E) positional embedding instead of sinusoids 4.92 25.7\\nbig 6 1024 4096 16 0.3 300K 4.33 26.4 213\\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This',\n",
       " '(E) positional embedding instead of sinusoids 4.92 25.7\\nbig 6 1024 4096 16 0.3 300K 4.33 26.4 213\\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This\\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\\nfunction than dot product may be beneﬁcial. We further observe in rows (C) and (D) that, as expected,\\nbigger models are better, and dropout is very helpful in avoiding over-ﬁtting. In row (E) we replace our\\nsinusoidal positional encoding with learned positional embeddings [8], and observe nearly identical\\nresults to the base model.\\n7 Conclusion\\nIn this work, we presented the Transformer, the ﬁrst sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained signiﬁcantly faster than architectures based',\n",
       " 'multi-headed self-attention.\\nFor translation tasks, the Transformer can be trained signiﬁcantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\\nmodel outperforms even all previously reported ensembles.\\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efﬁciently handle large inputs and outputs\\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\\nThe code we used to train and evaluate our models is available at https://github.com/\\ntensorflow/tensor2tensor.\\nAcknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful',\n",
       " 'tensorflow/tensor2tensor.\\nAcknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\\ncomments, corrections and inspiration.\\n9',\n",
       " 'References\\n[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\\narXiv:1607.06450, 2016.\\n[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\\nlearning to align and translate. CoRR, abs/1409.0473, 2014.\\n[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V . Le. Massive exploration of neural\\nmachine translation architectures. CoRR, abs/1703.03906, 2017.\\n[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\\nreading. arXiv preprint arXiv:1601.06733, 2016.\\n[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,\\nand Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical\\nmachine translation. CoRR, abs/1406.1078, 2014.\\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\\npreprint arXiv:1610.02357, 2016.',\n",
       " 'machine translation. CoRR, abs/1406.1078, 2014.\\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\\npreprint arXiv:1610.02357, 2016.\\n[7] Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation\\nof gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\\n[8] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-\\ntional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\\n[9] Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint\\narXiv:1308.0850, 2013.\\n[10] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\\nRecognition, pages 770–778, 2016.\\n[11] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient ﬂow in',\n",
       " 'Recognition, pages 770–778, 2016.\\n[11] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient ﬂow in\\nrecurrent nets: the difﬁculty of learning long-term dependencies, 2001.\\n[12] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation,\\n9(8):1735–1780, 1997.\\n[13] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring\\nthe limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\\n[14] Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\\non Learning Representations (ICLR), 2016.\\n[15] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\\nray Kavukcuoglu. Neural machine translation in linear time.arXiv preprint arXiv:1610.10099v2,\\n2017.\\n[16] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.',\n",
       " '2017.\\n[16] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.\\n[17] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\\n[18] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\\narXiv:1703.10722, 2017.\\n[19] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130, 2017.\\n[20] Samy Bengio Łukasz Kaiser. Can active memory replace attention? In Advances in Neural\\nInformation Processing Systems, (NIPS), 2016.\\n10',\n",
       " '[21] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\\nbased neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\\n[22] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention\\nmodel. In Empirical Methods in Natural Language Processing, 2016.\\n[23] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\\nsummarization. arXiv preprint arXiv:1705.04304, 2017.\\n[24] Oﬁr Press and Lior Wolf. Using the output embedding to improve language models. arXiv\\npreprint arXiv:1608.05859, 2016.\\n[25] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words\\nwith subword units. arXiv preprint arXiv:1508.07909, 2015.\\n[26] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,\\nand Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\\nlayer. arXiv preprint arXiv:1701.06538, 2017.',\n",
       " 'and Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\\nlayer. arXiv preprint arXiv:1701.06538, 2017.\\n[27] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\\nnov. Dropout: a simple way to prevent neural networks from overﬁtting. Journal of Machine\\nLearning Research, 15(1):1929–1958, 2014.\\n[28] Sainbayar Sukhbaatar, arthur szlam, Jason Weston, and Rob Fergus. End-to-end memory\\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,\\nAdvances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates,\\nInc., 2015.\\n[29] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural\\nnetworks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\\n[30] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.',\n",
       " 'networks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\\n[30] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.\\nRethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\\n[31] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\\nMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine\\ntranslation system: Bridging the gap between human and machine translation. arXiv preprint\\narXiv:1609.08144, 2016.\\n[32] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\\nfast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\\n11']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Convert the text to embeddings\n",
    "texts = [doc.page_content for doc in chunks]\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8ddd1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 326 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 11/11 [00:09<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (326, 384)\n",
      "Adding 326 documents to vector store...\n",
      "Successfully added 326 documents to vector store\n",
      "Total documents in collection: 326\n"
     ]
    }
   ],
   "source": [
    "### Generate embeddings\n",
    "embeddings = embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "### Store in the vector database\n",
    "vectorstore.add_documents(chunks, embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-langchain (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
